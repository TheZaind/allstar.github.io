{
    "questions": [
                    {
                        "question": "Welche Eigenschaft beschreibt einen Host in einem Netzwerk am besten?",
                        "options": [
                        "Ein Host ist immer ein Server, der Dienste anbietet",
                        "Ein Host ist immer ein Client, der Dienste abruft",
                        "Ein Host ist ein Gerät mit einer IP-Adresse zur Kommunikation im Netzwerk",
                        "Ein Host ist eine passive Netzwerkkomponente, die Signale verstärkt"
                        ],
                        "correct": 2,
                        "explain": "Ein **Host** ist definitionsgemäß ein Gerät, das mit einem Netzwerk verbunden ist und dem eine **IP-Adresse** zur Kommunikation zugewiesen wurde. Hosts werden auch als **Endgeräte** bezeichnet und können dabei sowohl die Rolle eines Clients als auch eines Servers einnehmen - sie sind aber nicht auf eine dieser Rollen beschränkt. Hosts sind aktive Teilnehmer der Netzwerkkommunikation und keine passiven Komponenten."
                    },
                    {
                        "question": "Wofür ist die Sicherungsschicht (Layer 2) im OSI-Modell primär verantwortlich?",
                        "options": [
                        "Verbindung zwischen Anwendungen herstellen",
                        "Kommunikation von Netzwerkkarte zu Netzwerkkarte",
                        "Routing zwischen verschiedenen Netzwerken",
                        "Verarbeitung von Benutzerdaten und Anwendungsprotokollen"
                        ],
                        "correct": 1,
                        "explain": "Die **Sicherungsschicht (Layer 2)** ist für die **Kommunikation von Netzwerkkarte zu Netzwerkkarte** verantwortlich. Sie bereitet die zu übertragenden Daten für das physische Netzwerk vor und ermöglicht die direkte Kommunikation zwischen Network Interface Cards (NICs). Dies beinhaltet Aufgaben wie Datenkapselung in Frames, Medienzugriffskontrolle und Fehlererkennung auf Framebasis."
                    },
                    {
                        "question": "Welche der folgenden Aufgaben gehört NICHT zu den Funktionen der Sicherungsschicht?",
                        "options": [
                        "Fehlererkennung und Ablehnung beschädigter Frames",
                        "Kapselung von Layer-3-Paketen in Layer-2-Frames",
                        "Routing von Paketen zwischen verschiedenen Netzwerken",
                        "Steuerung der Datenübertragung über das physische Medium"
                        ],
                        "correct": 2,
                        "explain": "**Routing von Paketen zwischen verschiedenen Netzwerken** ist eine Funktion der **Vermittlungsschicht (Layer 3)** und nicht der Sicherungsschicht. Die Sicherungsschicht ist für die direkte Kommunikation zwischen Geräten im selben Netzwerksegment zuständig, während die Vermittlungsschicht für die Weiterleitung von Paketen zwischen verschiedenen Netzwerken verantwortlich ist. Die Sicherungsschicht führt Fehlererkennung durch, kapselt Layer-3-Pakete und steuert die Übertragung über das physische Medium."
                    },
                    {
                        "question": "Die Sicherungsschicht im OSI-Modell besteht aus zwei Teilschichten nach IEEE 802 LAN/MAN Standards. Diese sind:",
                        "options": [
                        "Transport Control und Network Access",
                        "Logical Link Control (LLC) und Media Access Control (MAC)",
                        "Physical Control und Data Transmission",
                        "Network Interface und Protocol Interface"
                        ],
                        "correct": 1,
                        "explain": "Die Sicherungsschicht nach IEEE 802 LAN/MAN Standards besteht aus zwei Teilschichten:\n\n1. **Logical Link Control (LLC)** - IEEE 802.2, die mit der Netzwerksoftware auf den oberen Schichten kommuniziert und Informationen hinzufügt, die das verwendete Vermittlungsschichtprotokoll identifizieren\n2. **Media Access Control (MAC)** - Implementiert in Hardware (z.B. IEEE 802.3, 802.11 oder 802.15), verantwortlich für Datenkapselung und Medienzugriffskontrolle\n\nDiese Aufteilung ermöglicht eine klare Trennung zwischen hardwarenahen Funktionen und softwarebasierten Protokollaspekten."
                    },
                    {
                        "question": "Was fügt der LLC-Sublayer (Logical Link Control) zu den Netzwerkprotokolldaten hinzu?",
                        "options": [
                        "Nur Quell- und Ziel-MAC-Adressen",
                        "Fehlerkorrekturbits für beschädigte Pakete",
                        "Steuerungsinformationen zur Erreichung des Zielknotens",
                        "Layer-1-Bitübertragungsinformationen"
                        ],
                        "correct": 2,
                        "explain": "Der **LLC-Sublayer (Logical Link Control)** fügt den Netzwerkprotokolldaten (typischerweise einem IP-Paket) **Steuerungsinformationen** hinzu, damit das Paket seinen Zielknoten erreichen kann. Diese Steuerungsinformationen ermöglichen es unter anderem, dass mehrere Layer-3-Protokolle (wie IPv4 und IPv6) dieselbe Netzwerkschnittstelle und dasselbe Medium nutzen können, indem erkennbar wird, welches Vermittlungsschichtprotokoll für den Frame verwendet wird."
                    },
                    {
                        "question": "Eine wichtige Funktion des MAC-Sublayers ist die 'Datenkapselung'. Welche der folgenden Komponenten gehört NICHT zur Datenkapselung durch den MAC-Sublayer?",
                        "options": [
                        "Frame-Begrenzung",
                        "Adressierung",
                        "Fehlererkennung",
                        "Routenberechnung"
                        ],
                        "correct": 3,
                        "explain": "**Routenberechnung** gehört nicht zur Datenkapselung durch den MAC-Sublayer, sondern ist eine Funktion der Vermittlungsschicht (Layer 3). Der MAC-Sublayer bietet folgende Datenkapselungsfunktionen:\n\n- **Frame-Begrenzung**: Verwendung von Begrenzungszeichen zur Identifizierung verschiedener Felder im Frame und zur Synchronisierung zwischen Sende- und Empfangsknoten\n- **Adressierung**: Bereitstellung von Quell- und Zieladressierung für den Transport des Layer-2-Frames zwischen Geräten auf demselben Medium\n- **Fehlererkennung**: Jeder Frame enthält einen Trailer mit Prüfsummen zur Erkennung von Übertragungsfehlern"
                    },
                    {
                        "question": "Der MAC-Sublayer ist für die Medienzugriffskontrolle verantwortlich. Wann wird diese Kontrolle insbesondere benötigt?",
                        "options": [
                        "Nur bei Glasfaserverbindungen",
                        "Bei Vollduplex-Kommunikation",
                        "Bei Halbduplex-Kommunikation über ein gemeinsam genutztes Medium",
                        "Ausschließlich bei kabellosen Verbindungen"
                        ],
                        "correct": 2,
                        "explain": "Die Medienzugriffskontrolle des MAC-Sublayers wird besonders bei **Halbduplex-Kommunikation über ein gemeinsam genutztes Medium** benötigt. In solchen Umgebungen können mehrere Geräte zur gleichen Zeit versuchen, auf das Medium zuzugreifen, was zu Kollisionen führen kann. Die Medienzugriffskontrolle regelt, welches Gerät wann senden darf, um Kollisionen zu vermeiden oder zu behandeln.\n\nBei **Vollduplex-Kommunikation** hingegen ist keine spezielle Zugriffskontrolle erforderlich, da beide Kommunikationspartner gleichzeitig senden und empfangen können, ohne dass Kollisionen auftreten."
                    },
                    {
                        "question": "Welche Funktionen führt ein Router bezüglich der Layer-2-Frames bei jedem Hop entlang eines Netzwerkpfades aus?",
                        "options": [
                        "Er modifiziert nur die Ziel-IP-Adresse und leitet den Frame weiter",
                        "Er führt eine vollständige Entkapselung, Routingentscheidung und neue Kapselung durch",
                        "Er tauscht nur die MAC-Header aus, während der Rest des Frames intakt bleibt",
                        "Er verschlüsselt den Frame für die sichere Übertragung zum nächsten Hop"
                        ],
                        "correct": 1,
                        "explain": "Ein Router führt bei jedem Hop entlang des Pfades die folgenden Layer-2-Funktionen aus:\n\n1. **Empfangen eines Frames** von einem Medium\n2. **Entpacken des Frames**, um das Layer-3-Paket zu extrahieren\n3. **Treffen einer Routingentscheidung** basierend auf der Zieladresse des Pakets\n4. **Erneutes Kapseln des Pakets** in einen neuen Frame, der für das nächste Medium geeignet ist\n5. **Weiterleitung des neuen Frames** auf das entsprechende Segment des physischen Netzes\n\nDiese vollständige Entkapselung und neue Kapselung ist notwendig, weil verschiedene Netzwerksegmente unterschiedliche Layer-2-Protokolle verwenden können (z.B. Ethernet für LAN und PPP für WAN-Verbindungen)."
                    },
                    {
                        "question": "Durch welche Organisationen werden typischerweise Standards für die Sicherungsschicht definiert?",
                        "options": [
                        "Ausschließlich durch die IETF (Internet Engineering Task Force)",
                        "Durch Microsoft, Apple und Linux Foundation",
                        "Durch IEEE, ITU, ISO und ANSI",
                        "Ausschließlich durch die W3C (World Wide Web Consortium)"
                        ],
                        "correct": 2,
                        "explain": "Standards für die Sicherungsschicht werden typischerweise durch folgende Organisationen definiert:\n\n- **IEEE** (Institute of Electrical and Electronics Engineers)\n- **ITU** (International Telecommunication Union)\n- **ISO** (International Organization for Standardization)\n- **ANSI** (American National Standards Institute)\n\nIm Gegensatz zu den Protokollen höherer Schichten des TCP/IP-Modells, die oft durch RFCs (Request for Comments) der IETF definiert werden, sind diese Organisationen für die Definition der offenen Standards und Protokolle der Netzwerkzugangsschicht (OSI Bitübertragungs- und Sicherungsschicht) verantwortlich."
                    },
                    {
                        "question": "Ein Ethernet-Frame enthält sowohl Quell- als auch Zieladressen auf Layer 2. Diese Adressen sind:",
                        "options": [
                        "IP-Adressen",
                        "MAC-Adressen",
                        "Port-Nummern",
                        "Domain-Namen"
                        ],
                        "correct": 1,
                        "explain": "Ein Ethernet-Frame enthält sowohl Quell- als auch Zieladressen auf Layer 2, und diese sind **MAC-Adressen** (Media Access Control). MAC-Adressen sind 48-Bit-Hardwareadressen, die fest in die Netzwerkkarte eingebrannt sind und zur eindeutigen Identifizierung von Geräten auf dem physischen Netzwerk dienen.\n\nIm Vergleich dazu sind:\n- IP-Adressen: Layer-3-Adressen (Vermittlungsschicht)\n- Port-Nummern: Layer-4-Adressen (Transportschicht)\n- Domain-Namen: Gehören zur Anwendungsschicht und werden durch DNS in IP-Adressen aufgelöst"
                    },
                    {
                        "question": "In welcher Beziehung stehen die Logical Link Control (LLC) und die höheren Schichten des OSI-Modells?",
                        "options": [
                        "LLC kommuniziert direkt mit der Anwendungsschicht",
                        "LLC kommuniziert mit der Netzwerksoftware auf den oberen Schichten",
                        "LLC hat keine Verbindung zu höheren Schichten",
                        "LLC kommuniziert ausschließlich mit der Transportschicht"
                        ],
                        "correct": 1,
                        "explain": "Die **Logical Link Control (LLC)** kommuniziert mit der **Netzwerksoftware auf den oberen Schichten**. Als oberer Teil der Sicherungsschicht bildet LLC die Schnittstelle zwischen der Netzwerksoftware der höheren Schichten und der Gerätehardware in den unteren Schichten.\n\nDie LLC fügt Informationen in den Frame ein, die erkennen, welches Vermittlungsschichtprotokoll für den Frame benutzt wird. Diese wichtige Funktion ermöglicht es, dass mehrere Layer-3-Protokolle (wie IPv4 und IPv6) dieselbe Netzwerkschnittstelle und dieselben Medien nutzen können, da die höheren Protokolle anhand der LLC-Informationen identifiziert werden können."
                    },
                    {
                        "question": "Wenn ein Paket von einem lokalen Host zu einem entfernten Ziel übertragen wird, muss es möglicherweise verschiedene Netzwerkumgebungen durchqueren. Was passiert mit dem Layer-2-Frame während dieser Übertragung?",
                        "options": [
                        "Der Frame bleibt unverändert von Quelle bis Ziel",
                        "Der Frame wird nur am Ziel geändert",
                        "Der Frame wird an jedem Hop entpackt und neu gekapselt",
                        "Der Frame wird nur bei Übertragungsfehlern modifiziert"
                        ],
                        "correct": 2,
                        "explain": "Während der Übertragung eines Pakets von einem lokalen Host zu einem entfernten Ziel wird der **Layer-2-Frame an jedem Hop entpackt und neu gekapselt**. Dies geschieht, weil:\n\n1. Verschiedene Netzwerksegmente unterschiedliche Layer-2-Protokolle und Medientypen verwenden können (z.B. Ethernet im LAN, PPP über eine serielle WAN-Verbindung)\n2. Jeder Router auf dem Weg:\n   - Empfängt einen Frame vom eingehenden Medium\n   - Entpackt den Frame, um das Layer-3-Paket zu extrahieren\n   - Trifft eine Routingentscheidung\n   - Kapselt das Paket in einen neuen Frame, der für das ausgehende Medium geeignet ist\n   - Leitet den neuen Frame auf das entsprechende Segment weiter\n\nDies führt dazu, dass ein Paket während seiner Reise mehrere unterschiedliche Layer-2-Frames durchläuft, während das Layer-3-Paket (mit Ausnahme von TTL/Hop Count-Änderungen) weitgehend unverändert bleibt."
                    },
                    {
                        "question": "Die Sicherungsschicht bereitet Daten für die Übertragung über das physische Netzwerk vor. Diese Funktion ermöglicht folgendes:",
                        "options": [
                        "Die Implementierung von Verschlüsselungsstandards",
                        "Verwendung von Transport-Layer-Security (TLS)",
                        "Die Unabhängigkeit höherer Protokolle vom jeweiligen Übertragungsmedium",
                        "Die direkte Kommunikation zwischen Anwendungen"
                        ],
                        "correct": 2,
                        "explain": "Die Vorbereitung der Daten für die Übertragung über das physische Netzwerk durch die Sicherungsschicht ermöglicht die **Unabhängigkeit höherer Protokolle vom jeweiligen Übertragungsmedium**.\n\nOhne die Sicherungsschicht müssten Vermittlungsschichtprotokolle (wie IP) für jede Medienart, die entlang eines Übertragungspfads auftritt, gesonderte Vorkehrungen treffen. Außerdem müsste die Vermittlungsschicht jedes Mal angepasst werden, wenn eine neue Netzwerktechnologie oder ein neues Medium genutzt würde.\n\nDurch die Abstraktion, die die Sicherungsschicht bietet, können die höheren Schichten unabhängig von den spezifischen Details des physischen Übertragungsmediums arbeiten, was die Entwicklung und Implementierung von Netzwerkprotokollen erheblich vereinfacht."
                    },
                    {
                        "question": "Was ist der primäre Zweck des Media Access Control (MAC) Sublayers?",
                        "options": [
                        "Implementierung von Sicherheitsprotokollen für die Datenübertragung",
                        "Kontrolle der Hardware für das Senden und Empfangen von Daten auf dem Medium",
                        "Verwaltung von IP-Adressen im lokalen Netzwerk",
                        "Protokollübersetzung zwischen unterschiedlichen Netzwerken"
                        ],
                        "correct": 1,
                        "explain": "Der primäre Zweck des **Media Access Control (MAC) Sublayers** ist die **Kontrolle der Hardware für das Senden und Empfangen von Daten auf dem Medium**. Der MAC-Sublayer wird in Hardware implementiert (z.B. in Netzwerkkarten) und ist verantwortlich für:\n\n1. Die Steuerung der Netzwerkkarte und anderer Hardware, die für das Senden und Empfangen von Daten auf dem kabelgebundenen oder drahtlosen Medium zuständig ist\n2. Datenkapselung, einschließlich Frame-Begrenzung, Adressierung und Fehlererkennung\n3. Medienzugriffskontrolle, die es mehreren Geräten ermöglicht, über ein gemeinsam genutztes Medium zu kommunizieren\n\nDer MAC-Sublayer arbeitet direkt mit verschiedenen Physical Layer-Technologien zusammen und bildet die Schnittstelle zwischen dem LLC-Sublayer und der physischen Übertragung."
                    },
                    {
                        "question": "Die Medienzugriffskontrolle ist eine wichtige Funktion der Sicherungsschicht. In welcher Situation ist diese Funktion NICHT notwendig?",
                        "options": [
                        "In drahtlosen Netzwerken mit mehreren Geräten",
                        "In geteilten Ethernet-Segmenten mit Hub-Verbindungen",
                        "In Vollduplex-Punkt-zu-Punkt-Verbindungen",
                        "In Netzwerken mit Broadcast-Übertragungen"
                        ],
                        "correct": 2,
                        "explain": "Die Medienzugriffskontrolle ist in **Vollduplex-Punkt-zu-Punkt-Verbindungen** nicht notwendig. In solchen Verbindungen kann jeder Kommunikationspartner gleichzeitig senden und empfangen, ohne dass Kollisionen auftreten können, da das Medium nicht geteilt wird.\n\nIn allen anderen genannten Szenarien ist eine Medienzugriffskontrolle erforderlich:\n\n- **Drahtlose Netzwerke mit mehreren Geräten**: Mehrere Geräte teilen sich das Funkspektrum als Medium\n- **Geteilte Ethernet-Segmente mit Hub-Verbindungen**: Mehrere Geräte teilen sich das gleiche Übertragungsmedium\n- **Netzwerke mit Broadcast-Übertragungen**: Hier müssen Zugriffe koordiniert werden, um Kollisionen zu vermeiden\n\nDie Medienzugriffskontrolle wird hauptsächlich benötigt, wenn mehrere Geräte um den Zugriff auf ein gemeinsam genutztes (Halbduplex-)Medium konkurrieren."
                    },
                    {
                        "question": "Bei seriellen Verbindungen zwischen zwei Routern ist die Medienzugriffskontrolle weniger komplex als bei Ethernet-LANs. Dies liegt daran, dass:",
                        "options": [
                        "Serielle Verbindungen automatische Fehlerkorrektur implementieren",
                        "Serielle Verbindungen typischerweise direkte Punkt-zu-Punkt-Verbindungen sind",
                        "Serielle Verbindungen höhere Übertragungsgeschwindigkeiten ermöglichen",
                        "Serielle Verbindungen grundsätzlich sicherer sind als Ethernet"
                        ],
                        "correct": 1,
                        "explain": "Bei seriellen Verbindungen zwischen zwei Routern ist die Medienzugriffskontrolle weniger komplex als bei Ethernet-LANs, weil **serielle Verbindungen typischerweise direkte Punkt-zu-Punkt-Verbindungen sind**.\n\nIn einer Punkt-zu-Punkt-Verbindung gibt es nur zwei Kommunikationspartner, die das Medium nutzen. Dadurch entfällt die Notwendigkeit komplexer Zugriffskontrollmechanismen, wie sie in geteilten Medien (z.B. in einem Ethernet-LAN mit vielen Hosts) erforderlich sind, wo mehrere Geräte gleichzeitig auf das Medium zugreifen möchten.\n\nBei Ethernet-LANs hingegen können viele Hosts gleichzeitig versuchen, auf das geteilte Medium zuzugreifen, was Mechanismen zur Kollisionsvermeidung oder -erkennung erfordert (z.B. CSMA/CD bei älteren Ethernet-Implementierungen)."
                    },
                    {
                        "question": "Was ist ein Netzwerkknoten im Kontext von Computernetzwerken?",
                        "options": [
                        "Ausschließlich ein Router, der Netzwerke verbindet",
                        "Eine spezielle Software zur Netzwerküberwachung",
                        "Ein Gerät, das Daten entlang eines Kommunikationspfads empfangen, erstellen, speichern oder weiterleiten kann",
                        "Eine physische Verbindungsstelle zwischen zwei Netzwerkkabeln"
                        ],
                        "correct": 2,
                        "explain": "Ein **Netzwerkknoten** im Kontext von Computernetzwerken ist **ein Gerät, das Daten entlang eines Kommunikationspfads empfangen, erstellen, speichern oder weiterleiten kann**.\n\nEin Netzwerkknoten kann entweder:\n- Ein **Endgerät** sein, wie ein Laptop oder ein Mobiltelefon, das als Quelle oder Ziel von Netzwerkverkehr dient\n- Ein **Zwischengerät** sein, wie ein Ethernet-Switch, Router oder Access Point, das Daten zwischen anderen Knoten weiterleitet\n\nDiese Definition umfasst also eine breite Palette von Geräten, die am Netzwerkverkehr teilnehmen können, und ist nicht auf eine bestimmte Geräteklasse beschränkt."
                    },
                    {
                        "question": "Wenn ein Router ein Paket zwischen verschiedenen Netzwerktypen weiterleitet, bleibt die Adressierung auf Layer 2 erhalten.",
                        "options": [
                        "Wahr",
                        "Falsch"
                        ],
                        "correct": 1,
                        "explain": "Diese Aussage ist **falsch**. Wenn ein Router ein Paket zwischen verschiedenen Netzwerktypen weiterleitet, bleibt die Adressierung auf Layer 2 **nicht** erhalten.\n\nBei jedem Hop entlang des Pfades führt ein Router folgende Layer-2-Funktionen aus:\n1. Empfängt einen Frame von einem Medium\n2. Entpackt den Frame, um das Layer-3-Paket zu extrahieren\n3. Trifft eine Routingentscheidung basierend auf der Zieladresse des Pakets\n4. Kapselt das Paket in einen **neuen** Frame mit **neuen** Layer-2-Adressen für das ausgehende Interface\n5. Leitet den neuen Frame auf das entsprechende Segment weiter\n\nDie Layer-2-Adressen (MAC-Adressen) haben nur lokale Bedeutung innerhalb eines Netzwerksegments und werden an jeder Routergrenze geändert. Im Gegensatz dazu bleiben die Layer-3-Adressen (IP-Adressen) während des gesamten Übertragungswegs von Quelle zu Ziel gleich (abgesehen von NAT-Szenarien)."
                    },
                    {
                        "question": "Die Logical Link Control (LLC) ermöglicht die gleichzeitige Nutzung mehrerer Vermittlungsschichtprotokolle auf derselben Netzwerkschnittstelle.",
                        "options": [
                        "Wahr",
                        "Falsch"
                        ],
                        "correct": 0,
                        "explain": "Diese Aussage ist **wahr**. Die Logical Link Control (LLC) ermöglicht tatsächlich die gleichzeitige Nutzung mehrerer Vermittlungsschichtprotokolle auf derselben Netzwerkschnittstelle.\n\nDer LLC-Sublayer (IEEE 802.2) fügt Informationen in den Frame ein, die erkennen, welches Vermittlungsschichtprotokoll für den Frame benutzt wird. Diese wichtige Funktion ermöglicht es, dass mehrere Layer-3-Protokolle, wie IPv4 und IPv6, dieselbe Netzwerkschnittstelle und dieselben Medien benutzen können.\n\nOhne diese Funktion müsste für jedes Vermittlungsschichtprotokoll eine separate physische Verbindung existieren, was ineffizient und unpraktisch wäre. Die LLC fungiert somit als Multiplexer, der verschiedene Protokolle der höheren Schichten über eine gemeinsame physische Infrastruktur laufen lässt."
                    },
                    {
                        "question": "Die Sicherungsschicht kapselt Daten in Frames. Welches der folgenden Elemente ist typischerweise NICHT Teil dieser Kapselung?",
                        "options": [
                        "Quell- und Ziel-MAC-Adressen",
                        "Frame-Begrenzungszeichen",
                        "TCP- oder UDP-Header",
                        "Fehlerkontroll-Trailer"
                        ],
                        "correct": 2,
                        "explain": "**TCP- oder UDP-Header** sind typischerweise **nicht** Teil der Kapselung durch die Sicherungsschicht. Diese Header gehören zur Transportschicht (Layer 4) des OSI-Modells und werden bereits vom Layer-3-Paket umschlossen, bevor dieses von der Sicherungsschicht gekapselt wird.\n\nDie Sicherungsschicht fügt bei der Kapselung typischerweise folgende Elemente hinzu:\n\n- **Quell- und Ziel-MAC-Adressen**: Zur Identifikation der sendenden und empfangenden Netzwerkkarten auf dem lokalen Netzwerksegment\n- **Frame-Begrenzungszeichen**: Zur Markierung von Anfang und Ende des Frames sowie zur Synchronisierung\n- **Fehlerkontroll-Trailer**: Meist in Form einer Prüfsumme (wie CRC), um Übertragungsfehler zu erkennen\n\nDie Sicherungsschicht kapselt das komplette Layer-3-Paket (das bereits Transport- und höhere Schichten enthält) und fügt ihre eigenen Header und Trailer hinzu."
                    },
                     {
                "question": "Ein Netzwerkadministrator plant ein neues LAN und muss sich zwischen verschiedenen Topologien entscheiden. Welche physische Topologie bietet den Vorteil, dass Geräte einfach hinzugefügt oder entfernt werden können und die Fehlersuche erleichtert wird?",
                "options": [
                    "Stern-Topologie",
                    "Bus-Topologie",
                    "Ring-Topologie",
                    "Mesh-Topologie"
                ],
                "correct": 0,
                "explain": "Die **Stern-Topologie** zeichnet sich durch ihre hervorragende Skalierbarkeit und einfache Fehlerdiagnose aus.\n\n- **Einfache Installation:** Endgeräte werden direkt mit einem zentralen Netzwerkgerät (typischerweise einem Ethernet-Switch) verbunden\n- **Skalierbarkeit:** Das Hinzufügen und Entfernen von Endgeräten ist unkompliziert, da jedes Gerät seine eigene Verbindung zum zentralen Punkt hat\n- **Fehlersuche:** Probleme lassen sich leichter isolieren, da Verbindungsprobleme meist auf ein spezifisches Gerät oder dessen Verbindung zum zentralen Switch beschränkt sind\n- **Erweiterbarkeit:** Die Stern-Topologie kann zu einer erweiterten Stern-Topologie (auch Baum-Topologie genannt) ausgebaut werden, indem mehrere Switches zwischengeschaltet werden"
            },
            {
                "question": "In einem WAN mit Hub-and-Spoke-Topologie ist jeder Endpunkt direkt mit jedem anderen Endpunkt verbunden.",
                "options": ["Wahr", "Falsch"],
                "correct": 1,
                "explain": "Diese Aussage ist **falsch**. In einer Hub-and-Spoke-Topologie sind die Endpunkte (Spokes) nicht direkt miteinander verbunden, sondern kommunizieren über einen zentralen Punkt (Hub).\n\n- **Zentrale Verbindungsstruktur:** Alle Endpunkte (Spokes) sind nur mit dem zentralen Hub verbunden\n- **Indirekte Kommunikation:** Wenn ein Endpunkt mit einem anderen kommunizieren möchte, muss der Datenverkehr immer über den zentralen Hub geleitet werden\n- **Kontrast zur Mesh-Topologie:** Anders als bei einer Mesh-Topologie, wo direkte Verbindungen zwischen allen Endpunkten bestehen, gibt es bei Hub-and-Spoke keine direkten Verbindungen zwischen den einzelnen Spokes\n- **Effizienz vs. Redundanz:** Hub-and-Spoke benötigt weniger physische Verbindungen als eine vollständige Mesh-Topologie, bietet aber auch weniger Redundanz"
            },
            {
                "question": "Welche Kommunikationsmethode erlaubt es zwei verbundenen Geräten, gleichzeitig zu senden und zu empfangen?",
                "options": [
                    "Halbduplex",
                    "Vollduplex",
                    "Simplex",
                    "Multiplex"
                ],
                "correct": 1,
                "explain": "**Vollduplex** ermöglicht die gleichzeitige bidirektionale Kommunikation zwischen zwei Geräten.\n\n- **Gleichzeitiger Datenaustausch:** Beide Geräte können gleichzeitig auf dem Medium übertragen und empfangen\n- **Höhere Effizienz:** Die gleichzeitige Übertragung in beide Richtungen erhöht den Datendurchsatz und reduziert Latenzzeiten\n- **Typische Anwendung:** Moderne Ethernet-Switches arbeiten standardmäßig im Vollduplex-Modus\n- **Mediennutzung:** Die Sicherungsschicht stellt sicher, dass das Medium jederzeit beiden Knoten für die Übertragung zur Verfügung steht\n- **Kontrast zu Halbduplex:** Anders als bei Halbduplex gibt es keine Beschränkung auf eine Richtung zur Zeit"
            },
            {
                "question": "Bei der Einrichtung eines Netzwerks werden verschiedene Topologien diskutiert. Was beschreibt die 'logische Topologie' eines Netzwerks am besten?",
                "options": [
                    "Die physische Anordnung der Kabelverbindungen zwischen den Geräten",
                    "Die Art und Weise, wie ein Netzwerk Frames von einem Knoten zum nächsten überträgt",
                    "Die genauen Standorte der Geräte mit Raumnummern und Positionen im Rack",
                    "Die Anzahl und Typen der verwendeten Netzwerkgeräte"
                ],
                "correct": 1,
                "explain": "Die **logische Topologie** bezieht sich auf die Art und Weise, wie ein Netzwerk Frames von einem Knoten zum nächsten überträgt.\n\n- **Virtueller Datenfluss:** Sie identifiziert die virtuellen Verbindungen und den logischen Pfad, den Daten im Netzwerk nehmen\n- **Adressierungsschema:** Beinhaltet die Verwendung von Geräteschnittstellen und Layer-3-IP-Adressierungsschemata\n- **Einfluss auf Implementierung:** Die logische Topologie beeinflusst direkt den Typ des Netzwerk-Framings und die Medienzugriffskontrolle\n- **Sicht der Sicherungsschicht:** Die Sicherungsschicht (Data Link Layer) 'sieht' die logische Topologie eines Netzes bei der Steuerung des Datenzugriffs auf die Medien\n- **Kontrast zur physischen Topologie:** Während die physische Topologie die tatsächlichen Kabelverbindungen und Hardware-Standorte beschreibt, konzentriert sich die logische Topologie auf den konzeptionellen Datenfluss"
            },
            {
                "question": "Ein IT-Techniker richtet ein WLAN ein. Welchen Medienzugriffssteuerungsmechanismus verwendet ein modernes WLAN?",
                "options": [
                    "CSMA/CD (Carrier Sense Multiple Access with Collision Detection)",
                    "Token Ring",
                    "CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance)",
                    "ARCNET"
                ],
                "correct": 2,
                "explain": "Moderne WLANs (IEEE 802.11) verwenden **CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance)**.\n\n- **Kollisionsvermeidung statt -erkennung:** Da in drahtlosen Umgebungen Kollisionen schwer zu erkennen sind, konzentriert sich CSMA/CA darauf, Kollisionen zu vermeiden, statt sie zu erkennen\n- **Wartezeit vor Übertragung:** Geräte warten gezielt vor der Übertragung, um Kollisionen zu reduzieren\n- **Übertragungsdauer:** Jedes sendende Gerät gibt die erforderliche Zeitdauer für seine Übertragung an, damit andere Geräte wissen, wie lange sie warten müssen\n- **Bestätigungsmechanismus:** Nach einem gesendeten Frame gibt der Empfänger eine Bestätigung aus\n- **Kontrast zu CSMA/CD:** Anders als bei CSMA/CD (verwendet in älteren Ethernet-LANs mit Bus-Topologie oder Hubs) wird nicht auf das Erkennen von Kollisionen, sondern auf deren Vermeidung gesetzt"
            },
            {
                "question": "Die physische Topologie eines Netzwerks ist immer identisch mit seiner logischen Topologie.",
                "options": ["Wahr", "Falsch"],
                "correct": 1,
                "explain": "Diese Aussage ist **falsch**. Die physische und logische Topologie eines Netzwerks können sich deutlich unterscheiden.\n\n- **Unterschiedliche Betrachtungsebenen:** Die physische Topologie beschreibt die tatsächliche materielle Anordnung der Verbindungen und Geräte, während die logische Topologie den konzeptionellen Datenfluss darstellt\n- **Beispiel zur Verdeutlichung:** Ein physisches Stern-Netzwerk mit einem Switch kann logisch als Punkt-zu-Punkt-Verbindungen zwischen den angeschlossenen Geräten funktionieren\n- **Zwischengeschaltete Geräte:** Das Hinzufügen von zwischengeschalteten physischen Verbindungen muss die logische Topologie nicht ändern - beispielsweise kann eine logische Punkt-zu-Punkt-Verbindung über mehrere physische Geräte realisiert werden\n- **IP-Adressierungsschema:** Die logische Topologie umfasst auch das Adressierungsschema und die Verbindung virtueller Netzwerke, unabhängig von der physischen Verkabelung"
            },
            {
                "question": "Ein Systemadministrator möchte ein älteres Ethernet-Netzwerk mit Hub auf ein Switch-basiertes Netzwerk umstellen. Welcher Vorteil ergibt sich hinsichtlich der Duplexfähigkeit?",
                "options": [
                    "Wechsel von Vollduplex zu Halbduplex",
                    "Kein Unterschied in der Duplexfähigkeit",
                    "Wechsel von Halbduplex zu Vollduplex",
                    "Wechsel von Multiplex zu Simplex"
                ],
                "correct": 2,
                "explain": "Bei der Umstellung von einem Hub-basierten auf ein Switch-basiertes Ethernet-Netzwerk erfolgt ein **Wechsel von Halbduplex zu Vollduplex**.\n\n- **Hub-Limitationen:** Ethernet-Hubs arbeiten im Halbduplex-Modus, was bedeutet, dass Geräte entweder senden ODER empfangen können, aber nicht beides gleichzeitig\n- **Switch-Fähigkeiten:** Ethernet-Switches arbeiten standardmäßig im Vollduplex-Modus, was gleichzeitiges Senden UND Empfangen ermöglicht\n- **Leistungssteigerung:** Der Wechsel zu Vollduplex verdoppelt theoretisch die verfügbare Bandbreite und reduziert Latenzzeiten durch Wegfall der Kollisionserkennung\n- **Kollisionsdomänen:** Switches erstellen separate Kollisionsdomänen für jeden Port, während Hubs eine einzige gemeinsame Kollisionsdomäne für alle angeschlossenen Geräte darstellen\n- **Medienzugriffskontrolle:** Mit der Umstellung auf Switches entfällt die Notwendigkeit für CSMA/CD bei Ethernet-Netzwerken"
            },
            {
                "question": "In einem Netzwerk mit hohem Datenaufkommen tritt ein Problem auf: Bei gleichzeitigen Übertragungen kommt es zu zahlreichen Kollisionen. Welche Netzwerkkomponente wird am wahrscheinlichsten verwendet?",
                "options": [
                    "Moderner Ethernet-Switch",
                    "Ethernet-Hub",
                    "Router",
                    "Firewall"
                ],
                "correct": 1,
                "explain": "Die beschriebenen Kollisionsprobleme treten höchstwahrscheinlich in einem Netzwerk mit einem **Ethernet-Hub** auf.\n\n- **Gemeinsames Medium:** Hubs stellen ein gemeinsames Medium für alle angeschlossenen Geräte bereit, wobei alle Geräte dieselbe Kollisionsdomäne teilen\n- **Halbduplex-Betrieb:** Ethernet-Hubs arbeiten im Halbduplex-Modus, was bedeutet, dass nur ein Gerät zurzeit senden kann\n- **CSMA/CD erforderlich:** In Hub-basierten Netzwerken wird CSMA/CD verwendet, um mit Kollisionen umzugehen, was bei hohem Datenaufkommen zu Ineffizienz führt\n- **Kollisionen bei gleichzeitiger Übertragung:** Wenn zwei oder mehr Geräte gleichzeitig senden, kommt es zu Kollisionen, was zu beschädigten Daten und notwendigen erneuten Übertragungen führt\n- **Kontrast zu Switches:** Moderne Ethernet-Switches arbeiten im Vollduplex-Modus und erstellen separate Kollisionsdomänen für jeden Port, wodurch Kollisionen eliminiert werden"
            },
            {
                "question": "Welche Art von WAN-Topologie beschreibt eine Verbindung, bei der mehrere, aber nicht alle Endgeräte miteinander verbunden sind?",
                "options": [
                    "Punkt-zu-Punkt",
                    "Hub-and-Spoke",
                    "Vollständige Mesh",
                    "Teilweise Mesh (Hybrid)"
                ],
                "correct": 3,
                "explain": "Eine **teilweise Mesh-Topologie (Hybrid)** beschreibt eine WAN-Struktur, bei der mehrere, aber nicht alle Endgeräte direkt miteinander verbunden sind.\n\n- **Hybride Lösung:** Diese Topologie kombiniert Elemente verschiedener Grundtopologien und stellt einen Kompromiss zwischen vollständiger Vermaschung und einfacheren Strukturen dar\n- **Selektive Verbindungen:** Direkte Verbindungen werden strategisch zwischen häufig kommunizierenden oder kritischen Knoten implementiert\n- **Effizienz vs. Redundanz:** Im Vergleich zur vollständigen Mesh-Topologie werden weniger physische Verbindungen benötigt, was Kosten spart, während immer noch mehr Redundanz als bei Punkt-zu-Punkt oder Hub-and-Spoke geboten wird\n- **Flexibilität:** Die teilweise Vermaschung erlaubt es Netzwerkdesignern, Redundanz dort zu implementieren, wo sie am meisten benötigt wird, ohne die Komplexität und Kosten einer vollständigen Vermaschung\n- **Skalierbarkeit:** Diese Topologie lässt sich leichter skalieren als eine vollständige Mesh-Topologie, da nicht jedes neue Gerät mit allen bestehenden verbunden werden muss"
            },
            {
                "question": "Moderne Ethernet-Netzwerke mit Switches verwenden CSMA/CD als Zugriffsmethode.",
                "options": ["Wahr", "Falsch"],
                "correct": 1,
                "explain": "Diese Aussage ist **falsch**. Moderne Ethernet-Netzwerke mit Switches benötigen keine CSMA/CD-Zugriffsmethode mehr.\n\n- **Vollduplex-Betrieb:** Moderne Ethernet-Switches arbeiten im Vollduplex-Modus, bei dem Geräte gleichzeitig senden und empfangen können\n- **Separate Kollisionsdomänen:** Jeder Switch-Port bildet seine eigene Kollisionsdomäne, wodurch Kollisionen zwischen verschiedenen angeschlossenen Geräten eliminiert werden\n- **Keine Medienkontention:** Da es keine Konkurrenzsituation um das Medium gibt (jedes Gerät hat seine eigene dedizierte Verbindung zum Switch), ist keine Kollisionserkennung oder -vermeidung notwendig\n- **Historischer Kontext:** CSMA/CD wurde in älteren Ethernet-Implementierungen verwendet, insbesondere bei Bus-Topologien und Hub-basierten Netzwerken, die im Halbduplex-Modus arbeiteten\n- **Effizienzsteigerung:** Der Wegfall von CSMA/CD in modernen Ethernet-Netzwerken trägt zu höherer Effizienz und Durchsatz bei"
            },
            {
                "question": "Ein Netzwerkarchitekt plant ein WAN für eine Firma mit mehreren Standorten. Welche Topologie würde die geringste Anzahl an Verbindungen erfordern, wenn alle Standorte miteinander kommunizieren müssen?",
                "options": [
                    "Vollständige Mesh",
                    "Punkt-zu-Punkt",
                    "Hub-and-Spoke",
                    "Teilweise Mesh"
                ],
                "correct": 2,
                "explain": "Die **Hub-and-Spoke-Topologie** erfordert die geringste Anzahl an Verbindungen, wenn alle Standorte miteinander kommunizieren müssen.\n\n- **Zentrale Verbindungsstruktur:** Alle Außenstandorte (Spokes) sind nur mit einem zentralen Standort (Hub) verbunden\n- **Minimale Verbindungsanzahl:** Für n Standorte werden nur (n-1) Verbindungen benötigt, im Gegensatz zu n(n-1)/2 Verbindungen bei einer vollständigen Mesh-Topologie\n- **Indirekte Kommunikation:** Standorte kommunizieren miteinander über den zentralen Hub, was zwar zusätzliche Latenz verursachen kann, aber die Anzahl der erforderlichen Verbindungen drastisch reduziert\n- **Kosteneffizienz:** Weniger Verbindungen bedeuten in der Regel geringere WAN-Kosten, was diese Topologie besonders für Organisationen mit Kostendruck attraktiv macht\n- **Single Point of Failure:** Ein wesentlicher Nachteil ist die Abhängigkeit vom zentralen Hub, dessen Ausfall die Kommunikation zwischen allen Standorten unterbrechen würde"
            },
            {
                "question": "Ein Netzwerktechniker findet heraus, dass zwei verbundene Geräte Leistungsprobleme haben. Das eine ist auf Vollduplex eingestellt, das andere auf Halbduplex. Wie wird dieses Problem bezeichnet?",
                "options": [
                    "Duplex-Diskrepanz",
                    "Topologie-Konflikt",
                    "Frametyp-Mismatch",
                    "Bandbreiten-Inkonsistenz"
                ],
                "correct": 0,
                "explain": "Dieses Problem wird als **Duplex-Diskrepanz** bezeichnet.\n\n- **Definition:** Eine Duplex-Diskrepanz tritt auf, wenn zwei verbundene Netzwerkschnittstellen in unterschiedlichen Duplex-Modi arbeiten - eine im Vollduplex und die andere im Halbduplex\n- **Auswirkungen:** Dies führt zu Ineffizienz, längeren Latenzzeiten und Leistungseinbußen der Verbindung\n- **Ursachen:** Häufig entsteht das Problem durch falsche manuelle Konfiguration oder fehlerhafte Auto-Negotiation zwischen den Geräten\n- **Fehlermuster:** Typische Symptome sind intermittierende Verbindungsprobleme, niedrige Durchsatzraten und erhöhte Fehlerraten, insbesondere bei höherem Datenaufkommen\n- **Lösung:** Die Behebung erfordert die Konfiguration beider Geräte im gleichen Duplex-Modus, idealerweise im Vollduplex, wenn dies von beiden Geräten unterstützt wird"
            },
            {
                "question": "In einem Point-to-Point Protocol (PPP) Netzwerk muss ein Gerät überprüfen, ob eingehende Frames für dieses Gerät oder für andere Geräte bestimmt sind.",
                "options": ["Wahr", "Falsch"],
                "correct": 1,
                "explain": "Diese Aussage ist **falsch**. In einem Point-to-Point Protocol (PPP) Netzwerk muss ein Gerät NICHT überprüfen, ob eingehende Frames für dieses Gerät oder für andere Geräte bestimmt sind.\n\n- **Exklusive Kommunikation:** Bei einer Punkt-zu-Punkt-Topologie teilen nur zwei Knoten das Medium und kommunizieren ausschließlich miteinander\n- **Einfaches Framing:** Die logischen Protokolle der Sicherungsschicht sind sehr einfach, da alle Frames auf dem Medium nur die zwei verbundenen Knoten betreffen\n- **Eindeutige Zustellung:** Ein Knoten platziert die Frames auf dem Medium an einem Ende, und der andere Knoten nimmt diese am anderen Ende der Verbindung wieder auf\n- **Keine Adressauflösung erforderlich:** Anders als bei Broadcast-Medien (wie bei Ethernet über shared Media) gibt es keine Notwendigkeit für Adressierung zur Unterscheidung zwischen mehreren potenziellen Empfängern\n- **Ausnahme Ethernet:** Es ist zu beachten, dass bei einer Punkt-zu-Punkt-Verbindung über Ethernet (im Gegensatz zu PPP) das Gerät weiterhin prüfen muss, ob der eingehende Frame für diesen Knoten bestimmt ist"
            },
            {
                "question": "Welches Medium wird in einem konfliktbasierten Netzwerk mit mehreren verbundenen Geräten typischerweise für die Kommunikation verwendet?",
                "options": [
                    "Dedizierte Punkt-zu-Punkt-Verbindungen",
                    "Geteiltes Medium mit allen verbundenen Geräten",
                    "Virtuelle private Netzwerke (VPNs)",
                    "Isolierte Kollisionsdomänen pro Gerät"
                ],
                "correct": 1,
                "explain": "In einem konfliktbasierten Netzwerk mit mehreren verbundenen Geräten wird typischerweise ein **geteiltes Medium mit allen verbundenen Geräten** verwendet.\n\n- **Gemeinsame Nutzung:** Alle angeschlossenen Geräte teilen sich dasselbe Übertragungsmedium und konkurrieren um dessen Nutzung\n- **Kollisionsdomäne:** Alle Geräte befinden sich in derselben Kollisionsdomäne, was bedeutet, dass wenn zwei Geräte gleichzeitig senden, eine Kollision entsteht\n- **Zugriffskontrolle erforderlich:** Um den Zugriff auf das geteilte Medium zu regeln, werden Verfahren wie CSMA/CD (bei älteren Ethernet-LANs) oder CSMA/CA (bei WLANs) eingesetzt\n- **Halbduplex-Betrieb:** Konfliktbasierte Netzwerke arbeiten typischerweise im Halbduplex-Modus, wobei nur ein Gerät zurzeit senden kann\n- **Beispiele:** Typische Beispiele sind ältere Ethernet-LANs mit Bus-Topologie, Ethernet-LANs über Hubs oder drahtlose LANs (WLANs)"
            },
            {
                "question": "Bei der Implementierung eines neuen Netzwerks soll eine Topologie mit kontrollierten Zugriffszeiten gewählt werden. Welche historische Technologie verwendete eine Zugriffsmethode, bei der jeder Knoten eine zugewiesene Zeitspanne hatte, in der er das Medium nutzen konnte?",
                "options": [
                    "Ethernet mit CSMA/CD",
                    "WLAN mit CSMA/CA",
                    "Token Ring",
                    "Ethernet über Twisted-Pair"
                ],
                "correct": 2,
                "explain": "**Token Ring** verwendete eine kontrollierte Zugriffsmethode, bei der jeder Knoten eine zugewiesene Zeitspanne zur Mediennutzung hatte.\n\n- **Kontrollierter Zugriff:** Im Token Ring-Netzwerk wurde ein spezielles Datenpaket (Token) in einer festgelegten Reihenfolge von Knoten zu Knoten weitergereicht\n- **Übertragungsrecht:** Nur der Knoten, der das Token besaß, durfte zu einem bestimmten Zeitpunkt senden\n- **Streng geregelte Struktur:** Diese Zugriffskontrolle eliminierte Kollisionen vollständig, führte aber zu Ineffizienzen, da ein Gerät warten musste, bis es an der Reihe war\n- **Historischer Kontext:** Token Ring wurde von IBM entwickelt und war in den 1980er und 1990er Jahren eine wichtige Netzwerktechnologie, wurde aber später von Ethernet verdrängt\n- **Weitere Beispiele:** ARCNET ist ein weiteres Beispiel für ein Netzwerk mit kontrolliertem Zugriff"
            },
            {
                "question": "Bei der Erweiterung eines bestehenden Netzwerks ist zu entscheiden, wie neue Geräte angebunden werden sollen. Welche physische Netzwerktopologie ist eine Erweiterung der Stern-Topologie, bei der mehrere Switches zwischengeschaltet werden?",
                "options": [
                    "Bus-Topologie",
                    "Mesh-Topologie",
                    "Ring-Topologie",
                    "Erweiterte Stern-Topologie (Baum)"
                ],
                "correct": 3,
                "explain": "Die **erweiterte Stern-Topologie (Baum-Topologie)** ist eine Erweiterung der Stern-Topologie, bei der mehrere Switches zwischengeschaltet werden.\n\n- **Hierarchische Struktur:** Diese Topologie bildet eine baumartige Struktur mit mehreren Ebenen von Switches\n- **Kaskadierung:** Ein zentraler Switch (Root) verbindet sich mit weiteren Switches, die wiederum Endgeräte oder weitere Switches anbinden können\n- **Vorteile der Stern-Topologie:** Behält die Vorteile der Stern-Topologie bei, einschließlich einfacher Installation, Skalierbarkeit und vereinfachter Fehlersuche\n- **Größere Reichweite:** Ermöglicht die Abdeckung größerer geografischer Bereiche oder mehrerer Etagen eines Gebäudes\n- **Strukturierte Verkabelung:** Unterstützt das Konzept der strukturierten Verkabelung mit Backbone-, Verteiler- und Zugangsbereichen"
            },
            {
                "question": "Welche Art von Kollisionsdomäne schafft ein moderner Ethernet-Switch pro Port?",
                "options": [
                    "Gemeinsame Kollisionsdomäne für alle Ports",
                    "Keine Kollisionsdomäne, da Kollisionen unmöglich sind",
                    "Separate Kollisionsdomäne für jeden Port",
                    "Variable Kollisionsdomänen basierend auf der Port-Geschwindigkeit"
                ],
                "correct": 2,
                "explain": "Ein moderner Ethernet-Switch schafft eine **separate Kollisionsdomäne für jeden Port**.\n\n- **Isolation des Datenverkehrs:** Jeder Port eines Switches bildet seine eigene, isolierte Kollisionsdomäne\n- **Kollisionsfreiheit bei Vollduplex:** Wenn die angeschlossenen Geräte im Vollduplex-Modus arbeiten (was heute Standard ist), sind Kollisionen innerhalb dieser Domänen praktisch eliminiert\n- **Kontrast zu Hubs:** Anders als bei Hubs, die eine einzige gemeinsame Kollisionsdomäne für alle angeschlossenen Geräte bilden, segmentiert ein Switch den Netzwerkverkehr\n- **Mikrosequenzierung:** Switches verwenden Puffer und Mikrosequenzierungstechniken, um Frames zwischen verschiedenen Ports zu übertragen, ohne dass es zu Kollisionen kommt\n- **Leistungssteigerung:** Diese Isolation führt zu einer erhöhten Netzwerkeffizienz, da Geräte nicht auf andere warten müssen, um zu senden"
            },
            {
                "question": "In einem konfliktbasierten Zugriffsnetzwerk mit CSMA/CD-Protokoll führt eine hohe Auslastung des Mediums zu effizienter Netzwerknutzung.",
                "options": ["Wahr", "Falsch"],
                "correct": 1,
                "explain": "Diese Aussage ist **falsch**. In einem konfliktbasierten Zugriffsnetzwerk mit CSMA/CD führt eine hohe Auslastung des Mediums zu verminderter Effizienz und Leistungseinbußen.\n\n- **Kollisionsanstieg:** Bei hoher Netzauslastung steigt die Wahrscheinlichkeit, dass mehrere Geräte gleichzeitig senden, was zu mehr Kollisionen führt\n- **Wiederholte Übertragungen:** Jede Kollision erfordert, dass die betroffenen Geräte ihre Übertragung abbrechen und nach einer zufälligen Wartezeit erneut versuchen\n- **Exponentieller Backoff:** Bei wiederholten Kollisionen verlängert sich die Wartezeit exponentiell (Binary Exponential Backoff), was zu längeren Verzögerungen führt\n- **Skalierungsproblem:** Konfliktbasierte Systeme wie CSMA/CD haben Schwierigkeiten, bei starker Mediennutzung zu skalieren\n- **Historischer Kontext:** Dieses Problem war ein wichtiger Grund für den Übergang von Hubs zu Switches in Ethernet-Netzwerken"
            },
        {
            "question": "Welche drei Hauptteile sind in jedem Frame der Sicherungsschicht enthalten? 🖥️",
            "options": [
            "Header, Daten, Footer",
            "Header, Daten, Trailer",
            "Start, Mitte, Ende",
            "Paket, Segment, Daten"
            ],
            "correct": 1,
            "explain": "Jeder Frame der Sicherungsschicht besteht aus drei Hauptteilen: **Header**, **Daten** und **Trailer**. \n\nDer Header enthält Steuerinformationen wie Start-Flags, Adressierung und Typinformationen. Der Datenbereich enthält die Nutzdaten, die von höheren Schichten kommen (typischerweise ein IP-Paket). Der Trailer befindet sich am Ende des Frames und enthält unter anderem Informationen zur Fehlererkennung (wie die FCS - Frame Check Sequence) und Stopp-Flags. Diese Struktur ist charakteristisch für die Sicherungsschicht und unterscheidet sie von anderen Protokollschichten, die in der Regel nur Headerdaten hinzufügen."
        },
        {
            "question": "Was ist die primäre Aufgabe der Sicherungsschicht im OSI-Modell? 🌐",
            "options": [
            "Logische Adressierung von Geräten im Internet",
            "Übersetzung von Domain-Namen in IP-Adressen",
            "Vorbereitung von Daten für den Transport über lokale Medien",
            "Ende-zu-Ende-Verbindung zwischen Anwendungen"
            ],
            "correct": 2,
            "explain": "Die primäre Aufgabe der Sicherungsschicht (Layer 2) im OSI-Modell ist die **Vorbereitung von Daten für den Transport über lokale Medien**. \n\nDie Sicherungsschicht kapselt die bereits gekapselten Daten (typischerweise IPv4- oder IPv6-Pakete) durch Hinzufügen eines Headers und eines Trailers für den Transport über das physische Medium. Sie ist für die NIC-zu-NIC-Kommunikation innerhalb desselben Netzwerks verantwortlich und stellt sicher, dass Daten zuverlässig zwischen direkt verbundenen Geräten übertragen werden. Funktionen wie logische Adressierung gehören zur Netzwerkschicht (Layer 3), DNS-Auflösung zur Anwendungsschicht und Ende-zu-Ende-Verbindungen zur Transportschicht."
        },
        {
            "question": "Eine CRC-Prüfsumme wird im Frame typischerweise wo gespeichert? 🔒",
            "options": [
            "Im Header unter dem Adressierungsfeld",
            "Im Datenfeld zwischen Nutzdaten",
            "Im Trailer als Teil des FCS-Feldes",
            "Als separater Frame nach dem eigentlichen Datenframe"
            ],
            "correct": 2,
            "explain": "Die CRC-Prüfsumme (Cyclic Redundancy Check) wird typischerweise **im Trailer als Teil des FCS-Feldes** (Frame Check Sequence) gespeichert. \n\nDer übertragende Knoten erstellt eine logische Zusammenfassung des Frame-Inhalts, die als CRC-Prüfsumme bekannt ist. Diese Prüfsumme wird im FCS-Feld im Trailer platziert. Der Empfängerknoten nutzt diese Information, um zu überprüfen, ob bei der Übertragung Fehler aufgetreten sind. Die Fehlererkennung ist eine wichtige Funktion der Sicherungsschicht, da Signale auf dem Medium Störungen, Verzerrungen oder Verluste erfahren können, die die Bit-Werte signifikant verändern könnten. Diese Platzierung im Trailer ermöglicht es, den gesamten vorherigen Frame-Inhalt (einschließlich Header und Daten) in die Prüfsummenberechnung einzubeziehen."
        },
        {
            "question": "Welche Aussage über Layer-2-Adressen (physische Adressen) ist korrekt? 🔍",
            "options": [
            "Sie ändern sich, wenn ein Gerät in ein anderes Netzwerk verschoben wird",
            "Sie sind hierarchisch wie IP-Adressen organisiert",
            "Sie werden hauptsächlich für die Zustellung außerhalb des lokalen Netzwerks verwendet",
            "Sie bleiben gleich, auch wenn das Gerät Teil eines anderen Netzwerks wird"
            ],
            "correct": 3,
            "explain": "Die korrekte Aussage ist, dass Layer-2-Adressen (physische Adressen) **gleich bleiben, auch wenn das Gerät Teil eines anderen Netzwerks wird**. \n\nIm Gegensatz zu logischen Adressen in Schicht 3 (IP-Adressen), die hierarchisch organisiert sind, geben physische Adressen keine Auskunft darüber, in welchem Netzwerk sich das Gerät befindet. Die physische Adresse ist für das bestimmte Gerät eindeutig und ändert sich nicht, wenn das Gerät in ein anderes Netzwerk oder Subnetz wechselt. Diese Eigenschaft der Layer-2-Adressen zeigt, dass sie nur zur Identifizierung von Geräten innerhalb desselben gemeinsam genutzten Mediums im selben IP-Netzwerk dienen und keine Bedeutung für die Weiterleitung außerhalb des lokalen Netzwerks haben."
        },
        {
            "question": "Der Router muss bei der Paketweiterleitung zwischen verschiedenen Netzwerksegmenten welche Operation durchführen? 💻",
            "options": [
            "Nur den Layer-2-Header ändern und weiterleiten",
            "Den Frame entkapseln, die IP-Adresse prüfen und einen neuen Frame erstellen",
            "Den Frame unverändert an das nächste Segment weiterleiten",
            "Ausschließlich die Quelladresse im Frame-Header aktualisieren"
            ],
            "correct": 1,
            "explain": "Beim Weiterleiten von Daten zwischen verschiedenen Netzwerksegmenten muss ein Router **den Frame entkapseln, die IP-Adresse prüfen und einen neuen Frame erstellen**. \n\nWenn Daten an ein anderes Netzwerksegment weitergeleitet werden müssen, muss der Router zunächst den Frame basierend auf der physischen (Layer-2) Adresse annehmen. Dann muss er den Frame entkapseln, um die hierarchische IP-Adresse zu untersuchen. Anhand dieser IP-Adresse kann der Router die Netzwerkadresse des Zielgeräts und den besten Pfad dorthin ermitteln. Nach dieser Entscheidung erstellt der Router einen vollständig neuen Frame für das Paket mit neuen Layer-2-Adressinformationen, passend für das nächste Netzwerksegment. Dieser Prozess des Entkapselns und Neuverpackens ist notwendig, da Layer-2-Adressen nur lokale Bedeutung haben und sich die physischen Adressierungsinformationen zwischen verschiedenen Netzwerksegmenten unterscheiden."
        },
        {
            "question": "Was ist ein wesentlicher Unterschied zwischen LAN- und traditionellen WAN-Protokollen der Sicherungsschicht? 🌍",
            "options": [
            "LAN-Protokolle verwenden keine physischen Adressen, WAN-Protokolle schon",
            "WAN-Protokolle bieten in der Regel eine höhere Bandbreite als LAN-Protokolle",
            "LANs verwenden typischerweise Technologien mit höherer Bandbreite als WANs",
            "WAN-Protokolle unterstützen mehr Hosts als LAN-Protokolle"
            ],
            "correct": 2,
            "explain": "Ein wesentlicher Unterschied zwischen LAN- und traditionellen WAN-Protokollen der Sicherungsschicht ist, dass **LANs typischerweise Technologien mit höherer Bandbreite als WANs verwenden**. \n\nEin LAN verwendet in der Regel eine Technologie mit hoher Bandbreite, die eine große Anzahl von Hosts unterstützt. Der relativ kleine geografische Bereich eines LANs (ein einzelnes oder mehrere Gebäude) und die hohe Anzahl von Benutzern machen diese Hochgeschwindigkeitstechnologien wirtschaftlich sinnvoll. Im Gegensatz dazu ist eine Technologie mit hoher Datenübertragungsrate für WANs, die große geografische Gebiete (z.B. Städte oder mehrere Städte) abdecken, traditionell teurer. Die Kosten für physische Fernverbindungen und die zur Übertragung der Signale über diese Entfernungen verwendete Technologie führen in der Regel zu einer geringeren verfügbaren Bandbreite. Dieser Unterschied in der Datenübertragungsrate führt normalerweise zum Einsatz unterschiedlicher Protokolle für LANs und WANs."
        },
        {
            "question": "Welches der folgenden Protokolle wird NICHT als typisches Protokoll der Sicherungsschicht aufgeführt? 📚",
            "options": [
            "Ethernet",
            "Frame Relay",
            "TCP/IP",
            "Point-to-Point Protocol (PPP)"
            ],
            "correct": 2,
            "explain": "Von den genannten Optionen wird **TCP/IP** NICHT als typisches Protokoll der Sicherungsschicht aufgeführt. \n\nTCP/IP ist tatsächlich eine Protokollsuite, bei der TCP ein Transportschichtprotokoll (Layer 4) und IP ein Netzwerkschichtprotokoll (Layer 3) ist. Sie operieren nicht auf der Sicherungsschicht (Layer 2). Die anderen genannten Protokolle - Ethernet, Frame Relay und Point-to-Point Protocol (PPP) - sind allesamt Protokolle der Sicherungsschicht, die für verschiedene Netzwerkumgebungen und -topologien entwickelt wurden. Ethernet wird typischerweise in LANs verwendet, während Frame Relay und PPP traditionell in WAN-Umgebungen eingesetzt wurden, obwohl heutzutage Ethernet auch im WAN-Bereich zunehmend verbreitet ist."
        },
        {
            "question": "In der Frame-Struktur der Sicherungsschicht identifiziert welches Feld das Layer-3-Protokoll im Datenfeld? 📋",
            "options": [
            "Start-Flag",
            "Adressierungsfeld",
            "Typfeld",
            "Steuerungsfeld"
            ],
            "correct": 2,
            "explain": "In der Frame-Struktur der Sicherungsschicht identifiziert das **Typfeld** das Layer-3-Protokoll im Datenfeld. \n\nDas Typfeld im Header eines Frames der Sicherungsschicht gibt an, welches Protokoll der höheren Ebene (typischerweise der Netzwerkschicht/Layer 3) im Datenfeld des Frames enthalten ist. Diese Information ist wichtig, damit der Empfänger nach dem Entpacken des Frames weiß, wie die Daten weiterverarbeitet werden sollen. Zum Beispiel könnte das Typfeld angeben, dass es sich bei den Daten um ein IPv4-Paket, ein IPv6-Paket oder ein ARP-Paket handelt. In Ethernet-Frames wird dieses Feld oft als EtherType bezeichnet und verwendet einen 16-Bit-Wert, um das Protokoll zu identifizieren (z.B. 0x0800 für IPv4, 0x86DD für IPv6)."
        },
        {
            "question": "Welches dieser Geräte arbeitet NICHT als Knoten auf der Sicherungsschicht? 🖧",
            "options": [
            "Netzwerkkarten auf Computern",
            "Ein DNS-Server",
            "Schnittstellen auf Routern",
            "Layer-2-Switches"
            ],
            "correct": 1,
            "explain": "Von den genannten Optionen arbeitet ein **DNS-Server** NICHT als Knoten auf der Sicherungsschicht. \n\nEin DNS-Server ist ein Dienst, der auf der Anwendungsschicht (Layer 7) des OSI-Modells operiert und für die Auflösung von Domainnamen in IP-Adressen zuständig ist. Im Gegensatz dazu sind Netzwerkkarten auf Computern, Schnittstellen auf Routern und Layer-2-Switches Geräte, die direkt als Knoten auf der Sicherungsschicht arbeiten. Diese Geräte führen Medienzugriffssteuerung für logische Schicht-2-Topologien aus und nutzen Layer-2-Protokolle für die Kommunikation. Sie verarbeiten Frames direkt auf der Sicherungsschicht und sind für die Adressierung, Fehlererkennung und Zustellungsprozesse auf dieser Schicht verantwortlich."
        },
        {
            "question": "IP-Pakete bleiben von Quelle bis Ziel unverändert, während Layer-2-Frames bei jedem Hop neu erstellt werden.",
            "options": ["Wahr", "Falsch"],
            "correct": 0,
            "explain": "Diese Aussage ist **wahr**. \n\nWährend ein IP-Paket vom Quell-Host zum Ziel-Host übertragen wird, bleibt der Paket-Header unverändert, unabhängig von der Anzahl der Hops entlang des Weges. Die Quell- und Ziel-IP-Adressen im IP-Header ändern sich nicht. Im Gegensatz dazu werden Layer-2-Frames an jedem Hop neu erstellt. Wenn ein Router ein Paket von einem Netzwerksegment zu einem anderen weiterleitet, muss er den empfangenen Frame entkapseln, die IP-Adresse untersuchen und dann einen völlig neuen Frame mit neuen Layer-2-Adressinformationen für das nächste Segment erstellen. Die Layer-2-Adressen werden nur für die lokale Zustellung verwendet und haben außerhalb des lokalen Netzwerks keine Bedeutung. Deshalb ändert sich die Frame-Einhüllung bei jedem Hop, während das IP-Paket selbst intakt bleibt."
        },
        {
            "question": "Eine instabile Netzwerkumgebung erfordert Frame-Strukturen mit weniger Steuerinformationen im Vergleich zu stabilen Umgebungen.",
            "options": ["Wahr", "Falsch"],
            "correct": 1,
            "explain": "Diese Aussage ist **falsch**. \n\nIn Wirklichkeit erfordert eine instabile Netzwerkumgebung Frame-Strukturen mit **mehr** Steuerinformationen im Vergleich zu stabilen Umgebungen, nicht weniger. In instabilen Umgebungen sind mehr Steuerelemente nötig, um den zuverlässigen Datentransport zu gewährleisten. Die Header- und Trailer-Felder sind größer, da sie mehr Steuerinformationen enthalten müssen. Dies führt zu einem größeren Overhead und in der Folge zu langsameren Übertragungsraten. Ein Beispiel hierfür ist ein WLAN-Frame, der zusätzliche Prozeduren zur Kollisionsvermeidung enthalten muss und daher mehr Steuerinformationen benötigt als ein Ethernet-Frame in einer stabileren kabelgebundenen Umgebung."
        },
        {
            "question": "Die logische Adresse in Schicht 3 gibt Auskunft darüber, in welchem Netzwerk sich ein Gerät befindet.",
            "options": ["Wahr", "Falsch"],
            "correct": 0,
            "explain": "Diese Aussage ist **wahr**. \n\nLogische Adressen in Schicht 3 (IP-Adressen) sind hierarchisch aufgebaut und geben Auskunft darüber, in welchem Netzwerk sich ein Gerät befindet. Eine IP-Adresse besteht aus einem Netzwerkteil und einem Hostteil, wobei der Netzwerkteil das spezifische Netzwerk identifiziert, zu dem das Gerät gehört. Diese hierarchische Struktur ermöglicht effizientes Routing zwischen verschiedenen Netzwerken. Im Gegensatz dazu geben physische Adressen in Schicht 2 keine Auskunft über das Netzwerk des Geräts. Sie sind für das jeweilige Gerät eindeutig, ändern sich aber nicht, wenn das Gerät Teil eines anderen Netzwerks wird. Daher werden Layer-2-Adressen nur für die Kommunikation innerhalb desselben lokalen Netzwerks verwendet."
        },
        {
            "question": "Quality of Service (QoS) wird im Steuerungsfeld des Frame-Headers implementiert.",
            "options": ["Wahr", "Falsch"],
            "correct": 0,
            "explain": "Diese Aussage ist **wahr**. \n\nQuality of Service (QoS) wird im Steuerungsfeld des Frame-Headers implementiert. Das Steuerungsfeld identifiziert spezielle Flusskontrolldienste wie QoS, die den Weiterleitungsvorrang für bestimmte Arten von Nachrichten bestimmen. Beispielsweise erhalten VoIP-Frames (Voice over IP) normalerweise eine höhere Priorität, da sie verzögerungsempfindlich sind und eine verzögerte Übertragung die Sprachqualität erheblich beeinträchtigen würde. Die QoS-Informationen im Steuerungsfeld ermöglichen es Netzwerkgeräten, wichtigen Datenverkehr zu identifizieren und entsprechend zu priorisieren, was besonders in Netzwerken mit begrenzter Bandbreite oder bei Überlastung wichtig ist."
        },
        {
            "question": "Ein FCS-Feld im Trailer eines Frames hat hauptsächlich die Funktion, die Adresse des nächsten Hops zu identifizieren.",
            "options": ["Wahr", "Falsch"],
            "correct": 1,
            "explain": "Diese Aussage ist **falsch**. \n\nDas FCS-Feld (Frame Check Sequence) im Trailer eines Frames dient **nicht** dazu, die Adresse des nächsten Hops zu identifizieren. Die Hauptfunktion des FCS-Feldes besteht in der Fehlererkennung. Es enthält eine CRC-Prüfsumme (Cyclic Redundancy Check), die vom sendenden Knoten durch eine logische Zusammenfassung des Frame-Inhalts erstellt wird. Der empfangende Knoten berechnet dieselbe Prüfsumme und vergleicht sie mit dem Wert im FCS-Feld. Bei Übereinstimmung wird angenommen, dass der Frame ohne Übertragungsfehler empfangen wurde. Bei Nichtübereinstimmung wird der Frame als beschädigt betrachtet und normalerweise verworfen. Die Adressierung des nächsten Hops wird hingegen durch die Zieladresse im Header des Frames bestimmt, nicht durch das FCS-Feld im Trailer."
        },
        {
            "question": "In welcher Situation ist der Overhead in der Framestruktur typischerweise am größten? 🚀",
            "options": [
            "Bei der Übertragung in einem stabilen kabelgebundenen LAN",
            "Bei der Übertragung über eine Satellitenverbindung in einem WAN",
            "Bei der Kommunikation zwischen zwei Computern im selben Ethernet-Segment",
            "Bei der Übertragung innerhalb eines modernen Datacenter-Netzwerks"
            ],
            "correct": 1,
            "explain": "Der Overhead in der Framestruktur ist typischerweise **bei der Übertragung über eine Satellitenverbindung in einem WAN** am größten. \n\nIn instabilen oder herausfordernden Übertragungsumgebungen wie Satellitenverbindungen sind mehr Steuerelemente nötig, um den Datentransport zuverlässig zu gewährleisten. Dies führt zu größeren Header- und Trailer-Feldern, da mehr Steuerinformationen für Fehlerkorrektur, Wiederholungsanfragen und Synchronisation benötigt werden. Der daraus resultierende größere Overhead führt zu langsameren effektiven Übertragungsraten. Im Vergleich dazu benötigen stabile Umgebungen wie kabelgebundene LANs oder Datacenter-Netzwerke weniger Steuerinformationen und haben daher einen geringeren Overhead in ihren Framestrukturen, was zu effizienteren Datenübertragungen führt."
        },
        {
            "question": "Welches Feld im Frame-Header ermöglicht es einer NIC, schnell zu bestimmen, ob ein Frame für sie bestimmt ist? 💡",
            "options": [
            "Das Typfeld",
            "Das Steuerungsfeld",
            "Das Adressierungsfeld",
            "Das Frame-Start-Feld"
            ],
            "correct": 2,
            "explain": "Das **Adressierungsfeld** im Frame-Header ermöglicht es einer NIC (Network Interface Card), schnell zu bestimmen, ob ein Frame für sie bestimmt ist. \n\nDie Adressierung der Sicherungsschicht befindet sich in der Regel am Anfang des Frame-Headers, sodass die NIC schnell feststellen kann, ob die Zieladresse mit ihrer eigenen Layer-2-Adresse übereinstimmt, bevor sie den Rest des Frames akzeptiert und verarbeitet. Diese Platzierung ist bewusst gewählt, um die Effizienz zu steigern - jede NIC kann so schnell entscheiden, ob sie den Frame ignorieren kann oder weiter verarbeiten muss, ohne den gesamten Frame empfangen zu müssen. Das Adressierungsfeld enthält sowohl die Zieladresse als auch die Quelladresse des Frames, wobei die Zieladresse für die Filterfunktion der empfangenden NICs entscheidend ist."
        },
        {
            "question": "Welches der folgenden Protokolle ersetzt zunehmend traditionelle WAN-Protokolle in modernen Netzwerken? 🔄",
            "options": [
            "Frame Relay",
            "Ethernet",
            "ATM (Asynchroner Übertragungsmodus)",
            "X.25"
            ],
            "correct": 1,
            "explain": "**Ethernet** ersetzt zunehmend traditionelle WAN-Protokolle in modernen Netzwerken. \n\nWährend traditionelle WANs verschiedene spezialisierte Protokolltypen für unterschiedliche Topologien verwendet haben (wie Point-to-Point Protocol, HDLC, Frame Relay, ATM und X.25), werden diese Layer-2-Protokolle im WAN-Bereich zunehmend durch Ethernet ersetzt. Diese Entwicklung wird oft als \"Ethernet im WAN\" oder \"Carrier Ethernet\" bezeichnet. Die Popularität von Ethernet für WAN-Verbindungen steigt, da es kostengünstiger sein kann, einfacher zu implementieren ist und eine konsistente Protokollverwendung über verschiedene Netzwerkbereiche (LAN und WAN) ermöglicht. Diese Konvergenz reduziert die Komplexität und vereinfacht die Netzwerkverwaltung."
        },
        {
            "question": "Was ist die Konsequenz der Verwendung zusätzlicher Steuerinformationen in Frames in instabilen Netzwerkumgebungen? 📉",
            "options": [
            "Erhöhte Datenübertragungsrate",
            "Reduzierter Energieverbrauch",
            "Verminderter Overhead",
            "Langsamere Übertragungsraten"
            ],
            "correct": 3,
            "explain": "Die Konsequenz der Verwendung zusätzlicher Steuerinformationen in Frames in instabilen Netzwerkumgebungen sind **langsamere Übertragungsraten**. \n\nIn instabilen Umgebungen sind mehr Steuerelemente nötig, um den Transport zu gewährleisten. Diese zusätzlichen Steuerinformationen vergrößern die Header- und Trailer-Felder der Frames, was zu einem erhöhten Overhead führt. Ein größerer Overhead bedeutet, dass ein geringerer Anteil der übertragenen Bits tatsächliche Nutzdaten sind, während ein größerer Anteil für Kontrollinformationen verwendet wird. Das Ergebnis sind langsamere effektive Übertragungsraten für die eigentlichen Daten. Es ist ein Kompromiss zwischen Zuverlässigkeit und Effizienz - in instabilen Umgebungen wird mehr Bandbreite für Kontrollinformationen geopfert, um die zuverlässige Datenübertragung zu gewährleisten."
        },
        {
        "question": "Ein Netzwerktechniker untersucht einen Ethernet-Frame und stellt fest, dass im 2-Byte-Feld nach der Quell-MAC-Adresse der hexadezimale Wert 0x86DD steht. Welches Protokoll wird im Frame gekapselt?",
        "options": [
            "IPv4",
            "IPv6",
            "ARP",
            "ICMP"
        ],
        "correct": 1,
        "explain": "Der hexadezimale Wert **0x86DD** im Typ/Länge-Feld eines Ethernet-Frames identifiziert **IPv6** als das gekapselte Protokoll der nächsthöheren Schicht.\n\nDie gängigen EtherType-Werte sind:\n- **0x800** für IPv4\n- **0x86DD** für IPv6\n- **0x806** für ARP (Address Resolution Protocol)\n\nDieses 2-Byte-Feld ist entscheidend für die Netzwerkschnittstelle, um zu wissen, an welches Protokoll auf höherer Ebene die Daten weitergeleitet werden sollen."
    },
    {
        "question": "Ein Netzwerkanalysator zeigt an, dass ein Ethernet-Frame 1600 Bytes Nutzdaten transportiert. Ist dieser Frame gültig?",
        "options": ["Wahr", "Falsch"],
        "correct": 1,
        "explain": "Diese Aussage ist **falsch**. Ein Standard-Ethernet-Frame kann maximal **1500 Bytes** im Datenfeld transportieren.\n\nEin Ethernet-Frame mit 1600 Bytes Nutzdaten würde die maximale Standard-Größe überschreiten und als \"Jumbo Frame\" oder \"Baby Giant Frame\" klassifiziert werden. Solche überdimensionierten Frames werden von Standard-Ethernet-Implementierungen normalerweise verworfen, es sei denn, die Netzwerkinfrastruktur unterstützt explizit Jumbo-Frames. Die meisten Fast Ethernet- und Gigabit-Ethernet-Switches und Netzwerkkarten unterstützen heutzutage zwar Jumbo-Frames, aber es ist wichtig, dass alle Geräte im Netzwerkpfad diese Funktionalität unterstützen, damit die Kommunikation erfolgreich ist."
    },
    {
        "question": "Bei der Analyse eines Netzwerkverkehrs wird ein Frame mit nur 60 Bytes (ohne Präambel und SFD) identifiziert. Wie wird ein solcher Frame vom Empfänger behandelt?",
        "options": [
            "Er wird normal verarbeitet, da er innerhalb der gültigen Größenbeschränkungen liegt",
            "Er wird automatisch als Kollisionsfragment verworfen",
            "Er wird akzeptiert, aber mit einer Warnmeldung markiert",
            "Er wird als prioritärer Frame behandelt"
        ],
        "correct": 1,
        "explain": "Ein Ethernet-Frame mit nur 60 Bytes (ohne Präambel und SFD) liegt **unter der Mindestgröße von 64 Bytes** und wird daher **automatisch als Kollisionsfragment (\"Runt Frame\") verworfen**.\n\nDie minimale Ethernet-Frame-Größe beträgt 64 Bytes, gemessen von der Ziel-MAC-Adresse bis zur Frame Check Sequence (FCS). Frames, die kleiner als diese Mindestgröße sind, werden als ungültig betrachtet und vom Empfänger verworfen. Diese Mindestgröße wurde entwickelt, um sicherzustellen, dass Kollisionen in älteren halbduplex Ethernet-Netzwerken zuverlässig erkannt werden können.\n\nWenn Nutzdaten nicht ausreichen, um die Mindestgröße zu erreichen, werden zusätzliche Bits (Padding) hinzugefügt, um den Frame auf 64 Bytes zu vergrößern."
    },
    {
        "question": "Der FCS-Wert (Frame Check Sequence) in einem Ethernet-Frame wird vom Empfänger neu berechnet und mit dem empfangenen Wert verglichen. Was passiert, wenn diese beiden Werte nicht übereinstimmen?",
        "options": [
            "Der Frame wird trotzdem verarbeitet, aber eine Warnmeldung wird generiert",
            "Der Frame wird verworfen",
            "Der Empfänger fordert automatisch eine erneute Übertragung an",
            "Der Frame wird an einen alternativen Pfad weitergeleitet"
        ],
        "correct": 1,
        "explain": "Wenn der neu berechnete FCS-Wert nicht mit dem empfangenen FCS-Wert übereinstimmt, **wird der Frame verworfen**.\n\nDer 4-Byte FCS-Wert (Frame Check Sequence) wird verwendet, um Fehler in einem Ethernet-Frame zu erkennen. Er basiert auf einer zyklischen Redundanzprüfung (CRC):\n\n1. Der Sender berechnet einen CRC-Wert über den gesamten Frame und fügt diesen in das FCS-Feld ein\n2. Der Empfänger führt dieselbe Berechnung durch und vergleicht das Ergebnis mit dem empfangenen FCS-Wert\n3. Wenn die Werte übereinstimmen, wird davon ausgegangen, dass der Frame intakt ist\n4. Bei Nichtübereinstimmung wird angenommen, dass der Frame während der Übertragung beschädigt wurde\n\nDiese Beschädigung könnte durch elektrische Störsignale oder andere Übertragungsprobleme verursacht worden sein. Die Ethernet-Spezifikation sieht vor, dass fehlerhafte Frames verworfen werden, ohne dass eine automatische Neuübertragung angefordert wird. Protokolle höherer Schichten (wie TCP) sind für die Behandlung solcher Fehler zuständig."
    },
    {
        "question": "In einem modernen Ethernet-LAN mit Switches, die im Vollduplex-Modus arbeiten, ist das CSMA/CD-Zugriffsverfahren immer noch notwendig.",
        "options": ["Wahr", "Falsch"],
        "correct": 1,
        "explain": "Diese Aussage ist **falsch**. In modernen Ethernet-LANs mit Switches im Vollduplex-Betrieb ist das CSMA/CD-Zugriffsverfahren **nicht mehr notwendig**.\n\nCSMA/CD (Carrier Sense Multiple Access/Collision Detection) wurde für Legacy-Ethernet mit Bustopologie oder Hubs entwickelt, die ein gemeinsames, halbduplexes Medium nutzen. In dieser Umgebung:\n- Konnte nur ein Gerät zur Zeit senden\n- Mussten Kollisionen erkannt werden, wenn mehrere Geräte gleichzeitig zu senden versuchten\n- War ein Back-Off-Algorithmus für die Wiederholung der Übertragung erforderlich\n\nModerne Ethernet-LANs verwenden jedoch Switches, die eine direkte, dedizierte Verbindung zwischen Kommunikationspartnern herstellen und im Vollduplex-Modus arbeiten. Dies bedeutet:\n- Geräte können gleichzeitig senden und empfangen\n- Es gibt keine Kollisionen mehr auf dem Medium\n- Der CSMA/CD-Mechanismus wird nicht mehr benötigt\n\nDies ist ein wichtiger Unterschied zwischen modernem geswitchtem Ethernet und älteren Ethernet-Implementierungen."
    },
    {
        "question": "Welches Feld im Ethernet-Frame wird verwendet, um festzustellen, ob ein Datagramm für IPv4, IPv6 oder ein anderes Protokoll bestimmt ist?",
        "options": [
            "Das Präambel-Feld",
            "Das Ziel-MAC-Adressfeld",
            "Das Typ/Länge-Feld",
            "Das FCS-Feld"
        ],
        "correct": 2,
        "explain": "Das **Typ/Länge-Feld** im Ethernet-Frame identifiziert das Protokoll der nächsthöheren Schicht.\n\nDieses 2-Byte-Feld (auch als EtherType bezeichnet) enthält einen hexadezimalen Wert, der angibt, welches Protokoll in den Nutzdaten gekapselt ist. Einige häufige Werte sind:\n\n- **0x800** für IPv4\n- **0x86DD** für IPv6\n- **0x806** für ARP (Address Resolution Protocol)\n\nDie anderen Felder haben unterschiedliche Funktionen:\n- Das Präambel-Feld dient zur Synchronisation zwischen Sender und Empfänger\n- Das Ziel-MAC-Adressfeld identifiziert den beabsichtigten Empfänger auf Layer 2\n- Das FCS-Feld (Frame Check Sequence) wird zur Fehlererkennung verwendet\n\nDas Typ/Länge-Feld ist entscheidend für die Weiterverarbeitung der Daten, da es dem empfangenden Gerät mitteilt, an welches Protokoll der höheren Schicht die Daten weitergeleitet werden sollen."
    },
    {
        "question": "Ein Netzwerkadministrator analysiert Ethernet-Frames und findet einen Frame mit 1518 Bytes (ohne Präambel und SFD). Wie ist dieser Frame zu klassifizieren?",
        "options": [
            "Als ungültiger Frame, da er zu groß ist",
            "Als Standard-Frame innerhalb der maximalen Größenbeschränkung",
            "Als Jumbo-Frame",
            "Als Kollisionsfragment"
        ],
        "correct": 1,
        "explain": "Ein Ethernet-Frame mit 1518 Bytes (ohne Präambel und SFD) ist ein **Standard-Frame innerhalb der maximalen Größenbeschränkung**.\n\nDie Größenbeschränkungen für Ethernet-Frames sind:\n- **Minimale Größe**: 64 Bytes\n- **Maximale Standard-Größe**: 1518 Bytes\n\nBei der Berechnung der Frame-Größe werden alle Bytes von der Ziel-MAC-Adresse bis zur Frame Check Sequence (FCS) gezählt, aber das Präambel-Feld und der Start Frame Delimiter (SFD) werden **nicht** einbezogen.\n\nDaher ist ein Frame mit 1518 Bytes (ohne Präambel und SFD) genau an der oberen Grenze der standardmäßigen Ethernet-Frame-Größe und wird als gültiger Standard-Frame betrachtet. Erst wenn ein Frame mehr als 1518 Bytes hätte oder seine Nutzdaten mehr als 1500 Bytes umfassen würden, würde er als Jumbo-Frame oder Baby Giant Frame klassifiziert werden."
    },
    {
        "question": "Wenn ein IPv4-Paket nur 30 Bytes Daten enthält und in einen Ethernet-Frame gekapselt wird, was geschieht mit der Größe des Frames?",
        "options": [
            "Der Frame wird genau 30 Bytes groß sein",
            "Der Frame wird mit dem IPv4-Header genau 50 Bytes groß sein",
            "Der Frame wird mit zusätzlichen Bits aufgefüllt, um die Mindestgröße von 64 Bytes zu erreichen",
            "Der Frame wird automatisch fragmentiert"
        ],
        "correct": 2,
        "explain": "Wenn ein IPv4-Paket nur 30 Bytes Daten enthält und in einen Ethernet-Frame gekapselt wird, **wird der Frame mit zusätzlichen Bits aufgefüllt, um die Mindestgröße von 64 Bytes zu erreichen**.\n\nEin typisches IPv4-Paket mit 30 Bytes Daten würde bestehen aus:\n- IPv4-Header: 20 Bytes (minimal)\n- Daten: 30 Bytes\n- Gesamt: 50 Bytes\n\nBei der Kapselung in einen Ethernet-Frame kommen hinzu:\n- Ziel-MAC-Adresse: 6 Bytes\n- Quell-MAC-Adresse: 6 Bytes\n- Typ/Länge-Feld: 2 Bytes\n- IPv4-Paket: 50 Bytes\n- FCS: 4 Bytes\n- Gesamt: 68 Bytes\n\nDa die Mindestgröße eines Ethernet-Frames 64 Bytes beträgt, muss in diesem Fall kein Padding hinzugefügt werden. Wäre das IPv4-Paket jedoch kleiner, würde der resultierende Ethernet-Frame mit zusätzlichen Bits (Padding) aufgefüllt werden, um die erforderliche Mindestgröße zu erreichen. Diese Mindestgröße ist wichtig für die zuverlässige Erkennung von Kollisionen in halbduplex Ethernet-Umgebungen."
    },
    {
        "question": "Welche maximale Datenübertragungsrate wird derzeit von den Ethernet-Standards unterstützt?",
        "options": [
            "10 Gbit/s",
            "40 Gbit/s",
            "100 Gbit/s",
            "1000 Gbit/s"
        ],
        "correct": 2,
        "explain": "Die derzeit höchste von den Ethernet-Standards unterstützte Datenübertragungsrate beträgt **100 Gbit/s** (100.000 Mbit/s).\n\nDie Ethernet-Technologie hat im Laufe der Zeit verschiedene Geschwindigkeitsstufen entwickelt:\n\n- 10 Mbit/s (ursprüngliches Ethernet)\n- 100 Mbit/s (Fast Ethernet)\n- 1.000 Mbit/s (1 Gbit/s, Gigabit Ethernet)\n- 10.000 Mbit/s (10 Gbit/s)\n- 40.000 Mbit/s (40 Gbit/s)\n- 100.000 Mbit/s (100 Gbit/s)\n\nDie Standards für 100 Gbit/s Ethernet sind bereits etabliert und werden in Hochleistungsnetzwerken, Rechenzentren und Backbone-Infrastrukturen eingesetzt. Standards für noch höhere Geschwindigkeiten (wie 200 Gbit/s und 400 Gbit/s) sind in der Entwicklung oder wurden möglicherweise nach dem Erstellungsdatum dieses Materials eingeführt."
    },
    {
        "question": "Die Präambel eines Ethernet-Frames enthält Informationen über das gekapselte Protokoll der höheren Schicht.",
        "options": ["Wahr", "Falsch"],
        "correct": 1,
        "explain": "Diese Aussage ist **falsch**. Die Präambel eines Ethernet-Frames enthält **keine** Informationen über das gekapselte Protokoll der höheren Schicht.\n\nDie Präambel (7 Bytes) und der Start Frame Delimiter (SFD, 1 Byte) dienen ausschließlich zur **Synchronisation** zwischen dem sendenden und dem empfangenden Gerät. Sie bereiten den Empfänger auf die Ankunft eines neuen Frames vor, indem sie ihm signalisieren, dass Daten folgen werden.\n\nDie Information über das gekapselte Protokoll der höheren Schicht wird im **Typ/Länge-Feld** (auch als EtherType bezeichnet) übertragen, das sich nach den MAC-Adressen befindet. Dieses 2-Byte-Feld enthält hexadezimale Werte wie 0x800 für IPv4, 0x86DD für IPv6 oder 0x806 für ARP."
    },
    {
        "question": "Ein Systemadministrator untersucht eine Netzwerkverbindung und stellt fest, dass sie mit 'IEEE 802.3ab' bezeichnet wird. Um welche Art von Verbindung handelt es sich?",
        "options": [
            "Fast Ethernet über Kupfer",
            "Gigabit Ethernet über Fiber",
            "Gigabit Ethernet über Kupfer",
            "10 Gigabit Ethernet über Fiber"
        ],
        "correct": 2,
        "explain": "Die Bezeichnung **IEEE 802.3ab** steht für **Gigabit Ethernet über Kupfer**, auch bekannt als 1000BASE-T.\n\nDie verschiedenen IEEE 802.3-Standards bezeichnen unterschiedliche Ethernet-Implementierungen:\n\n- **IEEE 802.3u**: Fast Ethernet (100 Mbit/s)\n- **IEEE 802.3z**: Gigabit Ethernet über Glasfaser (1000BASE-X)\n- **IEEE 802.3ab**: Gigabit Ethernet über Kupfer (1000BASE-T)\n- **IEEE 802.3ae**: 10 Gigabit Ethernet über Glasfaser\n\nDer Standard IEEE 802.3ab definiert die Übertragung von Gigabit Ethernet (1000 Mbit/s) über Kupferkabel, typischerweise Cat5e oder höher, mit einer maximalen Distanz von 100 Metern. Diese Technologie ist in modernen LANs weit verbreitet, da sie hohe Geschwindigkeiten über kostengünstige Twisted-Pair-Verkabelung ermöglicht."
    },
    {
        "question": "Ein Netzwerkingenieur gibt an, dass ein bestimmter Ethernet-Frame im LLC-Sublayer verarbeitet wird. Welche Funktion wird dabei durchgeführt?",
        "options": [
            "Die Erkennung von Kollisionen auf dem Medium",
            "Die Identifikation des verwendeten Vermittlungsschichtprotokolls",
            "Die Berechnung der Frame Check Sequence",
            "Die Bestimmung der MAC-Adressen"
        ],
        "correct": 1,
        "explain": "Im LLC-Sublayer (Logical Link Control) wird **die Identifikation des verwendeten Vermittlungsschichtprotokolls** durchgeführt.\n\nDer IEEE 802.2 LLC-Sublayer ist Teil der Sicherungsschicht und kommuniziert zwischen:\n- Der Netzwerksoftware auf den oberen Schichten\n- Der Gerätehardware in den unteren Schichten\n\nEine seiner Hauptfunktionen ist das Hinzufügen von Informationen in den Frame, die erkennen, welches Vermittlungsschichtprotokoll (Layer 3) für den Frame benutzt wird. Diese Identifikation ermöglicht es mehreren Layer-3-Protokollen (wie IPv4 und IPv6), dieselbe Netzwerkschnittstelle und dasselbe Medium zu verwenden.\n\nDie anderen Optionen beschreiben Funktionen, die hauptsächlich im MAC-Sublayer (Media Access Control) ausgeführt werden, wie die Adressierung auf dem Data-Link-Layer, die Medienzugriffskontrolle und die Fehlererkennung."
    },
    {
        "question": "Welches der folgenden Felder ist NICHT Teil eines Ethernet-Frames?",
        "options": [
            "Ziel-MAC-Adresse",
            "Quell-MAC-Adresse",
            "IP-Header",
            "Frame Check Sequence (FCS)"
        ],
        "correct": 2,
        "explain": "Der **IP-Header** ist **kein** direkter Bestandteil eines Ethernet-Frames, sondern Teil des gekapselten Protokolls der höheren Schicht (Layer 3).\n\nEin Standard-Ethernet-Frame besteht aus folgenden Feldern:\n1. Präambel und Start Frame Delimiter (SFD) - 8 Bytes\n2. Ziel-MAC-Adresse - 6 Bytes\n3. Quell-MAC-Adresse - 6 Bytes\n4. Typ/Länge-Feld - 2 Bytes\n5. Daten (enthält gekapselte Protokolle höherer Schichten) - 46-1500 Bytes\n6. Frame Check Sequence (FCS) - 4 Bytes\n\nDer IP-Header ist Teil des Datenfelds und gehört zur Vermittlungsschicht (Layer 3), nicht zur Sicherungsschicht (Layer 2), auf der Ethernet arbeitet. Der IP-Header ist in den Ethernet-Frame eingebettet (gekapselt), aber kein eigenes Feld des Ethernet-Frames selbst."
    },
    {
        "question": "Ein Frame mit einer Größe von 62 Bytes (ohne Präambel und SFD) wird über ein Ethernet-Netzwerk gesendet. Was geschieht mit diesem Frame?",
        "options": [
            "Er wird normal übertragen, da er innerhalb der gültigen Größenbegrenzungen liegt",
            "Er wird mit Padding-Bits auf 64 Bytes vergrößert und dann übertragen",
            "Er wird als ungültiger Frame verworfen",
            "Er wird fragmentiert und in mehreren kleineren Frames übertragen"
        ],
        "correct": 1,
        "explain": "Ein Frame mit einer Größe von 62 Bytes (ohne Präambel und SFD) **wird mit Padding-Bits auf 64 Bytes vergrößert und dann übertragen**.\n\nDie minimale Ethernet-Frame-Größe beträgt 64 Bytes (ohne Präambel und SFD). Dies ist eine feste Anforderung, die sicherstellt, dass:\n- Kollisionen in CSMA/CD-Netzwerken zuverlässig erkannt werden können\n- Die minimale Paketgröße für alle Ethernet-Implementierungen einheitlich ist\n\nWenn ein Frame die Mindestgröße unterschreitet (wie in diesem Fall 62 Bytes), werden automatisch zusätzliche Bits, sogenanntes Padding, hinzugefügt, um die Größe auf 64 Bytes zu erhöhen. Dieses Padding wird im Datenfeld angehängt und enthält keine nutzbaren Informationen.\n\nDer resultierende Frame mit 64 Bytes erfüllt dann die Mindestgröße und kann normal übertragen werden. Der Empfänger erkennt das Padding und verwirft es bei der Verarbeitung des Frames."
    },
    {
        "question": "Welcher Layer des OSI-Modells ist für die Adressierung mit MAC-Adressen zuständig?",
        "options": [
            "Bitübertragungsschicht (Layer 1)",
            "Sicherungsschicht (Layer 2)",
            "Vermittlungsschicht (Layer 3)",
            "Transportschicht (Layer 4)"
        ],
        "correct": 1,
        "explain": "Die **Sicherungsschicht (Layer 2)** des OSI-Modells ist für die Adressierung mit MAC-Adressen zuständig.\n\nDie verschiedenen Schichten haben unterschiedliche Adressierungsschemata:\n\n- **Bitübertragungsschicht (Layer 1)**: Beschäftigt sich mit der physischen Übertragung von Bits und verwendet keine eigene Adressierung\n- **Sicherungsschicht (Layer 2)**: Verwendet MAC-Adressen (Media Access Control) für die Kommunikation zwischen direkt verbundenen Geräten im selben Netzwerksegment\n- **Vermittlungsschicht (Layer 3)**: Verwendet logische Adressen wie IP-Adressen für die Kommunikation zwischen verschiedenen Netzwerken\n- **Transportschicht (Layer 4)**: Verwendet Portnummern zur Identifikation von Anwendungen\n\nIn der Sicherungsschicht, speziell im MAC-Sublayer, werden die 6-Byte (48-Bit) MAC-Adressen verwendet, um sowohl den Absender als auch den beabsichtigten Empfänger eines Ethernet-Frames zu identifizieren."
    },
    {
        "question": "Die maximale Größe des Datenfelds in einem Standard-Ethernet-Frame beträgt 1.500 Bytes.",
        "options": ["Wahr", "Falsch"],
        "correct": 0,
        "explain": "Diese Aussage ist **wahr**. Die maximale Größe des Datenfelds in einem Standard-Ethernet-Frame beträgt tatsächlich **1.500 Bytes**.\n\nDie Struktur eines Ethernet-Frames umfasst:\n- Präambel und SFD: 8 Bytes (werden bei der Frame-Größenberechnung nicht mitgezählt)\n- Ziel-MAC-Adresse: 6 Bytes\n- Quell-MAC-Adresse: 6 Bytes\n- Typ/Länge-Feld: 2 Bytes\n- **Datenfeld: 46-1.500 Bytes**\n- FCS: 4 Bytes\n\nDiese 1.500-Byte-Begrenzung des Datenfelds ist eine wichtige Konstante in Ethernet-Netzwerken und wird als Maximum Transmission Unit (MTU) bezeichnet. Sie begrenzt die Größe der Pakete höherer Protokollschichten, die ohne Fragmentierung in einem Ethernet-Frame transportiert werden können.\n\nBei Jumbo-Frames, die von vielen modernen Gigabit- und schnelleren Ethernet-Implementierungen unterstützt werden, kann diese Grenze auf bis zu 9.000 Bytes oder mehr erhöht werden, aber der Standard-Wert bleibt 1.500 Bytes."
    },
    {
        "question": "Bei einer Störung auf dem Übertragungsmedium wird ein Bit in einem Ethernet-Frame verfälscht. Welcher Mechanismus erkennt diesen Fehler?",
        "options": [
            "Der Start Frame Delimiter (SFD)",
            "Das Typ/Länge-Feld",
            "Die Frame Check Sequence (FCS)",
            "Die Ziel-MAC-Adresse"
        ],
        "correct": 2,
        "explain": "Der Mechanismus, der einen verfälschten Bit in einem Ethernet-Frame erkennt, ist die **Frame Check Sequence (FCS)**.\n\nDie Frame Check Sequence ist ein 4-Byte-Feld am Ende des Ethernet-Frames, das zur Fehlererkennung dient. Sie verwendet eine zyklische Redundanzprüfung (CRC, Cyclic Redundancy Check), um Übertragungsfehler aufzudecken:\n\n1. Der Sender berechnet den CRC-Wert über den gesamten Frame (von der Ziel-MAC-Adresse bis zum Ende des Datenfelds)\n2. Dieser berechnete Wert wird in das FCS-Feld am Ende des Frames eingefügt\n3. Der Empfänger führt dieselbe CRC-Berechnung durch und vergleicht das Ergebnis mit dem empfangenen FCS-Wert\n4. Wenn die Werte übereinstimmen, wird der Frame als intakt angesehen\n5. Wenn die Werte nicht übereinstimmen (z.B. weil ein Bit durch eine Störung verfälscht wurde), wird der Frame als fehlerhaft erkannt und verworfen\n\nDie FCS ist ein sehr effektiver Mechanismus zur Erkennung von Bitfehlern in der Datenübertragung und ein wesentlicher Bestandteil der Fehlererkennungsfähigkeiten von Ethernet."
    },
    {
        "question": "Ein Netzwerktechniker beobachtet einen Ethernet-Frame und stellt fest, dass im Ziel-MAC-Adressfeld alle Bits auf 1 gesetzt sind (FF:FF:FF:FF:FF:FF). An wen ist dieser Frame adressiert?",
        "options": [
            "An den nächsten Router im Netzwerk",
            "An alle Geräte im selben Netzwerksegment",
            "An eine Multicast-Gruppe von ausgewählten Geräten",
            "An keinen - dies ist ein ungültiger Frame"
        ],
        "correct": 1,
        "explain": "Ein Ethernet-Frame mit der Ziel-MAC-Adresse FF:FF:FF:FF:FF:FF ist **an alle Geräte im selben Netzwerksegment** adressiert. Dies ist eine **Broadcast-Adresse**.\n\nIn Ethernet-Netzwerken gibt es drei Arten von MAC-Adressen:\n\n1. **Unicast-Adressen**: Identifizieren eine einzelne Netzwerkschnittstelle\n2. **Multicast-Adressen**: Adressieren eine Gruppe von Netzwerkschnittstellen (beginnen mit einer ungeraden ersten Hexadezimalziffer)\n3. **Broadcast-Adresse**: Adressiert alle Geräte im selben Broadcast-Domain\n\nDie Broadcast-Adresse mit allen Bits auf 1 gesetzt (FF:FF:FF:FF:FF:FF in hexadezimaler Notation) wird verwendet, wenn ein Frame an alle Geräte im selben Netzwerksegment gesendet werden soll. Typische Anwendungsfälle für Broadcast-Frames sind:\n- ARP-Anfragen (Address Resolution Protocol)\n- DHCP-Discover-Nachrichten\n- Bestimmte Routing-Protokoll-Updates\n\nJedes Gerät im Netzwerk muss einen Frame mit dieser Zieladresse verarbeiten, im Gegensatz zu Frames mit Unicast-Adressen, die nur vom spezifischen adressierten Gerät verarbeitet werden."
    },
    [
  {
    "question": "Welches Zahlensystem wird zur Darstellung von Ethernet-MAC-Adressen verwendet?",
    "options": [
      "Dezimal",
      "Oktal",
      "Hexadezimal",
      "Binär"
    ],
    "correct": 2,
    "explain": "Ethernet-MAC-Adressen werden im **hexadezimalen Zahlensystem** dargestellt. Das hexadezimale Zahlensystem verwendet die Zahlen 0 bis 9 und die Buchstaben A bis F, wobei jede hexadezimale Ziffer vier binäre Bits repräsentiert. Da eine Ethernet-MAC-Adresse aus einem 48-Bit-Binärwert besteht, kann sie durch 12 hexadezimale Ziffern ausgedrückt werden."
  },
  {
    "question": "Wie viele Bits umfasst eine vollständige Ethernet-MAC-Adresse?",
    "options": [
      "32 Bits",
      "48 Bits",
      "64 Bits",
      "128 Bits"
    ],
    "correct": 1,
    "explain": "Eine vollständige Ethernet-MAC-Adresse besteht aus **48 Bits**. Dies entspricht 6 Bytes oder 12 hexadezimalen Ziffern. Die Adresse wird oft in einem Format mit Bindestrichen oder Doppelpunkten dargestellt, um die Lesbarkeit zu verbessern, z.B. 00-60-2F-3A-07-BC."
  },
  {
    "question": "Was bedeutet die Abkürzung OUI im Kontext von MAC-Adressen?",
    "options": [
      "Original User Interface",
      "Organizational Unit Identifier",
      "Organizationally Unique Identifier",
      "Optical Unit Interface"
    ],
    "correct": 2,
    "explain": "OUI steht für **Organizationally Unique Identifier**. Dies ist ein 24-Bit-Code (die ersten drei Bytes bzw. sechs hexadezimalen Ziffern einer MAC-Adresse), der von der IEEE an Hersteller von Netzwerkgeräten vergeben wird. Dieser Code stellt sicher, dass jeder Hersteller eindeutige MAC-Adressen für seine Geräte erzeugen kann, indem er den OUI mit einem selbst zugewiesenen, einzigartigen Wert für die restlichen 24 Bits kombiniert."
  },
  {
    "question": "Das hexadezimale Zahlensystem wird für IPv4-Adressen verwendet.",
    "options": [
      "Wahr",
      "Falsch"
    ],
    "correct": 1,
    "explain": "Diese Aussage ist **falsch**. IPv4-Adressen werden typischerweise im dezimalen Zahlensystem dargestellt (z.B. 192.168.1.1). Im Gegensatz dazu werden IPv6-Adressen und Ethernet-MAC-Adressen im hexadezimalen Zahlensystem dargestellt. Diese Unterscheidung ist wichtig für Netzwerkadministratoren und -techniker, um verschiedene Adresstypen korrekt zu identifizieren und zu verwenden."
  },
  {
    "question": "Welchem dezimalen Wert entspricht die hexadezimale Zahl 0A?",
    "options": [
      "8",
      "9",
      "10",
      "11"
    ],
    "correct": 2,
    "explain": "Die hexadezimale Zahl **0A** entspricht dem dezimalen Wert **10**. Im Hexadezimalsystem repräsentieren die Buchstaben A bis F die dezimalen Werte 10 bis 15. Somit steht A für den dezimalen Wert 10. Die Berechnung erfolgt wie folgt: 0×16¹ + A(10)×16⁰ = 0 + 10 = 10."
  },
  {
    "question": "Welchen Teil einer MAC-Adresse kann ein Gerätehersteller nach der Registrierung bei der IEEE selbst festlegen?",
    "options": [
      "Die ersten 24 Bits",
      "Die ersten 3 hexadezimalen Ziffern",
      "Die letzten 24 Bits",
      "Die mittleren 16 Bits"
    ],
    "correct": 2,
    "explain": "Ein Gerätehersteller kann **die letzten 24 Bits** (oder die letzten sechs hexadezimalen Ziffern) einer MAC-Adresse selbst festlegen. Die ersten 24 Bits (oder ersten sechs hexadezimalen Ziffern) sind der vom IEEE zugewiesene OUI (Organizationally Unique Identifier), der den Hersteller eindeutig identifiziert. Der Hersteller ist dafür verantwortlich, sicherzustellen, dass jedes seiner Geräte eine eindeutige Kombination der letzten 24 Bits erhält."
  },
  {
    "question": "Eine Unicast-MAC-Adresse kann sowohl als Quell- als auch als Zieladresse in einem Ethernet-Frame verwendet werden.",
    "options": [
      "Wahr",
      "Falsch"
    ],
    "correct": 0,
    "explain": "Diese Aussage ist **wahr**. Eine Unicast-MAC-Adresse ist eine eindeutige Adresse, die für die Übertragung eines Frames von einem Sender zu einem einzelnen Empfänger verwendet wird. Sie kann sowohl als Quell-MAC-Adresse (die MAC-Adresse des sendenden Geräts) als auch als Ziel-MAC-Adresse (die MAC-Adresse des empfangenden Geräts) in einem Ethernet-Frame verwendet werden. Wichtig ist jedoch zu beachten, dass die Quell-MAC-Adresse immer eine Unicast-Adresse sein muss, während die Ziel-MAC-Adresse auch eine Broadcast- oder Multicast-Adresse sein kann."
  },
  {
    "question": "Welche Eigenschaften hat ein Ethernet-Broadcast-Frame?",
    "options": [
      "Er wird nur von einem bestimmten Gerät empfangen",
      "Er hat die MAC-Adresse 01-00-5E",
      "Er wird von jedem Gerät im Ethernet-LAN empfangen",
      "Er wird immer von Routern weitergeleitet"
    ],
    "correct": 2,
    "explain": "Ein Ethernet-Broadcast-Frame **wird von jedem Gerät im Ethernet-LAN empfangen und verarbeitet**. Er ist durch die Ziel-MAC-Adresse FF-FF-FF-FF-FF-FF-FF (48 Einsen in binärer Form) gekennzeichnet. Ein Switch flutet alle seine Ports mit diesem Frame (außer dem eingehenden Port), und Router leiten ihn standardmäßig nicht weiter. Broadcasts werden häufig für Dienste wie DHCP verwendet, bei denen ein Gerät mit allen anderen Geräten im lokalen Netzwerk kommunizieren muss."
  },
  {
    "question": "Was ist das spezielle Merkmal der Ziel-MAC-Adresse eines IPv4-Multicast-Frames?",
    "options": [
      "Sie beginnt mit FF-FF-FF",
      "Sie beginnt mit 01-00-5E",
      "Sie beginnt mit 33-33",
      "Sie beginnt mit 00-00-00"
    ],
    "correct": 1,
    "explain": "Die Ziel-MAC-Adresse eines IPv4-Multicast-Frames **beginnt mit 01-00-5E**. Diese spezielle Präfix kennzeichnet, dass es sich um einen Ethernet-Frame handelt, der ein IPv4-Multicast-Paket enthält. Für IPv6-Multicast-Pakete beginnt die Ziel-MAC-Adresse hingegen mit 33-33. Multicast-Frames werden an eine Gruppe von Geräten gesendet, die zur gleichen Multicast-Gruppe gehören, im Gegensatz zu Broadcast-Frames, die an alle Geräte im LAN gesendet werden."
  },
  {
    "question": "Welche der folgenden MAC-Adressen ist eine gültige Broadcast-Adresse?",
    "options": [
      "01-00-5E-00-00-01",
      "33-33-00-00-00-01",
      "FF-FF-FF-FF-FF-FF",
      "00-00-00-00-00-00"
    ],
    "correct": 2,
    "explain": "Die MAC-Adresse **FF-FF-FF-FF-FF-FF** ist eine gültige Broadcast-Adresse. Diese Adresse besteht aus 48 Einsen in binärer Form und wird verwendet, um Ethernet-Frames an alle Geräte in einem lokalen Netzwerk zu senden. Wenn ein Gerät einen Frame mit dieser Zieladresse empfängt, verarbeitet es den Frame, anstatt ihn zu verwerfen. 01-00-5E-00-00-01 ist eine IPv4-Multicast-Adresse, 33-33-00-00-00-01 ist eine IPv6-Multicast-Adresse, und 00-00-00-00-00-00 ist keine standardmäßig verwendete Adresse."
  },
  {
    "question": "Was versteht man unter einer 'burned-in address' (BIA) im Kontext von Netzwerkhardware?",
    "options": [
      "Eine MAC-Adresse, die nach einem Netzwerkfehler nicht mehr funktioniert",
      "Eine MAC-Adresse, die im ROM der Netzwerkkarte fest kodiert ist",
      "Eine IP-Adresse, die fest dem Gerät zugewiesen wurde",
      "Eine Adresse, die bei hoher Netzwerkauslastung überhitzt"
    ],
    "correct": 1,
    "explain": "Eine **'burned-in address' (BIA)** ist eine MAC-Adresse, die im Read-Only-Memory (ROM) der Netzwerkkarte fest kodiert ('eingebrannt') ist. Dies bedeutet, dass die Adresse dauerhaft im ROM-Chip kodiert ist und beim Hochfahren des Computers aus dem ROM in den RAM kopiert wird. Allerdings ist es in modernen Betriebssystemen und Netzwerkkarten oft möglich, diese Adresse durch Software zu ändern, was bedeutet, dass das Filtern oder Steuern des Verkehrs auf Basis der MAC-Adresse nicht mehr als vollständig sicher angesehen werden kann."
  },
  {
    "question": "Das Protokoll ARP (Address Resolution Protocol) verwendet Ethernet- und IPv4-Broadcastadressen.",
    "options": [
      "Wahr",
      "Falsch"
    ],
    "correct": 1,
    "explain": "Diese Aussage ist teilweise **falsch**. Während ein ARP-Request tatsächlich als Ethernet-Broadcast gesendet wird (mit der Ziel-MAC-Adresse FF-FF-FF-FF-FF-FF), ist es wichtig zu beachten, dass eine ARP-Nachricht kein IPv4-Paket ist und daher keine IPv4-Broadcastadresse verwendet. ARP operiert auf Schicht 2 des OSI-Modells und wird verwendet, um die MAC-Adresse zu ermitteln, die einer bekannten IPv4-Adresse zugeordnet ist. Es ist ein Beispiel dafür, dass nicht alle Ethernet-Broadcasts ein IPv4-Broadcast-Paket enthalten."
  },
  {
    "question": "Wofür steht das Akronym MAC im Netzwerkkontext?",
    "options": [
      "Maximum Access Control",
      "Media Access Control",
      "Multiple Address Configuration",
      "Mainframe Access Controller"
    ],
    "correct": 1,
    "explain": "MAC steht für **Media Access Control**. Die MAC-Adresse ist eine eindeutige Identifikationsnummer, die jedem Netzwerkinterface (wie einer Netzwerkkarte) zugewiesen wird. Sie wird auf der Data-Link-Schicht (Schicht 2) des OSI-Modells verwendet und dient zur eindeutigen Identifizierung von Geräten in einem lokalen Netzwerk. MAC-Adressen werden vom Hersteller der Netzwerkhardware zugewiesen und sollten theoretisch weltweit eindeutig sein."
  },
  {
    "question": "Wie viele verschiedene OUIs kann die IEEE theoretisch an Hersteller vergeben?",
    "options": [
      "2^16 (65.536)",
      "2^24 (16.777.216)",
      "2^32 (4.294.967.296)",
      "2^48 (281.474.976.710.656)"
    ],
    "correct": 1,
    "explain": "Die IEEE kann theoretisch **2^24 (16.777.216)** verschiedene OUIs an Hersteller vergeben. Ein OUI besteht aus 24 Bits (oder 3 Bytes bzw. 6 hexadezimalen Ziffern) und bildet die ersten 24 Bits einer MAC-Adresse. Mit 24 Bits können 2^24 verschiedene Kombinationen dargestellt werden, was ungefähr 16,8 Millionen verschiedenen Herstellern entspricht. Jeder Hersteller kann dann mit seinen zugewiesenen letzten 24 Bits theoretisch 2^24 verschiedene Geräte eindeutig identifizieren."
  },
  {
    "question": "Was geschieht, wenn eine Netzwerkkarte einen Ethernet-Frame empfängt, dessen Ziel-MAC-Adresse nicht mit der eigenen übereinstimmt?",
    "options": [
      "Der Frame wird zum nächsten Gerät weitergeleitet",
      "Der Frame wird an den Sender zurückgeschickt",
      "Der Frame wird verworfen",
      "Der Frame wird an einen Router weitergeleitet"
    ],
    "correct": 2,
    "explain": "Wenn eine Netzwerkkarte einen Ethernet-Frame empfängt, dessen Ziel-MAC-Adresse nicht mit der eigenen physischen MAC-Adresse (im RAM gespeichert) übereinstimmt, **verwirft das Gerät den Frame**. Es gibt jedoch zwei Ausnahmen: Wenn die Ziel-MAC-Adresse eine Broadcast-Adresse ist (FF-FF-FF-FF-FF-FF) oder wenn es sich um eine Multicast-Adresse handelt und der Host zu dieser Multicastgruppe gehört, dann wird der Frame akzeptiert und zur weiteren Verarbeitung an höhere OSI-Schichten weitergeleitet."
  },
  {
    "question": "Eine Multicast-MAC-Adresse kann als Quelladresse in einem Ethernet-Frame verwendet werden.",
    "options": [
      "Wahr",
      "Falsch"
    ],
    "correct": 1,
    "explain": "Diese Aussage ist **falsch**. Eine Multicast-MAC-Adresse kann nur als Zieladresse, nie als Quelladresse in einem Ethernet-Frame verwendet werden. Die Quelladresse muss immer eine Unicast-Adresse sein, da sie ein spezifisches physisches Gerät identifiziert, von dem der Frame stammt. Multicast-Adressen repräsentieren Gruppen von Empfängern und haben keinen Sinn als Absenderadressen. Dies gilt auch für IPv4- und IPv6-Multicast-Adressen, die ebenfalls nur als Zieladressen und nie als Quelladressen verwendet werden können."
  },
  {
    "question": "Welchen Wert haben die ersten 24 Bits einer MAC-Adresse mit dem OUI von Cisco?",
    "options": [
      "00-00-0C (hexadezimal)",
      "00-60-2F (hexadezimal)",
      "01-00-5E (hexadezimal)",
      "FF-FF-FF (hexadezimal)"
    ],
    "correct": 1,
    "explain": "Die ersten 24 Bits (oder 6 hexadezimalen Ziffern) einer MAC-Adresse mit dem OUI von Cisco haben den Wert **00-60-2F** in hexadezimaler Darstellung. Dieser OUI wurde Cisco von der IEEE zugewiesen und wird als eindeutiger Identifikator für Cisco-Geräte verwendet. Wenn ein Netzwerkgerät eine MAC-Adresse hat, die mit 00-60-2F beginnt, kann man davon ausgehen, dass es sich um ein von Cisco hergestelltes Gerät handelt (oder zumindest ein Gerät mit einer Cisco-Netzwerkkarte)."
  },
  {
    "question": "Wie viele Bytes umfasst eine vollständige MAC-Adresse?",
    "options": [
      "4 Bytes",
      "6 Bytes",
      "8 Bytes",
      "12 Bytes"
    ],
    "correct": 1,
    "explain": "Eine vollständige MAC-Adresse umfasst **6 Bytes**. Da ein Byte 8 Bits entspricht, besteht eine MAC-Adresse aus insgesamt 48 Bits (6 × 8 = 48). In hexadezimaler Darstellung werden diese 6 Bytes durch 12 hexadezimale Ziffern dargestellt, da jede hexadezimale Ziffer 4 Bits repräsentiert. Die MAC-Adresse wird oft in einem Format mit Trennzeichen wie Bindestrichen oder Doppelpunkten dargestellt, z.B. 00-60-2F-3A-07-BC oder 00:60:2F:3A:07:BC."
  },
  {
    "question": "Welches Protokoll wird verwendet, um die MAC-Adresse zu bestimmen, die mit einer IPv6-Adresse verknüpft ist?",
    "options": [
      "Address Resolution Protocol (ARP)",
      "Reverse Address Resolution Protocol (RARP)",
      "Neighbor Discovery (ND)",
      "Dynamic Host Configuration Protocol (DHCP)"
    ],
    "correct": 2,
    "explain": "Das Protokoll, das verwendet wird, um die MAC-Adresse zu bestimmen, die mit einer IPv6-Adresse verknüpft ist, ist **Neighbor Discovery (ND)**. Dieses Protokoll ist Teil des ICMPv6-Protokolls und ersetzt ARP in IPv6-Netzwerken. Es bietet verschiedene Funktionen wie Router-Discovery, Prefix-Discovery, Parameter-Discovery und Duplikat-Adresserkennung. Im Gegensatz dazu wird das Address Resolution Protocol (ARP) verwendet, um die MAC-Adresse zu ermitteln, die einer IPv4-Adresse zugeordnet ist."
  },
  {
    "question": "In welchem Bereich liegen IPv4-Multicast-Adressen?",
    "options": [
      "10.0.0.0 bis 10.255.255.255",
      "172.16.0.0 bis 172.31.255.255",
      "192.168.0.0 bis 192.168.255.255",
      "224.0.0.0 bis 239.255.255.255"
    ],
    "correct": 3,
    "explain": "IPv4-Multicast-Adressen liegen im Bereich von **224.0.0.0 bis 239.255.255.255**. Diese Adressen werden verwendet, um Datenpakete an mehrere Empfänger gleichzeitig zu senden, die alle Mitglieder der gleichen Multicast-Gruppe sind. Im Gegensatz dazu sind die anderen aufgeführten Adressbereiche für private IPv4-Adressen reserviert: 10.0.0.0 bis 10.255.255.255 (ein Class-A-Netz), 172.16.0.0 bis 172.31.255.255 (16 Class-B-Netze) und 192.168.0.0 bis 192.168.255.255 (256 Class-C-Netze)."
  },
  {
    "question": "Welches Kriterium nutzt ein Layer-2-Ethernet-Switch für seine Weiterleitungsentscheidungen?",
    "options": [
      "IP-Adressen",
      "MAC-Adressen",
      "Portnummern",
      "Protokolltypen"
    ],
    "correct": 1,
    "explain": "Ein **Layer-2-Ethernet-Switch** trifft seine Weiterleitungsentscheidungen ausschließlich auf Basis der **MAC-Adressen**. Dies ist ein fundamentales Prinzip von Switches auf der Sicherungsschicht (Layer 2) des OSI-Modells. Der Switch arbeitet unabhängig vom transportierten Protokoll im Datenteil des Frames (wie IPv4, IPv6 oder ARP). Die Weiterleitungsentscheidung basiert allein auf den Layer-2-Ethernet-MAC-Adressen und nicht auf IP-Adressen (Layer 3), Portnummern (Layer 4) oder Protokolltypen."
  },
  {
    "question": "Was geschieht, wenn ein Ethernet-Switch einen Frame erhält, dessen Ziel-MAC-Adresse nicht in seiner MAC-Adresstabelle enthalten ist?",
    "options": [
      "Der Frame wird verworfen",
      "Der Frame wird an das Default Gateway gesendet",
      "Der Frame wird an alle Ports außer dem eingehenden Port weitergeleitet (Flooding)",
      "Der Switch sendet eine Anfrage, um die MAC-Adresse zu ermitteln"
    ],
    "correct": 2,
    "explain": "Wenn ein Ethernet-Switch einen Frame erhält und die Ziel-MAC-Adresse **nicht** in seiner MAC-Adresstabelle enthalten ist, führt er einen Vorgang namens **Flooding** durch. Dabei leitet der Switch den Frame an **alle Ports** außer dem Port weiter, an dem der Frame eingegangen ist. Diese Methode stellt sicher, dass der Frame sein Ziel erreicht, auch wenn der Switch die zugehörige Port-Zuordnung noch nicht kennt. Sobald das Zielgerät antwortet, lernt der Switch die MAC-Adresse und den zugehörigen Port und kann zukünftige Frames gezielt weiterleiten."
  },
  {
    "question": "Wie lange speichert ein Ethernet-Switch standardmäßig einen Eintrag in seiner MAC-Adresstabelle?",
    "options": [
      "1 Minute",
      "5 Minuten",
      "15 Minuten",
      "30 Minuten"
    ],
    "correct": 1,
    "explain": "Die meisten Ethernet-Switches behalten einen Eintrag in ihrer MAC-Adresstabelle standardmäßig für **5 Minuten**. Dieser Timer wird zurückgesetzt, wenn der Switch weitere Frames von derselben MAC-Adresse empfängt. Der Zeitwert ist ein Kompromiss zwischen Speichereffizienz und Netzwerkstabilität: Lange genug, um häufige Neueinträge zu vermeiden, aber kurz genug, um auf Netzwerkänderungen (wie umgesteckte Geräte) reagieren zu können."
  },
  {
    "question": "Was passiert, wenn ein Switch eine MAC-Adresse in seiner Tabelle hat, die jetzt aber über einen anderen Port kommuniziert?",
    "options": [
      "Der Switch ignoriert den Frame, da ein Konflikt vorliegt",
      "Der Switch behält beide Einträge für die gleiche MAC-Adresse",
      "Der Switch aktualisiert den Eintrag mit dem neuen Port",
      "Der Switch sendet eine Warnung an den Netzwerkadministrator"
    ],
    "correct": 2,
    "explain": "Wenn ein Switch eine Quell-MAC-Adresse in einem Frame erkennt, die bereits in seiner MAC-Adresstabelle vorhanden ist, aber von einem anderen Port stammt als zuvor registriert, **aktualisiert** der Switch den Eintrag mit dem **neuen Port**. Dies ermöglicht die korrekte Anpassung an Änderungen in der Netzwerktopologie, beispielsweise wenn ein Gerät physisch an einen anderen Port angeschlossen wird. Der Switch behandelt dies als neuen Eintrag und ersetzt den alten mit der aktualisierten Port-Nummer."
  },
  {
    "question": "Die MAC-Adresstabelle eines Switches wird auch als CAM-Tabelle bezeichnet.",
    "options": ["Wahr", "Falsch"],
    "correct": 0,
    "explain": "Diese Aussage ist **wahr**. Die MAC-Adresstabelle eines Switches wird auch als **CAM-Tabelle** bezeichnet, wobei CAM für **Content Addressable Memory** steht. Dieser spezialisierte Speichertyp ermöglicht sehr schnelle Suchvorgänge nach MAC-Adressen, was für die effiziente Weiterleitung von Frames entscheidend ist. Beide Begriffe werden in der Netzwerktechnik synonym verwendet, obwohl sie technisch gesehen leicht unterschiedliche Aspekte betonen: MAC-Adresstabelle bezieht sich auf die Funktion, während CAM-Tabelle die technische Implementierung beschreibt."
  },
  {
    "question": "Welcher grundlegende Unterschied besteht zwischen einem Ethernet-Hub und einem Ethernet-Switch bezüglich der Weiterleitung von Daten?",
    "options": [
      "Hubs arbeiten auf Layer 3, Switches auf Layer 2",
      "Hubs leiten Daten nur an bestimmte Ports weiter, Switches an alle",
      "Hubs wiederholen Bits an allen Ports außer dem eingehenden, Switches treffen gezielte Weiterleitungsentscheidungen",
      "Hubs können mehr Ports haben als Switches"
    ],
    "correct": 2,
    "explain": "Der grundlegende Unterschied zwischen einem Ethernet-Hub und einem Ethernet-Switch liegt in ihrer Weiterleitungsmethode:\n\n- **Hubs** sind einfache Layer-1-Geräte, die **alle empfangenen Bits an allen Ports außer dem eingehenden Port wiederholen** (Repeating). Sie haben keine Intelligenz zur gezielten Weiterleitung und erzeugen eine einzige Kollisionsdomäne.\n\n- **Switches** sind Layer-2-Geräte, die ihre **MAC-Adresstabelle nutzen, um gezielte Weiterleitungsentscheidungen** zu treffen. Sie leiten Frames nur an den Port weiter, an dem sich das Zielgerät befindet, was die Netzwerkeffizienz erheblich steigert und mehrere Kollisionsdomänen schafft."
  },
  {
    "question": "Wie lernt ein Ethernet-Switch, welche MAC-Adresse mit welchem Port verbunden ist?",
    "options": [
      "Durch manuelle Konfiguration durch den Netzwerkadministrator",
      "Durch Prüfung der Ziel-MAC-Adresse eingehender Frames",
      "Durch Prüfung der Quell-MAC-Adresse eingehender Frames",
      "Durch regelmäßiges Versenden von Discovery-Paketen"
    ],
    "correct": 2,
    "explain": "Ein Ethernet-Switch lernt die Zuordnung von MAC-Adressen zu Ports, indem er die **Quell-MAC-Adresse jedes eingehenden Frames** analysiert. Wenn ein Frame bei einem Port eingeht, extrahiert der Switch die Quell-MAC-Adresse und ordnet sie dem Port zu, über den der Frame empfangen wurde. Dieser Lernprozess ist dynamisch und automatisch, ohne dass manuelle Konfiguration erforderlich ist. Die Ziel-MAC-Adresse wird hingegen für die Weiterleitungsentscheidung verwendet, nicht für den Lernprozess."
  },
  {
    "question": "Ein Switch kann mehrere MAC-Adressen einem einzigen Port zuordnen.",
    "options": ["Wahr", "Falsch"],
    "correct": 0,
    "explain": "Diese Aussage ist **wahr**. Ein Switch kann durchaus mehrere MAC-Adressen mit einem einzigen Port verknüpfen. Dies ist besonders häufig in folgenden Szenarien:\n\n1. Wenn ein Port mit einem anderen Switch verbunden ist, da über diesen Port dann Frames von mehreren Endgeräten mit unterschiedlichen MAC-Adressen empfangen werden.\n\n2. Wenn ein Computer mehrere virtuelle Maschinen betreibt, die jeweils eigene MAC-Adressen haben.\n\n3. Wenn ein Gerät mit mehreren Netzwerkschnittstellen (und damit MAC-Adressen) über einen Port angeschlossen ist.\n\nDer Switch erstellt für jede eindeutige Quell-MAC-Adresse einen separaten Eintrag in seiner MAC-Adresstabelle, auch wenn alle über denselben Port kommunizieren."
  },
  {
    "question": "Wann wird ein Ethernet-Frame an die MAC-Adresse des Default Gateways gesendet?",
    "options": [
      "Wenn die Ziel-MAC-Adresse unbekannt ist",
      "Wenn sich die Ziel-IP-Adresse in einem Remote-Netzwerk befindet",
      "Wenn der Switch überlastet ist",
      "Wenn ein Broadcast-Paket gesendet werden soll"
    ],
    "correct": 1,
    "explain": "Ein Ethernet-Frame wird an die MAC-Adresse des Default Gateways (Router) gesendet, wenn sich die **Ziel-IP-Adresse in einem Remote-Netzwerk** befindet, also nicht im lokalen Subnetz des sendenden Geräts. Dies geschieht, weil:\n\n- Geräte im selben Subnetz direkt miteinander kommunizieren können (Layer 2)\n- Für die Kommunikation mit Geräten in anderen Netzen wird ein Router benötigt (Layer 3)\n- Das sendende Gerät verpackt das IP-Paket mit der Remote-Zieladresse in einen Ethernet-Frame\n- Als Ziel-MAC-Adresse wird die MAC-Adresse des Default Gateways verwendet\n\nDer Router empfängt diesen Frame, entpackt das IP-Paket und leitet es zum entsprechenden Remote-Netzwerk weiter."
  },
  {
    "question": "Welche Eigenschaften der MAC-Adresstabelle bestimmen die Weiterleitungsentscheidung eines Switches für einen eingehenden Frame?",
    "options": [
      "Die Quell-MAC-Adresse und die Port-Nummer",
      "Die Ziel-MAC-Adresse und die Quell-MAC-Adresse",
      "Die Ziel-MAC-Adresse und der zugeordnete Port",
      "Die IP-Adresse und die MAC-Adresse"
    ],
    "correct": 2,
    "explain": "Für die **Weiterleitungsentscheidung** eines Switches sind die **Ziel-MAC-Adresse des eingehenden Frames** und der dieser MAC-Adresse **zugeordnete Port** in der MAC-Adresstabelle entscheidend. Der Switch extrahiert die Ziel-MAC-Adresse aus dem Frame und sucht in seiner Tabelle nach einem passenden Eintrag. Findet er einen Treffer, wird der Frame gezielt an den entsprechenden Port weitergeleitet. Die Quell-MAC-Adresse wird zwar für den Lernprozess verwendet, spielt aber für die eigentliche Weiterleitungsentscheidung keine Rolle."
  },
  {
    "question": "Welche Auswirkung hat es, wenn ein Switch jeden empfangenen Frame an alle Ports weiterleiten würde?",
    "options": [
      "Das Netzwerk würde schneller werden",
      "Die Sicherheit würde erhöht werden",
      "Das Netzwerk würde überlastet werden und zum Erliegen kommen",
      "Es würde keinen Unterschied zu normalem Switch-Verhalten geben"
    ],
    "correct": 2,
    "explain": "Wenn ein Switch jeden empfangenen Frame an alle Ports weiterleiten würde, **würde das Netzwerk überlastet werden und wahrscheinlich zum Erliegen kommen**. Dies entspräche dem Verhalten eines Hubs und würde folgende negative Auswirkungen haben:\n\n- **Bandbreitenverschwendung**: Jeder Frame würde unnötigerweise an Geräte gesendet, für die er nicht bestimmt ist\n- **Erhöhtes Kollisionsrisiko** in Half-Duplex-Umgebungen\n- **Gesteigerte Latenz** durch Überlastung der Netzwerkverbindungen\n- **Sicherheitsrisiken**, da jedes Gerät alle Frames mitlesen könnte\n\nGerade der intelligente, gezielte Weiterleitungsmechanismus unterscheidet Switches von Hubs und ermöglicht effiziente, skalierbare Netzwerke."
  },
  {
    "question": "Wenn ein Gerät eine IP-Adresse kontaktieren möchte, die sich im selben Subnetz befindet, sendet es den Ethernet-Frame direkt an die MAC-Adresse dieses Geräts.",
    "options": ["Wahr", "Falsch"],
    "correct": 0,
    "explain": "Diese Aussage ist **wahr**. Wenn ein Gerät mit einem anderen Gerät im selben Subnetz kommunizieren möchte, sendet es den Ethernet-Frame direkt an die MAC-Adresse des Zielgeräts, ohne den Umweg über ein Default Gateway (Router).\n\nDer Ablauf ist wie folgt:\n1. Das sendende Gerät vergleicht seine eigene IP-Adresse und Subnetzmaske mit der Ziel-IP-Adresse\n2. Befindet sich das Ziel im selben Subnetz, ermittelt das Gerät die MAC-Adresse des Ziels (falls nicht bekannt) mittels ARP (Address Resolution Protocol)\n3. Der Ethernet-Frame wird mit der Ziel-MAC-Adresse des tatsächlichen Empfängers erstellt\n4. Der Switch leitet den Frame direkt an das Zielgerät weiter\n\nDer Einsatz eines Default Gateways ist nur für die Kommunikation mit Geräten in anderen Netzwerken erforderlich."
  },
  {
    "question": "Welche Informationen enthält ein typischer Eintrag in der MAC-Adresstabelle eines Switches?",
    "options": [
      "MAC-Adresse, IP-Adresse und Status",
      "MAC-Adresse, Port-Nummer und Aktualisierungstimer",
      "IP-Adresse, Port-Nummer und Gerätename",
      "MAC-Adresse, Protokolltyp und Priorität"
    ],
    "correct": 1,
    "explain": "Ein typischer Eintrag in der MAC-Adresstabelle eines Switches enthält folgende Informationen:\n\n- **MAC-Adresse**: Die eindeutige Hardware-Adresse des Geräts\n- **Port-Nummer**: Der physische Switch-Port, an dem das Gerät angeschlossen ist oder über den es erreichbar ist\n- **Aktualisierungstimer**: Ein Zeitwert, der angibt, wie lange der Eintrag noch gültig ist (standardmäßig 5 Minuten)\n\nDiese drei Informationen sind ausreichend für die grundlegende Switching-Funktion. IP-Adressen werden nicht in der MAC-Adresstabelle gespeichert, da ein Layer-2-Switch seine Weiterleitungsentscheidungen ausschließlich auf Basis von MAC-Adressen trifft, unabhängig vom höherschichtigen Protokoll wie IPv4 oder IPv6."
  },
  {
    "question": "Bei der Kommunikation mit einem Remote-Host bleibt die Ziel-MAC-Adresse im Ethernet-Frame immer gleich, auch wenn das Paket mehrere Router passiert.",
    "options": ["Wahr", "Falsch"],
    "correct": 1,
    "explain": "Diese Aussage ist **falsch**. Bei der Kommunikation mit einem Remote-Host ändert sich die Ziel-MAC-Adresse im Ethernet-Frame bei jedem Hop (Router-Übergang).\n\nWenn ein Paket zwischen verschiedenen Netzwerken transportiert wird:\n\n1. Das sendende Gerät erstellt einen Frame mit:\n   - Ziel-MAC-Adresse des lokalen Default Gateways (Router)\n   - Ziel-IP-Adresse des entfernten Hosts\n\n2. Der Router empfängt den Frame, entpackt das IP-Paket und entscheidet anhand seiner Routing-Tabelle, wohin es weitergesendet werden soll\n\n3. Er erstellt einen neuen Ethernet-Frame mit:\n   - Ziel-MAC-Adresse des nächsten Hops (nächster Router oder Zielhost)\n   - Gleicher Ziel-IP-Adresse wie zuvor\n\nDieser Prozess wiederholt sich an jedem Router auf dem Weg zum Ziel. Die MAC-Adressen sind nur für die Kommunikation auf dem jeweiligen Netzsegment relevant, während die IP-Adressen die Ende-zu-Ende-Kommunikation beschreiben."
  },
      {
        "question": "Welche Frame-Weiterleitungsmethode berechnet den CRC-Wert eines Frames, bevor dieser weitergeleitet wird?",
        "options": [
            "Store-and-Forward-Switching",
            "Cut-Through-Switching",
            "Fast-Forward-Switching",
            "Fragment-Free-Switching"
        ],
        "correct": 0,
        "explain": "**Store-and-Forward-Switching** ist die einzige Methode, die den gesamten Frame empfängt und vor der Weiterleitung eine vollständige CRC-Prüfung durchführt. Dadurch wird sichergestellt, dass fehlerhafte Frames erkannt und verworfen werden, bevor sie unnötige Bandbreite im Netzwerk verbrauchen. Diese Methode ist besonders vorteilhaft in Netzwerken, die QoS-Analysen (Quality of Service) benötigen, da sie die Klassifizierung von Frames für Netzwerkpriorisierung ermöglicht."
    },
    {
        "question": "Ein Vorteil des Cut-Through-Switchings gegenüber dem Store-and-Forward-Switching ist:",
        "options": [
            "Erhöhte Fehlerkorrekturmöglichkeiten",
            "Bessere QoS-Unterstützung",
            "Geringere Latenzzeit",
            "Verbesserte Sicherheit"
        ],
        "correct": 2,
        "explain": "Der Hauptvorteil des **Cut-Through-Switchings** ist die **geringere Latenzzeit** (Verzögerung). Cut-Through-Switches beginnen mit der Weiterleitung, sobald sie genügend Daten gelesen haben, um die Zieladresse zu bestimmen. Sie warten nicht auf den kompletten Frame. Diese Methode kommt insbesondere in Anwendungen zum Einsatz, in denen minimale Verzögerungen wichtig sind. Allerdings fehlt diesem Verfahren die Möglichkeit, beschädigte Frames vor der Weiterleitung zu erkennen, was bei Store-and-Forward-Switching standardmäßig geschieht."
    },
    {
        "question": "Fast-Forward-Switching leitet Frames weiter, nachdem welcher Teil des Frames gelesen wurde?",
        "options": [
            "Nach den ersten 64 Byte des Frames",
            "Nach der Ziel-MAC-Adresse",
            "Nach der Präambel und dem Startdelimiter",
            "Nach der vollständigen CRC-Prüfung"
        ],
        "correct": 1,
        "explain": "**Fast-Forward-Switching** leitet einen Frame sofort weiter, nachdem die **Ziel-MAC-Adresse** erkannt wurde. Die Ziel-MAC-Adresse befindet sich in den ersten 6 Byte des Frames nach der Präambel. Diese Methode bietet die geringste Latenzzeit unter allen Switching-Arten, da der Switch nicht wartet, bis der gesamte Frame empfangen wurde. Der Nachteil ist, dass möglicherweise fehlerhafte Frames weitergeleitet werden, da keine Fehlerprüfung stattfindet."
    },
    {
        "question": "Fragment-Free-Switching speichert einen bestimmten Teil des Frames vor der Weiterleitung. Wie viele Bytes sind das?",
        "options": [
            "32 Byte",
            "48 Byte",
            "64 Byte",
            "128 Byte"
        ],
        "correct": 2,
        "explain": "**Fragment-Free-Switching** speichert die ersten **64 Byte** des Frames, bevor es mit der Weiterleitung beginnt. Diese Methode stellt einen Kompromiss zwischen Store-and-Forward-Switching und Fast-Forward-Switching dar. Der Grund für die Speicherung der ersten 64 Byte liegt darin, dass die meisten Netzwerkfehler und Kollisionen in diesem Bereich auftreten. Diese Prüfung hilft dabei, die Weiterleitung kollidierter Frames zu vermeiden, bietet aber dennoch eine geringere Latenzzeit als Store-and-Forward-Switching."
    },
    {
        "question": "Welche Methode der Speicherpufferung teilt jedem Port einen festgelegten Speicherblock zu?",
        "options": [
            "Gemeinsame Speicherpufferung",
            "Portbasierte Speicherpufferung",
            "Dynamic Memory Allocation",
            "Frame-Buffering"
        ],
        "correct": 1,
        "explain": "Die **portbasierte Speicherpufferung** teilt jedem Port einen festgelegten Speicherblock zu. Bei dieser Methode kann ein Port seinen zugewiesenen Pufferspeicher nicht mit anderen Ports teilen, selbst wenn diese ihren Speicher nicht nutzen. Diese Art der Speicherpufferung kann zu Einschränkungen führen, wenn ein Port mehr Puffer benötigt als ihm zugewiesen wurde, während andere Ports ungenutzte Kapazitäten haben."
    },
    {
        "question": "Gemeinsame Speicherpufferung ist besonders vorteilhaft bei:",
        "options": [
            "Symmetrischem Switching mit einheitlichen Datenraten",
            "Asymmetrischem Switching mit unterschiedlichen Datenraten",
            "Nur Cut-Through-Switching",
            "Nur Fast-Forward-Switching"
        ],
        "correct": 1,
        "explain": "**Gemeinsame Speicherpufferung** ist besonders vorteilhaft bei **asymmetrischem Switching mit unterschiedlichen Datenraten**. Diese Methode teilt den gesamten Speicher zwischen allen Ports auf und verwaltet ihn dynamisch je nach Bedarf. Dies ist wichtig, wenn verschiedene Ports mit unterschiedlichen Geschwindigkeiten arbeiten, beispielsweise wenn ein Server an einen 10-Gbit/s-Port und PCs an 1-Gbit/s-Ports angeschlossen sind. Die gemeinsame Pufferung ermöglicht es, größere Frames zu speichern, ohne dass weitere Frames verloren gehen."
    },
    {
        "question": "Bei einem Duplexfehler ist ein Port im Vollduplex-Modus und der andere im Halbduplex-Modus. Welches Problem tritt dabei hauptsächlich auf?",
        "options": [
            "Excessive timeouts",
            "Frame corruption",
            "Häufige Kollisionen",
            "Authentifizierungsfehler"
        ],
        "correct": 2,
        "explain": "Bei einem **Duplexfehler** treten vor allem **häufige Kollisionen** auf. Wenn ein Port im Vollduplex-Modus arbeitet, sendet er Daten, wann immer er möchte, da er davon ausgeht, dass gleichzeitiges Senden und Empfangen möglich ist. Der Port im Halbduplex-Modus dagegen kann nur entweder senden oder empfangen und prüft vor dem Senden, ob die Leitung frei ist. Da der Vollduplex-Port jederzeit sendet, kommt es zu häufigen Kollisionen beim Halbduplex-Port, was die Netzwerkleistung erheblich beeinträchtigt."
    },
    {
        "question": "GigabitEthernet-Ports können nur in welchem Duplexmodus arbeiten?",
        "options": [
            "Nur Halbduplex",
            "Nur Vollduplex",
            "Entweder Halb- oder Vollduplex",
            "Weder Halb- noch Vollduplex, sondern in einem speziellen GigabitEthernet-Modus"
        ],
        "correct": 1,
        "explain": "**GigabitEthernet-Ports** können ausschließlich im **Vollduplex-Modus** arbeiten. Dies ist eine fundamentale Eigenschaft von GigabitEthernet und höheren Standards. Der Vollduplex-Modus ermöglicht gleichzeitiges Senden und Empfangen von Daten, was für die hohen Bandbreiten dieser Verbindungen essentiell ist. Halbduplex-Betrieb ist bei GigabitEthernet nicht vorgesehen oder spezifiziert."
    },
    {
        "question": "Autonegotiation bei Ethernet-Verbindungen ermöglicht es Geräten, automatisch welche Parameter auszuhandeln?",
        "options": [
            "Nur Duplex-Modus",
            "Nur Geschwindigkeit",
            "Sowohl Duplex-Modus als auch Geschwindigkeit",
            "Weder Duplex-Modus noch Geschwindigkeit, sondern nur Fehlerkorrekturraten"
        ],
        "correct": 2,
        "explain": "**Autonegotiation** ermöglicht es Ethernet-Geräten, automatisch **sowohl den Duplex-Modus als auch die Geschwindigkeit** auszuhandeln. Diese optionale Funktion wird von den meisten modernen Ethernet-Switches und Netzwerkkarten unterstützt. Bei aktivierter Autonegotiation auf beiden Geräten wird die höchste gemeinsame Datenübertragungsrate und der optimale Duplex-Modus ausgewählt. Wenn beide Geräte Vollduplex bei einer bestimmten Geschwindigkeit unterstützen, wird dieser Modus gewählt."
    },
    {
        "question": "Duplexfehler sind eine der häufigsten Ursachen für Leistungsprobleme bei Ethernet-Verbindungen. Bei welchen Geschwindigkeiten treten diese Probleme typischerweise auf?",
        "options": [
            "Nur bei 1 Gbit/s Verbindungen",
            "Nur bei 10 Gbit/s Verbindungen",
            "Bei 10/100 Mbit/s Verbindungen",
            "Ausschließlich bei 40 Gbit/s Verbindungen"
        ],
        "correct": 2,
        "explain": "**Duplexfehler** treten typischerweise bei **10/100 Mbit/s Ethernet-Verbindungen** auf. Sie gehören zu den häufigsten Ursachen für Leistungsprobleme bei diesen Geschwindigkeiten. Bei GigabitEthernet und schnelleren Verbindungen ist dieses Problem weniger relevant, da diese Standards nur im Vollduplex-Modus arbeiten können. Duplexfehler entstehen, wenn ein Port im Vollduplex- und der andere im Halbduplex-Modus arbeitet, was zu Kollisionen und erheblichen Leistungseinbußen führt."
    },
    {
        "question": "Welcher Typ von Ethernet-Kabel wird üblicherweise verwendet, um zwei Switches miteinander zu verbinden?",
        "options": [
            "Straight-Through-Kabel",
            "Crossover-Kabel",
            "Rollover-Kabel",
            "Koaxialkabel"
        ],
        "correct": 1,
        "explain": "Für die Verbindung zwischen **zwei Switches** wird traditionell ein **Crossover-Kabel** verwendet. Dies liegt daran, dass bei der Verbindung gleichartiger Geräte (Switch zu Switch, Router zu Router oder Host zu Host) die Sende- und Empfangsleitungen gekreuzt werden müssen. Durch die Kreuzung werden die Sendepins eines Geräts mit den Empfangspins des anderen Geräts verbunden und umgekehrt. Bei moderneren Geräten mit Auto-MDIX-Funktionalität kann allerdings auch ein Straight-Through-Kabel verwendet werden."
    },
    {
        "question": "Die Auto-MDIX-Funktion bei Switches ermöglicht:",
        "options": [
            "Automatische Konfiguration von IP-Adressen",
            "Automatische Erkennung und Konfiguration des angeschlossenen Kabeltyps",
            "Automatisches Update der Switch-Firmware",
            "Automatische Optimierung der MAC-Adresstabelle"
        ],
        "correct": 1,
        "explain": "Die **Auto-MDIX-Funktion** (Automatic Medium-Dependent Interface Crossover) ermöglicht die **automatische Erkennung und Konfiguration des angeschlossenen Kabeltyps**. Wenn diese Funktion aktiviert ist, erkennt der Switch automatisch, ob ein Crossover- oder Straight-Through-Kabel angeschlossen ist, und konfiguriert die Schnittstelle entsprechend. Dies bedeutet, dass unabhängig vom Gerät am anderen Ende der Verbindung sowohl Crossover- als auch Straight-Through-Kabel verwendet werden können."
    },
    {
        "question": "Ab welcher Cisco IOS Release-Version ist Auto-MDIX standardmäßig aktiviert?",
        "options": [
            "10.2 oder höher",
            "11.5 oder höher",
            "12.2(18) SE oder höher",
            "15.0 oder höher"
        ],
        "correct": 2,
        "explain": "Die **Auto-MDIX-Funktion** ist ab **Cisco IOS Release 12.2(18) SE oder höher** standardmäßig aktiviert. Bei älteren Versionen muss diese Funktion manuell konfiguriert werden. Die Funktion kann jedoch auch deaktiviert sein, weshalb es nach wie vor eine gute Praxis ist, den richtigen Kabeltyp für die jeweilige Verbindung zu verwenden. Auto-MDIX kann bei Bedarf mit dem Befehl `mdix auto` im Schnittstellenkonfigurationsmodus wieder aktiviert werden."
    },
    {
        "question": "Welche Weiterleitungsmethode stellt einen Kompromiss zwischen Store-and-Forward-Switching und Fast-Forward-Switching dar?",
        "options": [
            "Cut-Through-Switching",
            "Fragment-Free-Switching",
            "Express Forwarding",
            "Adaptive Switching"
        ],
        "correct": 1,
        "explain": "**Fragment-Free-Switching** stellt einen Kompromiss zwischen Store-and-Forward-Switching und Fast-Forward-Switching dar. Diese Methode speichert die ersten 64 Byte eines Frames, bevor er weitergeleitet wird. Der Grund für diese spezifische Bytezahl liegt darin, dass die meisten Netzwerkfehler und Kollisionen in den ersten 64 Byte auftreten. Fragment-Free-Switching versucht, Fast-Forward-Switching zu optimieren, indem es eine begrenzte Fehleranalyse durchführt, ohne die vollständige Verzögerung des Store-and-Forward-Verfahrens zu verursachen."
    },
    {
        "question": "Beim Store-and-Forward-Switching wird die Integrität eines Frames vor der Weiterleitung überprüft. Welche Technologie wird dafür verwendet?",
        "options": [
            "Checksum",
            "CRC (Cyclic Redundancy Check)",
            "Parity Bit",
            "Hash-Funktion"
        ],
        "correct": 1,
        "explain": "Beim **Store-and-Forward-Switching** wird die Integrität eines Frames mithilfe des **CRC (Cyclic Redundancy Check)** überprüft. Der CRC basiert auf einer mathematischen Formel, die die Anzahl der Bits im Frame berücksichtigt und einen Prüfwert berechnet. Der Switch empfängt den gesamten Frame, berechnet den CRC-Wert neu und vergleicht ihn mit dem im Frame enthaltenen Wert. Stimmen die Werte nicht überein, wird der Frame als fehlerhaft erkannt und verworfen, was die Bandbreitennutzung durch fehlerhafte Daten reduziert."
    },
    {
        "question": "Eine direkte Verbindung zwischen einem Router und einem Host erfordert welchen Kabeltyp?",
        "options": [
            "Straight-Through-Kabel",
            "Crossover-Kabel",
            "Rollover-Kabel",
            "Konsolenkabel"
        ],
        "correct": 1,
        "explain": "Eine **direkte Verbindung zwischen einem Router und einem Host** erfordert ein **Crossover-Kabel**. Dies mag zunächst überraschend sein, da Router und Hosts unterschiedliche Gerätetypen sind. Der Grund liegt jedoch in der Netzwerkschnittstellen-Klassifikation: Die Ethernet-Ports von Routern werden als DTE (Data Terminal Equipment) klassifiziert, ebenso wie die NICs in Hosts. Bei der Verbindung von zwei DTE-Geräten muss ein Crossover-Kabel verwendet werden, um die Sende- und Empfangsleitungen korrekt zu verbinden."
    },
    {
        "question": "Wenn ein Switch zwischen Store-and-Forward-Switching und Cut-Through-Switching wechselt, basiert diese Entscheidung auf:",
        "options": [
            "Der aktuellen Netzwerkauslastung",
            "Dem Typ des angeschlossenen Geräts",
            "Einer benutzerdefinierten Fehlerrate",
            "Der Größe der zu übertragenden Frames"
        ],
        "correct": 2,
        "explain": "Die Entscheidung eines Switches, zwischen **Store-and-Forward-Switching und Cut-Through-Switching** zu wechseln, basiert typischerweise auf einer **benutzerdefinierten Fehlerrate**. Einige Switches können so konfiguriert werden, dass sie Cut-Through-Switching auf einzelnen Ports verwenden, bis ein benutzerdefinierter Fehlergrenzwert erreicht wird. Sobald dieser Grenzwert überschritten wird, wechselt der Switch automatisch zu Store-and-Forward-Switching, um Fehler zu reduzieren. Wenn die Fehlerrate wieder unter den Grenzwert sinkt, kann der Port automatisch zum Cut-Through-Switching zurückkehren."
    },
    {
        "question": "Store-and-Forward-Switching ist besonders wichtig für QoS-Analysen in konvergenten Netzwerken. Was ist ein Beispiel für einen Datenverkehr, der typischerweise priorisiert wird?",
        "options": [
            "E-Mail-Datenverkehr",
            "File Transfer Protocol (FTP)",
            "Voice over IP (VoIP)",
            "HTTP Web-Browsing"
        ],
        "correct": 2,
        "explain": "In konvergenten Netzwerken, die **Store-and-Forward-Switching** für QoS-Analysen nutzen, wird typischerweise **Voice over IP (VoIP)**-Datenverkehr priorisiert. VoIP-Anwendungen sind zeitkritisch und empfindlich gegenüber Verzögerungen und Jitter. Selbst kurze Unterbrechungen können die Sprachqualität erheblich beeinträchtigen. Store-and-Forward-Switching ermöglicht die vollständige Prüfung und Klassifizierung von Frames, was die Implementierung von QoS-Richtlinien erlaubt, die dem VoIP-Verkehr Vorrang vor weniger zeitkritischem Datenverkehr wie Web-Browsing oder E-Mail geben."
    },
    {
        "question": "Ein Duplexfehler tritt auf, wenn:",
        "options": [
            "Beide Ports im Halbduplex-Modus arbeiten",
            "Beide Ports im Vollduplex-Modus arbeiten",
            "Ein Port im Vollduplex-Modus und der andere im Halbduplex-Modus arbeitet",
            "Beide Ports unterschiedliche Geschwindigkeiten haben, aber denselben Duplex-Modus"
        ],
        "correct": 2,
        "explain": "Ein **Duplexfehler** tritt auf, wenn **ein Port im Vollduplex-Modus und der andere im Halbduplex-Modus arbeitet**. Diese Nichtübereinstimmung führt zu Kommunikationsproblemen, da der Port im Vollduplex-Modus davon ausgeht, dass er jederzeit senden kann, während der Port im Halbduplex-Modus nur sendet, wenn er die Leitung als frei erkennt. Dies führt zu zahlreichen Kollisionen am Halbduplex-Port, da der Vollduplex-Port weiterhin sendet, ohne auf eine freie Leitung zu achten."
    },
    {
    "question": "Welche grundlegenden Kommunikationsprotokolle sind auf der Vermittlungsschicht (OSI-Schicht 3) angesiedelt?",
    "options": [
      "TCP und UDP",
      "IPv4 und IPv6",
      "HTTP und FTP",
      "Ethernet und Token Ring"
    ],
    "correct": 1,
    "explain": "Die **Vermittlungsschicht (OSI-Schicht 3)** verwendet **IPv4 und IPv6** als grundlegende Kommunikationsprotokolle. Diese Protokolle sind für die Adressierung und Paketweiterleitung zwischen verschiedenen Netzwerken verantwortlich. Auf dieser Schicht befinden sich auch Routing-Protokolle wie OSPF und Benachrichtigungsprotokolle wie ICMP. TCP und UDP sind hingegen Protokolle der Transportschicht (Schicht 4), während HTTP und FTP Anwendungsprotokolle (Schicht 7) sind. Ethernet und Token Ring gehören zur Sicherungsschicht (Schicht 2)."
  },
  {
    "question": "Die Vermittlungsschicht ist für die Kommunikation zwischen verschiedenen Anwendungen auf einem Host verantwortlich.",
    "options": ["Wahr", "Falsch"],
    "correct": 1,
    "explain": "Diese Aussage ist **falsch**. Die Kommunikation zwischen verschiedenen Anwendungen auf einem Host ist Aufgabe der **Transportschicht (OSI-Schicht 4)**, nicht der Vermittlungsschicht. Die Vermittlungsschicht (OSI-Schicht 3) ermöglicht die Ende-zu-Ende-Kommunikation zwischen verschiedenen Hosts in unterschiedlichen Netzwerken und ist für Adressierung, Kapselung, Routing und Entkapselung von Paketen zuständig. Sie berücksichtigt nicht die spezifischen Anwendungen oder Dienste, die auf den Hosts laufen."
  },
  {
    "question": "Welche der folgenden Vorgänge gehört NICHT zu den grundlegenden Funktionen der Vermittlungsschicht?",
    "options": [
      "Adressierung der Endgeräte",
      "Kapselung von Daten",
      "Routing von Paketen",
      "Fehlererkennung und -korrektur"
    ],
    "correct": 3,
    "explain": "**Fehlererkennung und -korrektur** gehören nicht zu den grundlegenden Funktionen der Vermittlungsschicht. Diese Aufgaben werden typischerweise von höheren Schichten wie der Transportschicht (insbesondere TCP) übernommen. Die Vermittlungsschicht führt vier grundlegende Vorgänge aus:\n\n1. **Adressierung der Endgeräte** - Zuweisung eindeutiger IP-Adressen\n2. **Kapselung** - Umschließen der Transportschicht-PDU mit IP-Header\n3. **Routing** - Bestimmung des besten Pfades zur Weiterleitung von Paketen\n4. **Entkapselung** - Entfernen des IP-Headers am Ziel\n\nDas IP-Protokoll ist grundsätzlich unzuverlässig und bietet keine integrierten Mechanismen zur Fehlererkennung oder -korrektur für Datenpakete."
  },
  {
    "question": "Was versteht man unter einem 'Hop' im Kontext des Routings?",
    "options": [
      "Die maximale Anzahl von Paketen, die ein Router verarbeiten kann",
      "Ein Protokoll zur Überwachung des Paketflusses",
      "Ein Router, den ein Paket auf dem Weg zum Ziel durchläuft",
      "Die Geschwindigkeit, mit der ein Paket weitergeleitet wird"
    ],
    "correct": 2,
    "explain": "Ein **Hop** bezeichnet im Routing-Kontext einen **Router, den ein Paket auf dem Weg zum Ziel durchläuft**. Wenn ein Paket von einem Quell-Host zu einem Ziel-Host über mehrere Netzwerke geleitet wird, muss es typischerweise mehrere Router passieren. Jeder dieser Router stellt einen Hop dar. Der gesamte Pfad vom Quell- zum Ziel-Host kann also mehrere Hops umfassen. Router bestimmen dabei den optimalen Pfad und leiten die Pakete entsprechend weiter, wobei jeder Hop eine Entscheidung über den nächsten Weiterleitungsschritt trifft."
  },
  {
    "question": "Bei der Kapselung von Daten auf der Vermittlungsschicht wird...",
    "options": [
      "ein Frame-Header hinzugefügt",
      "ein IP-Header hinzugefügt",
      "ein TCP-Header hinzugefügt",
      "ein Anwendungs-Header hinzugefügt"
    ],
    "correct": 1,
    "explain": "Bei der **Kapselung auf der Vermittlungsschicht** wird ein **IP-Header** zu den Daten (der PDU) der Transportschicht hinzugefügt. Dieser Vorgang wandelt das Segment (Transportschicht-PDU) in ein IP-Paket (Vermittlungsschicht-PDU) um. Der IP-Header enthält wichtige Informationen wie die Quell- und Ziel-IP-Adresse, die für die Übertragung durch das Netzwerk erforderlich sind. Frame-Header werden erst auf der Sicherungsschicht (Schicht 2) hinzugefügt, TCP-Header gehören zur Transportschicht (Schicht 4), und Anwendungs-Header stammen aus der Anwendungsschicht (Schicht 7)."
  },
  {
    "question": "Die IP-Adressierungsinformationen eines Pakets bleiben vom Quell-Host bis zum Ziel-Host immer unverändert.",
    "options": ["Wahr", "Falsch"],
    "correct": 1,
    "explain": "Diese Aussage ist **falsch**. Obwohl IP-Adressierungsinformationen eines Pakets in den meisten Fällen vom Quell-Host bis zum Ziel-Host unverändert bleiben, gibt es eine wichtige Ausnahme: Network Address Translation (NAT) für IPv4. Bei NAT werden die Quell- oder Ziel-IP-Adressen geändert, typischerweise um private IP-Adressen aus internen Netzwerken in öffentliche IP-Adressen für das Internet zu übersetzen. Dies ist eine häufige Praxis in privaten Netzwerken und ermöglicht es mehreren Geräten, eine gemeinsame öffentliche IP-Adresse zu nutzen."
  },
  {
    "question": "Welche der folgenden Eigenschaften trifft NICHT auf das IP-Protokoll zu?",
    "options": [
      "Verbindungslos",
      "Unzuverlässig (Best-Effort)",
      "Medienunabhängig",
      "Garantierte Paketübertragung"
    ],
    "correct": 3,
    "explain": "**Garantierte Paketübertragung** trifft nicht auf das IP-Protokoll zu. IP wurde als Protokoll mit geringem Overhead konzipiert und bietet nur die grundlegenden Funktionen zur Paketübertragung. Es hat folgende Haupteigenschaften:\n\n1. **Verbindungslos** - Es wird keine explizite Verbindung mit dem Ziel aufgebaut, bevor Daten gesendet werden\n2. **Unzuverlässig (Best-Effort)** - Die Paketübertragung wird nicht garantiert, Pakete können verloren gehen\n3. **Medienunabhängig** - IP funktioniert unabhängig vom physischen Medium (Kupfer, Glasfaser, Wireless)\n\nDie Garantie der Paketübertragung, einschließlich Funktionen wie Nachverfolgung von Paketen und Sicherstellung der Zustellung, wird in höheren Schichten implementiert, insbesondere durch TCP auf der Transportschicht."
  },
  {
    "question": "Wie unterscheidet sich die verbindungslose Kommunikation von der verbindungsorientierten Kommunikation?",
    "options": [
      "Verbindungslos bedeutet, dass keine physische Verbindung existiert",
      "Verbindungslos erfordert mehr Overhead als verbindungsorientiert",
      "Bei verbindungsloser Kommunikation wird keine dedizierte Ende-zu-Ende-Verbindung vor der Datenübertragung hergestellt",
      "Verbindungslose Kommunikation kann nur in lokalen Netzwerken verwendet werden"
    ],
    "correct": 2,
    "explain": "Bei **verbindungsloser Kommunikation** wird **keine dedizierte Ende-zu-Ende-Verbindung vor der Datenübertragung hergestellt**. Das bedeutet, dass Pakete ohne vorherigen Handshake oder Verbindungsaufbau gesendet werden. IP als verbindungsloses Protokoll sendet Pakete einfach an das Ziel, ähnlich wie beim Versenden eines Briefes ohne vorherige Benachrichtigung des Empfängers. \n\nIm Gegensatz dazu wird bei verbindungsorientierter Kommunikation (wie TCP) zuerst eine Verbindung aufgebaut, bevor Daten übertragen werden. Verbindungslose Kommunikation verursacht weniger Overhead (nicht mehr), ist nicht auf lokale Netzwerke beschränkt und bezieht sich auf das logische Verbindungskonzept, nicht auf physische Verbindungen."
  },
  {
    "question": "Welcher Vorgang wird durchgeführt, wenn ein Router ein Paket für ein Medium mit kleinerer MTU (Maximum Transmission Unit) vorbereiten muss?",
    "options": [
      "Paketfragmentierung",
      "Paketkonsolidierung",
      "Header-Kompression",
      "Protokollkonvertierung"
    ],
    "correct": 0,
    "explain": "Wenn ein Router ein Paket für ein Medium mit kleinerer MTU (Maximum Transmission Unit) vorbereiten muss, führt er eine **Paketfragmentierung** durch. Bei diesem Vorgang wird das ursprüngliche IP-Paket in kleinere Pakete aufgeteilt, die der MTU des Zielmediums entsprechen. Jedes dieser Fragmente erhält einen eigenen IP-Header mit Informationen, die später die Rekonstruktion des ursprünglichen Pakets ermöglichen. \n\nDie Fragmente werden dann unabhängig voneinander weitergeleitet und erst am endgültigen Ziel wieder zusammengesetzt. Die Paketfragmentierung verursacht jedoch zusätzliche Latenz und Overhead, weshalb moderne Netzwerke versuchen, sie zu vermeiden. Bei IPv6 dürfen Router keine Fragmentation mehr durchführen."
  },
  {
    "question": "Der Prozess der Entkapselung auf der Vermittlungsschicht wird durchgeführt von:",
    "options": [
      "Dem Quell-Host des IP-Pakets",
      "Jedem Router auf dem Weg zum Ziel",
      "Dem Ziel-Host des IP-Pakets",
      "Dem Gateway zwischen verschiedenen Netzwerken"
    ],
    "correct": 2,
    "explain": "Der Prozess der **Entkapselung** auf der Vermittlungsschicht wird vom **Ziel-Host des IP-Pakets** durchgeführt. Wenn ein IP-Paket sein Ziel erreicht, prüft der Ziel-Host den IP-Header des Pakets. Falls die im Header enthaltene Ziel-IP-Adresse mit der eigenen IP-Adresse übereinstimmt, entfernt der Host den IP-Header vom Paket (Entkapselung). \n\nDie verbleibende PDU der Schicht 4 (typischerweise ein TCP- oder UDP-Segment) wird dann an die entsprechenden Dienste auf der Transportschicht übergeben. Router und Gateways auf dem Weg lesen zwar den IP-Header zur Weiterleitungsentscheidung, führen aber keine vollständige Entkapselung durch, da sie nur die Weiterleitungsinformationen benötigen."
  },
  {
    "question": "Die MTU (Maximum Transmission Unit) wird definiert durch:",
    "options": [
      "Die Transportschicht (Schicht 4)",
      "Die Vermittlungsschicht (Schicht 3)",
      "Die Sicherungsschicht (Schicht 2)",
      "Die Anwendungsschicht (Schicht 7)"
    ],
    "correct": 2,
    "explain": "Die **MTU (Maximum Transmission Unit)** wird durch die **Sicherungsschicht (OSI-Schicht 2)** definiert. Die MTU gibt die maximale Größe einer Protokolldateneinheit (PDU) an, die ein Medium transportieren kann. Diese Information wird von der Sicherungsschicht nach oben an die Vermittlungsschicht weitergegeben, damit diese entscheiden kann, wie groß IP-Pakete sein dürfen. \n\nWenn ein Paket größer ist als die MTU des Zielmediums, muss es fragmentiert werden. Die MTU ist ein Merkmal des spezifischen Übertragungsmediums und variiert je nach Technologie (z.B. Ethernet, WLAN, PPP). Die Sicherungsschicht bereitet die IP-Pakete für die Übertragung über das jeweilige Kommunikationsmedium vor und muss daher dessen Kapazitätsgrenzen kennen und berücksichtigen."
  },
  {
    "question": "Bei IPv6 können Router Pakete fragmentieren, wenn sie für das Zielmedium zu groß sind.",
    "options": ["Wahr", "Falsch"],
    "correct": 1,
    "explain": "Diese Aussage ist **falsch**. Bei IPv6 dürfen Router Pakete **nicht** fragmentieren. Dies ist ein wesentlicher Unterschied zu IPv4. Bei IPv6 muss die Fragmentierung, falls erforderlich, durch den sendenden Host erfolgen, nicht durch Router auf dem Übertragungsweg. Dieses Design wurde gewählt, um die Verarbeitungszeit in Routern zu reduzieren und die Effizienz des Routings zu verbessern. \n\nIPv6 verwendet Verfahren wie Path MTU Discovery, um die kleinste MTU auf dem Pfad zum Ziel zu ermitteln, damit der Sender bereits Pakete in der passenden Größe erzeugen kann. Dies reduziert den Overhead und die Latenz im Netzwerk, da die rechenintensive Fragmentierung vermieden wird."
  },
  {
    "question": "Welches der folgenden Protokolle ist KEIN Protokoll der Vermittlungsschicht?",
    "options": [
      "IPv4",
      "IPv6",
      "OSPF",
      "TCP"
    ],
    "correct": 3,
    "explain": "**TCP (Transmission Control Protocol)** ist kein Protokoll der Vermittlungsschicht, sondern gehört zur **Transportschicht (OSI-Schicht 4)**. Die Transportschicht ist für die Ende-zu-Ende-Kommunikation zwischen Anwendungen auf verschiedenen Hosts zuständig und bietet Dienste wie Verbindungsaufbau, Flusskontrolle und Zuverlässigkeit.\n\nDie anderen genannten Protokolle gehören zur Vermittlungsschicht (OSI-Schicht 3):\n- **IPv4 und IPv6** sind die grundlegenden Internetprotokolle für die Adressierung und Paketweiterleitung\n- **OSPF (Open Shortest Path First)** ist ein Routing-Protokoll zur Bestimmung optimaler Pfade zwischen Netzwerken\n\nDie Vermittlungsschicht konzentriert sich auf die Weiterleitung von Paketen zwischen verschiedenen Netzwerken, während die Transportschicht sich um die Kommunikation zwischen Anwendungen kümmert."
  },
  {
    "question": "Was geschieht mit dem Datenteil eines IP-Pakets während des Routings?",
    "options": [
      "Er wird komprimiert, um die Übertragung zu beschleunigen",
      "Er wird verschlüsselt, um die Sicherheit zu erhöhen",
      "Er wird verändert, um Routing-Informationen hinzuzufügen",
      "Er bleibt unverändert während der Vorgänge in der Vermittlungsschicht"
    ],
    "correct": 3,
    "explain": "Der **Datenteil eines IP-Pakets bleibt unverändert während der Vorgänge in der Vermittlungsschicht**. Beim Routing werden nur die Adressinformationen im IP-Header des Pakets untersucht, um Weiterleitungsentscheidungen zu treffen. Der Datenteil, der die gekapselte Transportschicht-PDU enthält, wird nicht geändert, gelesen oder verarbeitet.\n\nDies ist ein wichtiges Prinzip der Schichtenarchitektur: Jede Schicht interagiert nur mit den für sie relevanten Informationen. Router als Vermittlungsschichtgeräte kümmern sich nur um die Vermittlungsschichtinformationen (den IP-Header) und ignorieren den Inhalt des Pakets. Kompression, Verschlüsselung oder Modifikation des Datenteils würden in anderen Schichten erfolgen, nicht während des Routings."
  },
  {
    "question": "Welcher Prozess findet statt, wenn ein Paket bei einem Ziel-Host ankommt und die Ziel-IP-Adresse im Header mit der IP-Adresse des Hosts übereinstimmt?",
    "options": [
      "Kapselung",
      "Fragmentierung",
      "Entkapselung",
      "Konsolidierung"
    ],
    "correct": 2,
    "explain": "Wenn ein Paket bei einem Ziel-Host ankommt und die Ziel-IP-Adresse im Header mit der IP-Adresse des Hosts übereinstimmt, findet der Prozess der **Entkapselung** statt. Der Ziel-Host prüft zunächst den IP-Header und vergleicht die Ziel-IP-Adresse mit seiner eigenen Adresse. Bei Übereinstimmung entfernt der Host den IP-Header vom Paket (Entkapselung).\n\nDie verbleibende PDU der Schicht 4 (typischerweise ein TCP- oder UDP-Segment) wird dann an den entsprechenden Dienst auf der Transportschicht weitergeleitet. Dieser Prozess ist das Gegenstück zur Kapselung, die am Absender stattfindet. Durch die Entkapselung werden die Daten für die Verarbeitung durch höhere Schichten vorbereitet."
  },
  {
    "question": "Warum gilt IP als ein Protokoll mit 'geringem Overhead'?",
    "options": [
      "Weil es starke Datenkompression verwendet",
      "Weil es nur die grundlegenden Funktionen zur Paketübertragung bietet und keine Verwaltung des Paketflusses übernimmt",
      "Weil es nur in lokalen Netzwerken eingesetzt wird",
      "Weil es ausschließlich kleine Pakete überträgt"
    ],
    "correct": 1,
    "explain": "IP gilt als Protokoll mit **geringem Overhead**, weil es **nur die grundlegenden Funktionen zur Paketübertragung bietet und keine Verwaltung des Paketflusses übernimmt**. Es wurde bewusst minimalistisch konzipiert, um effizient zu arbeiten und nur die notwendigen Funktionen bereitzustellen, die für die Übertragung eines Pakets von einer Quelle zu einem Ziel über verbundene Netzwerke erforderlich sind.\n\nIP enthält keine zusätzlichen Felder im Header für Funktionen wie:\n- Verbindungsaufbau und -management\n- Nachverfolgung von Paketen\n- Fehlerkorrektur\n- Flusskontrolle\n\nDiese Funktionen werden stattdessen von höheren Schichten wie TCP (Transportschicht) übernommen. Durch diese Aufteilung der Verantwortlichkeiten kann IP sehr schlank und effizient bleiben."
  },
  {
    "question": "Was passiert, wenn ein IP-Paket während der Übertragung verloren geht oder beschädigt wird?",
    "options": [
      "IP kümmert sich automatisch um die erneute Übertragung des Pakets",
      "Der nächste Router auf dem Pfad sendet eine Fehlermeldung zurück an den Absender",
      "IP hat keine eingebauten Mechanismen zur Behandlung solcher Fehler; höhere Protokollschichten müssen sich darum kümmern",
      "Das Paket wird automatisch in kleinere Teile fragmentiert und erneut gesendet"
    ],
    "correct": 2,
    "explain": "Wenn ein IP-Paket während der Übertragung verloren geht oder beschädigt wird, hat **IP keine eingebauten Mechanismen zur Behandlung solcher Fehler; höhere Protokollschichten müssen sich darum kümmern**. Als unzuverlässiges (Best-Effort) Protokoll garantiert IP nicht, dass alle Pakete korrekt und vollständig übertragen werden.\n\nIP-Pakete enthalten zwar Informationen über den Zustellort, aber keine Mechanismen, um den Absender über eine erfolgreiche Zustellung zu informieren oder Pakete erneut zu übertragen. Folgende Probleme können auftreten:\n- Pakete können verloren gehen\n- Pakete können beschädigt werden\n- Pakete können in der falschen Reihenfolge ankommen\n\nDie Behebung dieser Probleme wird typischerweise von höheren Schichten übernommen, insbesondere von TCP auf der Transportschicht, das Mechanismen wie Sequenznummern, Bestätigungen und erneute Übertragungen implementiert."
  },
  {
    "question": "Die Medienunabhängigkeit des IP-Protokolls bedeutet, dass:",
    "options": [
      "IP-Pakete nur über ein bestimmtes Medium übertragen werden können",
      "IP nur mit bestimmten Protokollen der Sicherungsschicht zusammenarbeiten kann",
      "IP-Pakete über verschiedene physische Medien wie Kupfer, Glasfaser oder drahtlos übertragen werden können",
      "IP keine Vermittlungsschichtprotokolle benötigt"
    ],
    "correct": 2,
    "explain": "Die **Medienunabhängigkeit** des IP-Protokolls bedeutet, dass **IP-Pakete über verschiedene physische Medien wie Kupfer, Glasfaser oder drahtlos übertragen werden können**. Der Betrieb des IP ist unabhängig vom zugrundeliegenden physischen Medium, das die Daten transportiert.\n\nIP-Pakete können übertragen werden als:\n- Elektrische Signale über Kupferkabel (z.B. Ethernet, serielle Verbindungen)\n- Optische Signale über Glasfaserkabel\n- Funksignale bei drahtlosen Übertragungen (z.B. WLAN, Mobilfunk)\n\nDie Sicherungsschicht (OSI-Schicht 2) übernimmt die Aufgabe, das IP-Paket für die Übertragung über das jeweilige Medium vorzubereiten. Diese Abstraktion vom physischen Medium ist ein wichtiges Design-Prinzip des Internet und ermöglicht es, IP über praktisch jede Art von Netzwerkinfrastruktur zu nutzen."
  },
  {
    "question": "Was unterscheidet das Routing auf der Vermittlungsschicht vom Switching auf der Sicherungsschicht?",
    "options": [
      "Routing ist schneller als Switching",
      "Routing betrachtet Quell- und Ziel-MAC-Adressen, Switching betrachtet IP-Adressen",
      "Routing nutzt IP-Adressen und ermöglicht die Kommunikation zwischen verschiedenen Netzwerken, Switching nutzt MAC-Adressen und funktioniert innerhalb eines Netzwerks",
      "Routing ist auf lokale Netzwerke beschränkt, Switching funktioniert über Netzwerkgrenzen hinweg"
    ],
    "correct": 2,
    "explain": "**Routing auf der Vermittlungsschicht** und **Switching auf der Sicherungsschicht** unterscheiden sich grundlegend in ihren Adressierungsmethoden und Einsatzbereichen:\n\n**Routing (Vermittlungsschicht/Schicht 3):**\n- Nutzt logische IP-Adressen (z.B. 192.168.1.1)\n- Ermöglicht die Kommunikation zwischen verschiedenen Netzwerken\n- Trifft Weiterleitungsentscheidungen basierend auf Netzwerkadressen\n- Kann komplexe Pfadbestimmungen über mehrere Hops hinweg durchführen\n- Wird von Routern implementiert\n\n**Switching (Sicherungsschicht/Schicht 2):**\n- Nutzt physische MAC-Adressen (z.B. 00:1A:2B:3C:4D:5E)\n- Funktioniert nur innerhalb eines einzelnen Netzwerks\n- Trifft Weiterleitungsentscheidungen basierend auf Hardware-Adressen\n- Kann keine Pakete zwischen verschiedenen Netzwerken weiterleiten\n- Wird von Switches implementiert\n\nDie Kombination beider Technologien ermöglicht die effiziente Kommunikation sowohl innerhalb als auch zwischen Netzwerken."
  },
  {
        "question": "Welches Feld im IPv4-Paket-Header identifiziert das Protokoll der darüber liegenden Schicht?",
        "options": [
            "TTL",
            "Header Checksum",
            "Protocol",
            "Version"
        ],
        "correct": 2,
        "explain": "Das **Protocol-Feld** im IPv4-Header identifiziert das Protokoll der darüber liegenden Schicht. Es enthält einen 8-Bit-Binärwert, der den Payload-Typ der Paketdaten angibt, damit die Vermittlungsschicht die Daten an das entsprechende Protokoll der höheren Schicht übergeben kann. Häufige Werte sind beispielsweise:\n\n- ICMP: 1\n- TCP: 6\n- UDP: 17\n\nDiese Kennung ist essentiell für die korrekte Verarbeitung der Daten nach dem Routing."
    },
    {
        "question": "Welcher Binärwert ist im Versionsfeld eines IPv4-Paket-Headers enthalten?",
        "options": [
            "0100",
            "0110",
            "0010",
            "1000"
        ],
        "correct": 0,
        "explain": "Im Versionsfeld eines IPv4-Paket-Headers ist der 4-Bit-Binärwert **0100** enthalten. Diese Binärzahl entspricht dezimal der Zahl 4 und identifiziert das Paket eindeutig als IP-Paket der Version 4. Diese Information ist grundlegend für die korrekte Interpretation des gesamten Headers durch alle beteiligten Netzwerkgeräte, da verschiedene IP-Versionen unterschiedliche Header-Strukturen aufweisen können."
    },
    {
        "question": "Das TTL-Feld in einem IPv4-Paket wird an jedem Router, den das Paket passiert, um eins erhöht.",
        "options": ["Wahr", "Falsch"],
        "correct": 1,
        "explain": "Diese Aussage ist **falsch**. Das Time-to-Live (TTL)-Feld in einem IPv4-Paket wird bei jedem Router, den das Paket passiert, um eins **verringert** (dekrementiert), nicht erhöht. \n\nDer anfängliche TTL-Wert wird vom absendenden Gerät festgelegt. Dieser Mechanismus dient dazu, Endlosschleifen im Netzwerk zu verhindern. Wenn der TTL-Wert auf Null sinkt, verwirft der Router das Paket und sendet eine Internet Control Message Protocol (ICMP)-Zeitüberschreitungsnachricht an die Quell-IP-Adresse zurück. Da der Router den TTL-Wert ändert, muss er auch die Header-Prüfsumme neu berechnen."
    },
    {
        "question": "Welche der folgenden Felder werden spezifisch für die Handhabung von fragmentierten Paketen verwendet?",
        "options": [
            "Version, Protocol, TTL",
            "Identification, Flags, Fragment Offset",
            "DSCP, ECN, Total Length",
            "Header Checksum, Source IP, Destination IP"
        ],
        "correct": 1,
        "explain": "Die Felder **Identification, Flags und Fragment Offset** werden spezifisch für die Handhabung von fragmentierten Paketen verwendet. \n\n- **Identification**: Identifiziert eindeutig das ursprüngliche Paket, sodass alle Fragmente desselben Pakets denselben Identifikationswert haben\n- **Flags**: Enthalten Bits, die angeben, ob das Paket fragmentiert werden darf und ob weitere Fragmente folgen\n- **Fragment Offset**: Gibt die Position des Fragments innerhalb des ursprünglichen IP-Pakets an\n\nFragmentierung kann notwendig sein, wenn ein Router ein Paket von einem Medium zu einem anderen mit kleinerer MTU (Maximum Transmission Unit) weiterleiten muss."
    },
    {
        "question": "Die Quell-IPv4-Adresse in einem IPv4-Paket-Header kann welche Art(en) von Adressen enthalten?",
        "options": [
            "Nur Unicast-Adressen",
            "Unicast- oder Multicast-Adressen",
            "Unicast-, Multicast- oder Broadcast-Adressen",
            "Nur Multicast-Adressen"
        ],
        "correct": 0,
        "explain": "Die Quell-IPv4-Adresse in einem IPv4-Paket-Header kann **nur Unicast-Adressen** enthalten. \n\nEine Unicast-Adresse identifiziert eindeutig ein einzelnes Netzwerkgerät. Dies ist logisch, da ein Paket immer von genau einem Gerät stammen muss. \n\nIm Gegensatz dazu kann die Ziel-IPv4-Adresse eine Unicast-, Multicast- oder Broadcast-Adresse sein, da ein Paket an ein einzelnes Gerät, eine Gruppe von Geräten oder alle Geräte in einem Netzwerksegment gesendet werden kann."
    },
    {
        "question": "Ein Router muss die Header-Prüfsumme eines IPv4-Pakets neu berechnen, wenn er dieses weiterleitet. Warum?",
        "options": [
            "Weil der Router immer die Ziel-IP-Adresse ändert",
            "Weil der Header durch die Änderung des TTL-Feldes modifiziert wird",
            "Weil die DSCP-Bits bei jeder Weiterleitung angepasst werden",
            "Weil fragmentierte Pakete neu zusammengesetzt werden müssen"
        ],
        "correct": 1,
        "explain": "Ein Router muss die Header-Prüfsumme eines IPv4-Pakets neu berechnen, **weil der Header durch die Änderung des TTL-Feldes modifiziert wird**. \n\nBei jedem Hop (Weiterleitung durch einen Router) wird der TTL-Wert um eins verringert. Da sich dadurch der Inhalt des Headers ändert, stimmt die ursprüngliche Prüfsumme nicht mehr. Die Header-Prüfsumme dient zur Erkennung von beschädigten Headers und muss daher nach jeder Headeränderung neu berechnet werden, um die Integrität des Headers weiterhin überprüfen zu können."
    },
    {
        "question": "Das DiffServ-Feld (DS-Feld) im IPv4-Header dient primär welchem Zweck?",
        "options": [
            "Es enthält die Versionsnummer des IP-Protokolls",
            "Es bestimmt die Priorität des Pakets",
            "Es identifiziert das Protokoll der höheren Schicht",
            "Es gibt die Länge des Headers an"
        ],
        "correct": 1,
        "explain": "Das DiffServ-Feld (DS-Feld) im IPv4-Header dient primär dazu, **die Priorität des Pakets zu bestimmen**. \n\nDieses 8-Bit-Feld wurde früher als Type of Service (ToS)-Feld bezeichnet und ist in zwei Teile unterteilt:\n- Die sechs höchstwertigen Bits bilden den Differentiated Services Code Point (DSCP)\n- Die letzten zwei Bits sind die Explicit Congestion Notification (ECN)-Bits\n\nDurch die Angabe der Priorität können Netzwerkgeräte bestimmte Pakete bevorzugt behandeln, was für zeitkritische Anwendungen wie VoIP oder Videostreaming wichtig ist."
    },
    {
        "question": "Die beiden Felder im IPv4-Header, die normalerweise während der gesamten Übertragung unverändert bleiben, sind die Quell- und Ziel-IP-Adresse.",
        "options": ["Wahr", "Falsch"],
        "correct": 0,
        "explain": "Diese Aussage ist **wahr**. Die Quell- und Ziel-IP-Adressen im IPv4-Header bleiben normalerweise während der gesamten Übertragung unverändert. \n\nDiese Felder geben an, woher das Paket stammt (Quell-IP) und wohin es übertragen werden soll (Ziel-IP). Im Gegensatz zu anderen Feldern wie dem TTL-Wert, der bei jedem Hop dekrementiert wird, oder möglicherweise den Flags bei Fragmentierung, ändern sich diese Adressfelder während des normalen Routings nicht. \n\nAusnahmen können bei speziellen Techniken wie Network Address Translation (NAT) auftreten, die jedoch nicht Teil des standardmäßigen IP-Routings sind."
    },
    {
        "question": "Welches Feld im IPv4-Header hat eine Länge von 8 Bit und bestimmt die maximale Anzahl von Routern, die ein Paket passieren kann?",
        "options": [
            "Version",
            "Protocol",
            "Time-to-Live (TTL)",
            "Fragment Offset"
        ],
        "correct": 2,
        "explain": "Das **Time-to-Live (TTL)-Feld** im IPv4-Header hat eine Länge von 8 Bit und bestimmt die maximale Anzahl von Routern (Hops), die ein Paket passieren kann. \n\nDer anfängliche TTL-Wert wird vom absendenden Gerät festgelegt und bei jedem Router um eins verringert. Erreicht der Wert Null, wird das Paket verworfen und eine ICMP-Zeitüberschreitungsnachricht an den Absender zurückgeschickt. Dies verhindert, dass Pakete endlos im Netzwerk kreisen können, wenn beispielsweise durch fehlerhafte Routing-Tabellen eine Schleife entsteht."
    },
    {
        "question": "Was geschieht, wenn ein Router ein IPv4-Paket mit TTL-Wert 1 empfängt?",
        "options": [
            "Er leitet das Paket normal weiter",
            "Er erhöht den TTL-Wert auf 2",
            "Er verwirft das Paket und sendet eine ICMP-Nachricht",
            "Er fragmentiert das Paket in kleinere Einheiten"
        ],
        "correct": 2,
        "explain": "Wenn ein Router ein IPv4-Paket mit TTL-Wert 1 empfängt, **verringert er den Wert auf 0, verwirft das Paket und sendet eine ICMP-Zeitüberschreitungsnachricht** an die Quell-IP-Adresse zurück. \n\nDer Time-to-Live (TTL)-Wert wird bei jeder Verarbeitung durch einen Router um eins verringert. Wenn der Router den TTL-Wert auf Null dekrementiert, darf das Paket nicht mehr weitergeleitet werden. Dies ist ein wichtiger Mechanismus, um Routing-Schleifen zu verhindern, die sonst zu einer Überlastung des Netzwerks führen könnten. Die ICMP-Nachricht (Typ 11 - Time Exceeded) informiert den Absender darüber, dass das Paket sein Ziel nicht erreicht hat, weil sein TTL-Wert abgelaufen ist."
    },
    {
    "question": "Wie viele Bits umfasst eine IPv6-Adresse?",
    "options": [
      "64 Bits",
      "96 Bits",
      "128 Bits",
      "256 Bits"
    ],
    "correct": 2,
    "explain": "Eine IPv6-Adresse umfasst **128 Bits**. Im Vergleich dazu hat eine IPv4-Adresse nur 32 Bits. Diese deutliche Vergrößerung des Adressraums ist eines der wichtigsten Merkmale von IPv6 und ermöglicht die Bereitstellung einer nahezu unbegrenzten Anzahl eindeutiger IP-Adressen (etwa 340 Sextillionen), was eines der Hauptprobleme von IPv4 - den Mangel an verfügbaren Adressen - löst."
  },
  {
    "question": "NAT (Network Address Translation) wird mit IPv6 vollständig überflüssig.",
    "options": ["Wahr", "Falsch"],
    "correct": 0,
    "explain": "Diese Aussage ist **wahr**. Einer der Hauptvorteile von IPv6 ist, dass aufgrund des enormen Adressraums von IPv6 die Notwendigkeit für NAT entfällt. In IPv4-Netzwerken wird NAT hauptsächlich eingesetzt, um mehreren Geräten die Nutzung einer einzigen öffentlichen IPv4-Adresse zu ermöglichen. Mit IPv6 steht eine so große Anzahl öffentlicher Adressen zur Verfügung, dass jedes Gerät seine eigene öffentliche IPv6-Adresse haben kann. Dies vermeidet die durch NAT verursachten Probleme bei Anwendungen, die eine Ende-zu-Ende-Netzwerkverbindung benötigen."
  },
  {
    "question": "Welches der folgenden Felder ist im IPv6-Header neu hinzugekommen und war nicht Teil des IPv4-Headers?",
    "options": [
      "Traffic Class",
      "Flow Label",
      "Hop Limit",
      "Payload Length"
    ],
    "correct": 1,
    "explain": "Das **Flow Label** ist ein neues Feld, das im IPv6-Header eingeführt wurde und nicht im IPv4-Header vorhanden war. Dieses 20-Bit-Feld lässt darauf schließen, dass alle Pakete mit demselben Flow Label auf die gleiche Weise vom Router verarbeitet werden sollten. Es wurde entwickelt, um Echtzeitverkehr wie Streaming-Medien und Sprachkommunikation zu unterstützen.\n\nDie anderen Optionen sind entweder umbenannte oder modifizierte Felder aus dem IPv4-Header:\n- Traffic Class entspricht dem IPv4-Feld 'Differentiated Services'\n- Hop Limit ersetzt das IPv4-Feld 'TTL' (Time to Live)\n- Payload Length entspricht dem IPv4-Feld 'Gesamtlänge', bezieht sich aber nur auf die Nutzlast ohne den Header"
  },
  {
    "question": "Wie viele Byte umfasst ein IPv6-Header?",
    "options": [
      "20 Byte",
      "40 Byte",
      "60 Byte",
      "128 Byte"
    ],
    "correct": 1,
    "explain": "Ein IPv6-Header hat eine **feste Länge von 40 Byte**. Im Gegensatz dazu hat ein IPv4-Header eine Grundlänge von 20 Byte, kann aber mit Optionen auf bis zu 60 Byte erweitert werden. Der IPv6-Header ist hauptsächlich aufgrund der längeren Quell- und Zieladressen (jeweils 16 Byte bei IPv6 im Vergleich zu 4 Byte bei IPv4) größer. Trotz des größeren Headers wurde die Struktur des IPv6-Headers vereinfacht, indem einige IPv4-Felder entfernt wurden, was eine effizientere Paketverarbeitung ermöglicht."
  },
  {
    "question": "Eines der Hauptprobleme von IPv4 ist die Beeinträchtigung der Ende-zu-Ende-Konnektivität durch die Verwendung von NAT.",
    "options": ["Wahr", "Falsch"],
    "correct": 0,
    "explain": "Diese Aussage ist **wahr**. Die Verwendung von NAT (Network Address Translation) in IPv4-Netzwerken beeinträchtigt tatsächlich die Ende-zu-Ende-Konnektivität. NAT ermöglicht es mehreren Geräten, eine einzige öffentliche IPv4-Adresse zu teilen, indem es als Mittler zwischen den internen Netzwerkgeräten und dem Internet fungiert. Dies verbirgt jedoch die tatsächlichen IPv4-Adressen der internen Hosts und erschwert Anwendungen und Diensten, die eine direkte Ende-zu-Ende-Verbindung benötigen, die Kommunikation. Protokolle und Anwendungen müssen oft spezielle Mechanismen implementieren, um NAT-Traversal zu ermöglichen."
  },
  {
    "question": "Welche dieser Aussagen trifft auf den Vergleich zwischen IPv4- und IPv6-Headern zu?",
    "options": [
      "Der IPv6-Header enthält mehr Felder als der IPv4-Header",
      "Der IPv6-Header hat eine variable Länge, während der IPv4-Header eine feste Länge hat",
      "Der IPv6-Header enthält keine Prüfsumme, während der IPv4-Header eine Header-Prüfsumme enthält",
      "Der IPv6-Header behält alle Felder des IPv4-Headers bei und fügt nur neue hinzu"
    ],
    "correct": 2,
    "explain": "Der IPv6-Header enthält **keine Prüfsumme**, während der IPv4-Header eine Header-Prüfsumme enthält. Diese Veränderung wurde vorgenommen, weil die Prüffunktion bereits auf der darunterliegenden und darüberliegenden Schicht ausgeführt wird. Durch den Wegfall der Prüfsumme muss diese nicht von jedem Router neu berechnet werden, wenn er das Feld 'Hop Limit' dekrementiert, was die Leistungsfähigkeit des Netzwerks verbessert. \n\nDie anderen Aussagen sind nicht korrekt:\n- Der IPv6-Header ist mit 40 Byte zwar größer als der IPv4-Basis-Header (20 Byte), enthält aber tatsächlich weniger Felder, da einige IPv4-Felder entfernt wurden\n- Der IPv6-Header hat eine feste Länge von 40 Byte, während der IPv4-Header eine variable Länge von 20-60 Byte haben kann\n- Der IPv6-Header behält einige Felder bei, ändert andere und entfernt auch einige IPv4-Felder komplett"
  },
  {
    "question": "Wie viele eindeutige IPv4-Adressen gibt es theoretisch?",
    "options": [
      "Etwa 4,3 Millionen",
      "Etwa 4,3 Milliarden",
      "Etwa 4,3 Billionen",
      "Etwa 4,3 Biljarden"
    ],
    "correct": 1,
    "explain": "Es gibt theoretisch **etwa 4,3 Milliarden** (genauer 4.294.967.296) mögliche IPv4-Adressen. Diese Zahl ergibt sich aus der Berechnung von 2^32, da IPv4-Adressen 32 Bit umfassen. Diese begrenzte Anzahl an verfügbaren Adressen ist eines der Hauptprobleme von IPv4, da die Anzahl der internetfähigen Geräte weltweit diesen Wert längst überschritten hat. Dies ist einer der Hauptgründe für die Entwicklung und Einführung von IPv6."
  },
  {
    "question": "Welches Feld im IPv6-Header entspricht dem 'Protocol'-Feld im IPv4-Header?",
    "options": [
      "Payload Length",
      "Next Header",
      "Flow Label",
      "Traffic Class"
    ],
    "correct": 1,
    "explain": "Das **Next Header**-Feld im IPv6-Header entspricht dem 'Protocol'-Feld im IPv4-Header. Dieses 8-Bit-Feld gibt den Typ der Daten an, die das Paket transportiert, sodass die Vermittlungsschicht die Daten an das entsprechende Protokoll der höheren Schicht übergeben kann. Es identifiziert beispielsweise, ob die Nutzdaten TCP, UDP oder ein anderes Protokoll verwenden."
  },
  {
    "question": "IPv6 wurde entwickelt, um alle Protokolle zu ersetzen, die zur Erweiterung der Lebensdauer von IPv4 entwickelt wurden.",
    "options": ["Wahr", "Falsch"],
    "correct": 1,
    "explain": "Diese Aussage ist **falsch**. Während IPv6 entwickelt wurde, um die grundlegenden Einschränkungen von IPv4 zu überwinden (insbesondere den begrenzten Adressraum und die durch NAT verursachten Probleme), war es nie dazu gedacht, alle Protokolle zu ersetzen, die zur Erweiterung der Lebensdauer von IPv4 entwickelt wurden. Viele Protokolle und Techniken, die mit IPv4 verwendet werden, haben ihre eigenen spezifischen Funktionen und Anwendungsfälle, die über die bloße Adressierung hinausgehen. Zudem gibt es für IPv6 eigene Erweiterungsprotokolle und -mechanismen, und in vielen Fällen wurden ähnliche Protokolle für IPv6 adaptiert oder neu entwickelt."
  },
  {
    "question": "Was bedeutet es, wenn in IPv6 das 'Hop Limit' eines Pakets auf 0 reduziert wird?",
    "options": [
      "Das Paket wird priorisiert und schneller weitergeleitet",
      "Das Paket wird verworfen und eine ICMPv6-Nachricht wird zurückgesendet",
      "Das Paket wird an den nächsten Router ohne Änderung weitergeleitet",
      "Das Paket wird fragmentiert, um die Übertragung zu optimieren"
    ],
    "correct": 1,
    "explain": "Wenn das **'Hop Limit'** eines IPv6-Pakets auf 0 reduziert wird, wird das Paket **verworfen**, und eine **ICMPv6 Time Exceeded** Nachricht wird an den sendenden Host zurückgeschickt. Diese Nachricht informiert den Absender darüber, dass das Paket sein Ziel nicht erreicht hat, weil das Hop-Limit überschritten wurde. Das Hop-Limit-Feld in IPv6 entspricht dem TTL-Feld (Time To Live) in IPv4 und verhindert, dass Pakete endlos im Netzwerk kreisen können, falls Routing-Schleifen auftreten."
  },
  {
    "question": "In welcher Wissenschaftlichen Notation wird der IPv6-Adressraum dargestellt?",
    "options": [
      "10^18",
      "10^24",
      "10^30",
      "10^36"
    ],
    "correct": 3,
    "explain": "Der IPv6-Adressraum wird in der wissenschaftlichen Notation **10^36** dargestellt, was 1 Sextillion entspricht. Genauer gesagt beträgt die Gesamtzahl der IPv6-Adressen 2^128 oder etwa 340.282.366.920.938.463.463.374.607.431.768.211.456, was ungefähr 340 Sextillionen entspricht. Diese enorme Menge wird oft mit der Anzahl der Sandkörner auf der Erde verglichen, um die Größenordnung zu veranschaulichen. Im Vergleich dazu hat IPv4 mit seinem 32-Bit-Adressraum nur 2^32 oder etwa 4,3 Milliarden Adressen."
  },
  {
    "question": "Router fragmentieren IPv6-Pakete auf dem Weg zum Ziel, wenn sie zu groß für ein Netzwerksegment sind.",
    "options": ["Wahr", "Falsch"],
    "correct": 1,
    "explain": "Diese Aussage ist **falsch**. Im Gegensatz zu IPv4 fragmentieren Router keine gerouteten IPv6-Pakete. Bei IPv6 muss die Fragmentierung, falls erforderlich, vom Absender selbst durchgeführt werden. Dies geschieht durch einen Mechanismus namens Path MTU Discovery (PMTUD), der die größtmögliche Paketgröße für den gesamten Pfad zum Ziel ermittelt. Diese Änderung wurde eingeführt, um die Effizienz der Router zu verbessern und die Wahrscheinlichkeit von Fragmentierungsangriffen zu verringern."
  },
  {
    "question": "Welches dieser Felder ist im IPv6-Header NICHT enthalten, war aber Teil des IPv4-Headers?",
    "options": [
      "Version",
      "Header-Prüfsumme",
      "Quelladresse",
      "Zieladresse"
    ],
    "correct": 1,
    "explain": "Die **Header-Prüfsumme** ist im IPv6-Header nicht enthalten, war aber Teil des IPv4-Headers. In IPv6 wurde diese Prüfsumme weggelassen, da die Prüffunktion bereits auf der darunterliegenden Schicht (z.B. Ethernet) und auf der darüberliegenden Schicht (z.B. TCP, UDP) ausgeführt wird. Dies verbessert die Leistung, da Router die Prüfsumme nicht neu berechnen müssen, wenn sie das Hop-Limit-Feld dekrementieren. \n\nDie anderen genannten Felder sind sowohl in IPv4 als auch in IPv6 vorhanden:\n- Das Versionsfeld identifiziert die IP-Version (4 für IPv4, 6 für IPv6)\n- Quell- und Zieladressen sind in beiden Protokollversionen enthalten, obwohl sie in IPv6 aufgrund der größeren Adresslänge (128 Bit vs. 32 Bit) mehr Platz einnehmen"
  },
  {
    "question": "Welche Funktion hat das 'Flow Label'-Feld im IPv6-Header?",
    "options": [
      "Es gibt die Gesamtlänge des IPv6-Pakets an",
      "Es identifiziert den nächsten Header nach dem IPv6-Header",
      "Es legt fest, dass Pakete mit demselben Label auf die gleiche Weise verarbeitet werden",
      "Es begrenzt die maximale Anzahl von Hops, die ein Paket durchlaufen kann"
    ],
    "correct": 2,
    "explain": "Das **Flow Label**-Feld im IPv6-Header hat die Funktion, dass es festlegt, dass **Pakete mit demselben Label auf die gleiche Weise verarbeitet werden** sollen. Dieses 20-Bit-Feld wurde eingeführt, um die Verarbeitung von Echtzeit-Datenströmen zu verbessern, indem es Routern ermöglicht, zusammengehörige Pakete zu identifizieren und ähnlich zu behandeln, ohne den tieferen Inhalt der Pakete inspizieren zu müssen. Dies kann besonders für Anwendungen wie VoIP oder Videostreaming nützlich sein, die eine konsistente Behandlung von Paketen erfordern."
  },
  {
    "question": "Welche Aussage zur Länge des IPv6-Headers im Vergleich zum IPv4-Header ist korrekt?",
    "options": [
      "Der IPv6-Header ist kürzer als der IPv4-Header",
      "Der IPv6-Header hat die gleiche Länge wie der IPv4-Header",
      "Der IPv6-Header ist länger als der IPv4-Header, aber enthält weniger Felder",
      "Der IPv6-Header ist länger als der IPv4-Header und enthält mehr Felder"
    ],
    "correct": 2,
    "explain": "Der IPv6-Header ist **länger als der IPv4-Header, aber enthält weniger Felder**. Der IPv6-Header hat eine feste Länge von 40 Byte, während der IPv4-Header eine Grundlänge von 20 Byte hat (mit Optionen bis zu 60 Byte). Trotz der größeren Länge wurde der IPv6-Header vereinfacht und enthält weniger Felder als der IPv4-Header. Der Hauptgrund für die größere Länge sind die IPv6-Adressen (Quell- und Zieladresse), die jeweils 16 Byte (128 Bit) umfassen, im Vergleich zu 4 Byte (32 Bit) bei IPv4. Die Reduzierung der Feldanzahl führt zu einer effizienteren Paketverarbeitung durch Router."
  },
  {
    "question": "Wie reduziert IPv6 die Komplexität der Netzwerkkonfiguration im Vergleich zu IPv4?",
    "options": [
      "Durch die Einführung von mehr Header-Feldern",
      "Durch die Reduzierung der Notwendigkeit von NAT",
      "Durch die Implementierung komplexerer Routing-Algorithmen",
      "Durch die Verringerung der Adresslänge"
    ],
    "correct": 1,
    "explain": "IPv6 reduziert die Netzwerkkomplexität hauptsächlich **durch die Reduzierung der Notwendigkeit von NAT** (Network Address Translation). NAT wurde in IPv4-Netzwerken weit verbreitet eingesetzt, um mit dem Mangel an öffentlichen IPv4-Adressen umzugehen, indem mehrere Geräte eine einzige öffentliche IP-Adresse teilen können. Dies fügt jedoch Komplexität hinzu, erhöht die Latenz und erschwert die Fehlerbehebung. \n\nDurch den riesigen Adressraum von IPv6 wird NAT weitgehend überflüssig, da genügend eindeutige öffentliche IPv6-Adressen für praktisch jedes Gerät zur Verfügung stehen. Dies vereinfacht die Netzwerkkonfiguration und ermöglicht eine bessere Ende-zu-Ende-Konnektivität. Außerdem unterstützt IPv6 Funktionen wie Stateless Address Autoconfiguration (SLAAC), die die Netzwerkkonfiguration weiter vereinfachen."
  },
  {
    "question": "Wofür werden Erweiterungs-Header (EH) in IPv6 verwendet?",
    "options": [
      "Um den IPv6-Header zu verkürzen und die Effizienz zu steigern",
      "Um Kompatibilität mit IPv4-Headern herzustellen",
      "Um optionale Netzwerkschichtinformationen wie Fragmentierung oder Sicherheit bereitzustellen",
      "Um beschädigte IPv6-Header zu reparieren"
    ],
    "correct": 2,
    "explain": "Erweiterungs-Header (EH) in IPv6 werden verwendet, um **optionale Netzwerkschichtinformationen wie Fragmentierung oder Sicherheit bereitzustellen**. Diese Header sind optional und werden zwischen dem IPv6-Header und der Payload angeordnet. Sie bieten zusätzliche Funktionen, ohne den Basis-IPv6-Header zu verkomplizieren. Zu den häufig verwendeten Erweiterungs-Headern gehören:\n\n- Fragment-Header (für die Fragmentierung von Paketen)\n- Authentication Header (AH) und Encapsulating Security Payload (ESP) für IPsec-Sicherheit\n- Hop-by-Hop Options Header\n- Destination Options Header\n- Routing Header (für spezielle Routing-Anforderungen)\n- Mobility Header (für Mobile IPv6)\n\nDies ermöglicht eine modulare Erweiterung der IPv6-Funktionalität, ohne den Basis-Header zu ändern oder zu verkomplizieren."
  },
  {
    "question": "Das Hop-Limit-Feld im IPv6-Header entspricht welchem Feld im IPv4-Header?",
    "options": [
      "Time-to-Live (TTL)",
      "Header Length",
      "Fragment Offset",
      "Flags"
    ],
    "correct": 0,
    "explain": "Das **Hop-Limit**-Feld im IPv6-Header entspricht dem **Time-to-Live (TTL)**-Feld im IPv4-Header. Beide Felder haben die gleiche Funktion: Sie begrenzen die Lebensdauer eines Pakets im Netzwerk, indem sie einen Zähler enthalten, der von jedem Router, der das Paket weiterleitet, um eins dekrementiert wird. Wenn der Wert 0 erreicht, wird das Paket verworfen. \n\nDieser Mechanismus verhindert, dass Pakete bei Routing-Schleifen endlos im Netzwerk zirkulieren können. Der Hauptunterschied liegt in der Bezeichnung: Während 'Time-to-Live' eine zeitliche Komponente suggeriert, verdeutlicht 'Hop-Limit' besser, dass es sich um die Anzahl der Router-Hops handelt, die ein Paket maximal durchlaufen kann."
  },
  {
    "question": "Welche Aussage zum Umgang mit Optionen im IPv6-Header im Vergleich zum IPv4-Header ist korrekt?",
    "options": [
      "IPv6 hat keine Optionen, da alle notwendigen Funktionen im Basis-Header enthalten sind",
      "IPv6 und IPv4 behandeln Optionen auf identische Weise",
      "IPv6 platziert Optionen in separaten Erweiterungs-Headern statt im Basis-Header",
      "IPv6 verwendet dasselbe Options-Feld wie IPv4, aber mit mehr verfügbaren Bits"
    ],
    "correct": 2,
    "explain": "IPv6 **platziert Optionen in separaten Erweiterungs-Headern statt im Basis-Header**. Dies ist ein wesentlicher Unterschied zum IPv4-Design, wo Optionen Teil des Basis-Headers sind und diesen auf bis zu 60 Byte verlängern können. \n\nDiese Änderung in IPv6 bietet mehrere Vorteile:\n1. Der Basis-IPv6-Header hat eine feste Länge von 40 Byte, was die Verarbeitung durch Router vereinfacht und beschleunigt\n2. Erweiterungs-Header müssen nur von Routern oder dem Zielhost verarbeitet werden, die an der jeweiligen Option interessiert sind\n3. Neue Erweiterungs-Header können definiert werden, ohne das Basis-Protokoll zu ändern\n4. Die Reihenfolge der Erweiterungs-Header ist definiert, was die Verarbeitung effizienter macht\n\nDies ist ein Beispiel für die Modernisierung und Optimierung des Protokolldesigns in IPv6 im Vergleich zu IPv4."
  },
  {
    "question": "Was passiert, wenn ein Router ein Paket erhält und die Ziel-IPv4-Adresse ausliest?",
    "options": [
      "Er sendet es automatisch an seinen Standard-Gateway",
      "Er sucht in seiner Routing-Tabelle nach der besten Übereinstimmung",
      "Er kapselt es immer direkt in einen neuen Layer 2-Header",
      "Er leitet es immer an das Netzwerk mit der größten Bandbreite weiter"
    ],
    "correct": 1,
    "explain": "Wenn ein Paket an einer Router-Schnittstelle ankommt, liest der Router die Ziel-IPv4-Adresse aus und durchsucht seine eigene Routing-Tabelle, um die beste Übereinstimmung (longest match) zu finden. Anhand dieser Information entscheidet der Router, wohin das Paket weitergeleitet werden soll. Die Routing-Tabelle enthält alle bekannten Netzwerkadressen (Präfixe) und gibt an, an welche Schnittstelle oder zu welchem nächsten Router (Next Hop) ein Paket weitergeleitet werden soll."
  },
  {
    "question": "Welche Arten von Routeneinträgen werden in der Routing-Tabelle eines Routers gespeichert?",
    "options": [
      "Nur Standard-Routen und automatische Routen",
      "Lokale Routen, direkt verbundene Routen und Standard-Routen",
      "Direkt verbundene Netzwerke, Remote-Netzwerke und Standardroute",
      "Switch-Routen, Host-Routen und Default-Routen"
    ],
    "correct": 2,
    "explain": "In der Routing-Tabelle eines Routers werden drei Arten von Routeneinträgen gespeichert:\n\n1. **Direkt verbundene Netzwerke**: Diese stammen von den aktiven Schnittstellen des Routers und werden automatisch hinzugefügt, wenn eine Schnittstelle mit einer IP-Adresse konfiguriert und aktiviert wird.\n\n2. **Remote-Netzwerke**: Diese beziehen sich auf Netzwerke, die mit anderen Routern verbunden sind. Sie werden entweder manuell konfiguriert oder durch dynamische Routing-Protokolle gelernt.\n\n3. **Standardroute**: Ähnlich wie bei Hosts dient die Standardroute als letztmögliches Gateway, wenn keine spezifischere Route für ein Ziel gefunden wird."
  },
  {
    "question": "Wie werden in der Routing-Tabelle direkt verbundene Netzwerke gekennzeichnet?",
    "options": [
      "Mit dem Code 'D'",
      "Mit dem Code 'C'",
      "Mit dem Code 'S'",
      "Mit dem Code 'R'"
    ],
    "correct": 1,
    "explain": "In der Routing-Tabelle werden direkt verbundene Netzwerke mit dem Code 'C' gekennzeichnet, wobei 'C' für 'Connected' (verbunden) steht. Diese Einträge werden automatisch erstellt, sobald eine Schnittstelle mit einer IP-Adresse konfiguriert und aktiviert wird. Zusätzlich zum 'C'-Eintrag für das Netzwerk wird auch ein 'L'-Eintrag (Local) für die spezifische IP-Adresse der Schnittstelle hinzugefügt."
  },
  {
    "question": "Was ist der Unterschied zwischen statischem und dynamischem Routing?",
    "options": [
      "Statisches Routing erfolgt automatisch, dynamisches Routing erfordert manuelle Konfiguration",
      "Statisches Routing betrifft nur lokale Netzwerke, dynamisches Routing nur Remote-Netzwerke",
      "Statisches Routing verwendet feste IP-Adressen, dynamisches Routing verwendet DHCP",
      "Statisches Routing erfordert manuelle Konfiguration, dynamisches Routing passt sich automatisch an Änderungen an"
    ],
    "correct": 3,
    "explain": "Der fundamentale Unterschied zwischen statischem und dynamischem Routing liegt in der Anpassungsfähigkeit und Konfigurationsweise:\n\n**Statisches Routing**:\n- Erfordert manuelle Konfiguration durch den Administrator\n- Passt sich nicht automatisch an Topologieänderungen an\n- Bei Änderungen der Netzwerktopologie müssen neue statische Routen manuell konfiguriert werden\n- Eignet sich für kleine Netzwerke mit wenigen redundanten Verbindungen\n\n**Dynamisches Routing**:\n- Router tauschen automatisch Routing-Informationen aus\n- Passt sich automatisch an Topologieänderungen an\n- Erkennt neue Pfade, wenn die bestehenden nicht mehr verfügbar sind\n- Erfordert nur die grundlegende Konfiguration des Routing-Protokolls und die Freigabe der direkt angeschlossenen Netzwerke"
  },
  {
    "question": "Wofür steht das 'L' in der Routing-Tabelle eines Cisco-Routers?",
    "options": [
      "Link state - Verbindungsstatus",
      "LAN - Local Area Network",
      "Loop - Schleifenfreie Route",
      "Local - Die IP-Adresse der lokalen Schnittstelle"
    ],
    "correct": 3,
    "explain": "In der Routing-Tabelle eines Cisco-Routers steht der Code 'L' für 'Local' und bezeichnet die IP-Adresse einer direkt verbundenen, lokalen Schnittstelle. Für jede aktive Schnittstelle mit einer konfigurierten IP-Adresse werden automatisch zwei Einträge erstellt: ein 'C'-Eintrag (Connected) für das gesamte verbundene Netzwerk und ein 'L'-Eintrag (Local) speziell für die IP-Adresse der Schnittstelle selbst. Der 'L'-Eintrag hat typischerweise eine /32-Maske (für IPv4), was einer einzelnen Hostadresse entspricht."
  },
  {
    "question": "Ein Router fügt seinem IPv4-Routing-Table einen Routeneintrag für ein Remote-Netzwerk mit dem Code 'O' hinzu. Wie wurde diese Route gelernt?",
    "options": [
      "Über das Enhanced Interior Gateway Routing Protocol (EIGRP)",
      "Über eine statisch konfigurierte Route",
      "Über das Open Shortest Path First Protocol (OSPF)",
      "Über das Routing Information Protocol (RIP)"
    ],
    "correct": 2,
    "explain": "Ein Routeneintrag mit dem Code 'O' in der IPv4-Routing-Tabelle zeigt an, dass diese Route über das **Open Shortest Path First (OSPF)** Protokoll gelernt wurde. OSPF ist ein weit verbreitetes Link-State-Routing-Protokoll für IP-Netzwerke, das zum dynamischen Austausch von Routing-Informationen zwischen Routern verwendet wird. Andere häufige Codes sind:\n- 'D' für EIGRP (Enhanced Interior Gateway Routing Protocol)\n- 'S' für statisch konfigurierte Routen\n- 'R' für RIP (Routing Information Protocol)"
  },
  {
    "question": "Welche Aussage zum Prinzip des 'longest match' bei Routing-Entscheidungen ist korrekt?",
    "options": [
      "Es priorisiert die Route mit der längsten Übertragungsdistanz",
      "Es priorisiert die Standardroute über spezifischere Routen",
      "Es priorisiert die Route mit der längsten Präfix-Übereinstimmung (spezifischste Route)",
      "Es priorisiert die zuletzt konfigurierte Route im Router"
    ],
    "correct": 2,
    "explain": "Das Prinzip des 'longest match' (längste Übereinstimmung) bedeutet, dass der Router bei der Paketweiterleitung die Route auswählt, die die spezifischste oder präziseste Übereinstimmung mit der Ziel-IP-Adresse aufweist. Je länger das übereinstimmende Präfix (Netzmaske), desto spezifischer ist die Route.\n\nBeispiel: Wenn in der Routing-Tabelle Routen für 10.0.0.0/8 und 10.1.1.0/24 existieren und ein Paket an 10.1.1.10 gesendet werden soll, wird die Route für 10.1.1.0/24 verwendet, da sie eine längere und spezifischere Übereinstimmung darstellt. Die Standardroute (0.0.0.0/0) hat die kürzeste Präfixlänge und wird nur verwendet, wenn keine spezifischere Route gefunden wird."
  },
  {
    "question": "Bei einer Netzwerktopologieänderung passt sich eine statische Route automatisch an den neuen besten Pfad an.",
    "options": ["Wahr", "Falsch"],
    "correct": 1,
    "explain": "Diese Aussage ist **falsch**. Eine statische Route passt sich nicht automatisch an Topologieänderungen an. Wenn sich die Netzwerktopologie ändert und der in der statischen Route definierte Pfad nicht mehr verfügbar ist, muss der Netzwerkadministrator die Route manuell neu konfigurieren, um einen alternativen Pfad zu definieren. Dies ist einer der Hauptnachteile statischer Routen im Vergleich zu dynamischen Routing-Protokollen, die sich automatisch anpassen können, wenn sich die Netzwerktopologie ändert. Dynamische Routing-Protokolle tauschen kontinuierlich Routing-Informationen aus und können automatisch neue beste Pfade bestimmen, wenn der aktuelle Pfad ausfällt."
  },
  {
    "question": "Welche Informationen enthält ein Router-Routeneintrag für ein Remote-Netzwerk typischerweise?",
    "options": [
      "Nur die Ziel-MAC-Adresse",
      "Die Remote-Netzwerkadresse und ein time-to-live Wert",
      "Die Remote-Netzwerkadresse und die IP-Adresse des Next-Hop-Routers",
      "Nur die IP-Adresse des Client-Hosts im Remote-Netzwerk"
    ],
    "correct": 2,
    "explain": "Ein Router-Routeneintrag für ein Remote-Netzwerk enthält typischerweise die Remote-Netzwerkadresse (das Zielnetzwerk) und die IP-Adresse des Next-Hop-Routers (über welchen Router das Paket weitergeleitet werden soll). Bei statischen Routen wird dies explizit konfiguriert, z.B. mit dem Befehl `ip route [Ziel-Netzwerk] [Netzmaske] [Next-Hop-IP-Adresse]`. Bei dynamisch gelernten Routen werden diese Informationen über Routing-Protokolle ausgetauscht. Diese Informationen sind essentiell, damit der Router weiß, wohin er Pakete weiterleiten muss, die für Netzwerke bestimmt sind, die nicht direkt mit ihm verbunden sind."
  },
  {
    "question": "Was passiert, wenn ein Router ein Paket erhält und keine spezifische Route für das Ziel in seiner Routing-Tabelle hat?",
    "options": [
      "Das Paket wird verworfen und eine ICMP-Nachricht wird zurückgesendet",
      "Es leitet das Paket an die Standardroute (Gateway of last resort) weiter",
      "Es führt eine ARP-Anfrage durch, um die MAC-Adresse des Ziels zu finden",
      "Es sendet eine Broadcast-Nachricht an alle verbundenen Netzwerke"
    ],
    "correct": 1,
    "explain": "Wenn ein Router ein Paket erhält und keine spezifische Route für das Ziel in seiner Routing-Tabelle hat, wird das Paket an die Standardroute weitergeleitet, die auch als 'Gateway of last resort' bezeichnet wird. Die Standardroute hat das Präfix 0.0.0.0/0 und wird in der Routing-Tabelle häufig mit 'S*' gekennzeichnet, wenn sie statisch konfiguriert wurde. Sie fungiert als letzte Möglichkeit für Pakete, deren Ziel nicht durch andere spezifischere Routen abgedeckt wird. Wenn keine Standardroute konfiguriert ist, wird das Paket verworfen und in der Regel eine ICMP 'Destination Unreachable'-Nachricht zurückgesendet."
  },
  {
    "question": "Was ist ein Vorteil von dynamischen Routing-Protokollen gegenüber statischen Routen?",
    "options": [
      "Sie benötigen weniger Ressourcen auf dem Router",
      "Sie sind einfacher zu konfigurieren und zu verwalten",
      "Sie passen sich automatisch an Topologieänderungen an",
      "Sie bieten immer kürzere Pfade zu den Zielnetzwerken"
    ],
    "correct": 2,
    "explain": "Ein wesentlicher Vorteil von dynamischen Routing-Protokollen gegenüber statischen Routen ist, dass sie sich automatisch an Topologieänderungen anpassen können. Wenn ein Link ausfällt oder neue Netzwerke hinzukommen, tauschen Router, die dynamische Routing-Protokolle verwenden, diese Informationen automatisch aus und aktualisieren ihre Routing-Tabellen entsprechend, ohne dass ein Administrator eingreifen muss. Dies erhöht die Netzwerkresillienz und reduziert den Verwaltungsaufwand in größeren oder komplexeren Netzwerken. Allerdings benötigen dynamische Routing-Protokolle in der Regel mehr Ressourcen (CPU, Speicher, Bandbreite) als statische Routen und können in der initialen Konfiguration komplexer sein."
  },
  {
    "question": "Wenn ein Router eine Schnittstelle mit einer IP-Adresse konfiguriert und aktiviert, welche Arten von Routen werden automatisch zur Routing-Tabelle hinzugefügt?",
    "options": [
      "Nur eine Remote-Route",
      "Eine direkt verbundene Route (C) und eine lokale Route (L)",
      "Eine OSPF-Route und eine EIGRP-Route",
      "Nur eine Standardroute"
    ],
    "correct": 1,
    "explain": "Wenn ein Router eine Schnittstelle mit einer IP-Adresse konfiguriert und aktiviert, werden automatisch zwei Arten von Routen zur Routing-Tabelle hinzugefügt:\n\n1. Eine **direkt verbundene Route** (gekennzeichnet mit dem Code 'C' für Connected), die das gesamte Netzwerksegment repräsentiert, an das die Schnittstelle angeschlossen ist.\n\n2. Eine **lokale Route** (gekennzeichnet mit dem Code 'L' für Local), die speziell die IP-Adresse der Schnittstelle selbst repräsentiert, typischerweise mit einer /32-Maske für IPv4.\n\nDiese Routen werden ohne zusätzliche Konfiguration automatisch erstellt und ermöglichen die grundlegende Konnektivität zu direkt verbundenen Netzwerken."
  },
  {
    "question": "In welchem Fall ist die Verwendung von statischen Routen besonders sinnvoll?",
    "options": [
      "In sehr großen Netzwerken mit vielen Routern",
      "In Netzwerken mit häufigen Topologieänderungen",
      "In kleinen Netzwerken mit wenigen redundanten Verbindungen",
      "In Netzwerken mit hoher Bandbreitenanforderung"
    ],
    "correct": 2,
    "explain": "Die Verwendung von statischen Routen ist besonders sinnvoll in kleinen Netzwerken mit wenigen redundanten Verbindungen. In solchen Umgebungen ist die manuelle Konfiguration überschaubar, und die Wahrscheinlichkeit häufiger Topologieänderungen ist gering. Statische Routen bieten in diesen Szenarien mehrere Vorteile:\n\n- Sie verbrauchen weniger Router-Ressourcen (CPU, Speicher)\n- Sie erzeugen keinen Routing-Protokoll-Verkehr\n- Sie bieten mehr Kontrolle über den exakten Pfad der Pakete\n- Sie sind sicherer, da keine Routing-Informationen ausgetauscht werden\n\nIn großen Netzwerken oder solchen mit häufigen Änderungen würde der administrative Aufwand für die manuelle Aktualisierung statischer Routen jedoch schnell unpraktisch werden."
  },
  {
    "question": "Was ist der Zweck einer Standardroute in der Routing-Tabelle eines Routers?",
    "options": [
      "Sie dient als Backup, wenn die primäre Route ausfällt",
      "Sie ist das letztmögliche Gateway für Pakete ohne spezifische Route",
      "Sie wird nur für direkt verbundene Netzwerke verwendet",
      "Sie bestimmt den Pfad mit der höchsten Bandbreite im Netzwerk"
    ],
    "correct": 1,
    "explain": "Eine Standardroute (auch als Default Route bekannt) dient als letztmögliches Gateway für Pakete, für die keine spezifische Route in der Routing-Tabelle existiert. Sie wird verwendet, wenn keine längere Präfix-Übereinstimmung (longest match) gefunden wird. Die Standardroute hat die Netzwerkadresse 0.0.0.0 mit der Netzmaske 0.0.0.0 (oder /0), was bedeutet, dass sie zu jeder IP-Adresse passt, aber mit der kürzestmöglichen Präfixlänge. In der Routing-Tabelle wird sie oft als 'S*' gekennzeichnet, wenn sie statisch konfiguriert wurde, und als 'Gateway of last resort' bezeichnet. In vielen Netzwerkkonfigurationen werden Standardrouten verwendet, um den Verkehr zu externen Netzwerken (z.B. dem Internet) zu leiten."
  },
  {
    "question": "Welche der folgenden Aktionen führt ein dynamisches Routingprotokoll automatisch aus?",
    "options": [
      "Manuelle Konfiguration der Schnittstellen mit IP-Adressen",
      "Bestimmung des besten Pfads und Anpassung bei Topologieänderungen",
      "Deaktivierung nicht benötigter Schnittstellen zur Energieeinsparung",
      "Automatische Zuweisung von IP-Adressen an Clients im Netzwerk"
    ],
    "correct": 1,
    "explain": "Ein dynamisches Routingprotokoll führt automatisch folgende Schritte aus:\n\n1. Erkennung von Remote-Netzwerken durch Austausch von Routing-Informationen\n2. Pflege aktueller Routing-Informationen\n3. Auswahl des besten Pfads zu Zielnetzwerken basierend auf Metriken\n4. Bestimmung eines neuen besten Pfads, wenn der aktuelle Pfad nicht mehr verfügbar ist\n\nDiese Automatisierung macht dynamische Routing-Protokolle besonders wertvoll in größeren Netzwerken oder solchen mit häufigen Topologieänderungen. Der Netzwerkadministrator muss lediglich die Basiskonfiguration des dynamischen Routing-Protokolls vornehmen und die direkt angeschlossenen Netzwerke freigeben. Die Zuweisung von IP-Adressen an Clients wird hingegen von DHCP-Servern übernommen, nicht von Routing-Protokollen."
  },
  {
    "question": "Ein Router hat in seiner Routing-Tabelle Einträge für die Netzwerke 10.0.0.0/8 und 10.1.1.0/24. Welche Route wird für ein Paket mit der Zieladresse 10.1.1.10 verwendet?",
    "options": [
      "10.0.0.0/8, weil es ein größeres Netzwerk ist",
      "10.1.1.0/24, weil es die längste Präfix-Übereinstimmung hat",
      "Beide Routen werden verwendet (Load Balancing)",
      "Die Standardroute (0.0.0.0/0)"
    ],
    "correct": 1,
    "explain": "Für ein Paket mit der Zieladresse 10.1.1.10 wird die Route für das Netzwerk 10.1.1.0/24 verwendet, weil sie die längste Präfix-Übereinstimmung (longest match) hat. Bei Routing-Entscheidungen sucht der Router nach der spezifischsten Route, die mit der Zieladresse übereinstimmt. Je länger das übereinstimmende Präfix (je größer die Zahl nach dem /), desto spezifischer ist die Route.\n\nIn diesem Fall:\n- 10.0.0.0/8 deckt alle Adressen von 10.0.0.0 bis 10.255.255.255 ab (weniger spezifisch)\n- 10.1.1.0/24 deckt nur Adressen von 10.1.1.0 bis 10.1.1.255 ab (spezifischer)\n\nDa 10.1.1.10 in beiden Bereichen liegt, aber 10.1.1.0/24 spezifischer ist, wird diese Route verwendet."
  },
  {
    "question": "Wodurch unterscheidet sich die Paketweiterleitungsentscheidung eines Hosts von der eines Routers?",
    "options": [
      "Hosts verwenden keine Routing-Tabellen",
      "Router prüfen nie die MAC-Adresse, nur die IP-Adresse",
      "Hosts senden Pakete nur an das Standard-Gateway, wenn das Ziel im Remote-Netzwerk liegt",
      "Router haben keine Standardroute wie Hosts"
    ],
    "correct": 2,
    "explain": "Der wesentliche Unterschied in der Paketweiterleitungsentscheidung zwischen einem Host und einem Router besteht darin, dass ein Host Pakete nur dann an sein Standard-Gateway (meist ein Router) weiterleitet, wenn das Ziel in einem Remote-Netzwerk liegt. Ein Host prüft zunächst, ob die Ziel-IP in seinem lokalen Subnetz liegt. Wenn ja, kommuniziert er direkt; wenn nicht, sendet er das Paket an sein Standard-Gateway.\n\nEin Router hingegen ist darauf spezialisiert, Pakete zwischen verschiedenen Netzwerken weiterzuleiten. Er durchsucht seine komplexere Routing-Tabelle nach der besten Übereinstimmung für die Ziel-IP-Adresse und leitet das Paket entsprechend weiter. Router haben in der Regel viel detailliertere Routing-Tabellen mit Einträgen für verschiedene Netzwerke, während Host-Routing-Tabellen typischerweise einfacher sind."
  },
  {
    "question": "Wenn ein Paket an der Schnittstelle eines Routers ankommt, welcher Schritt erfolgt als erstes?",
    "options": [
      "Der Router sucht nach dem besten Pfad in der Routing-Tabelle",
      "Der Router entkapselt den Layer 2-Header und -Trailer",
      "Der Router kapselt das Paket in einen neuen Layer 2-Header ein",
      "Der Router sendet eine ARP-Anfrage, um die MAC-Adresse des Next Hop zu ermitteln"
    ],
    "correct": 1,
    "explain": "Wenn ein Paket an der Schnittstelle eines Routers ankommt, ist der erste Schritt, dass der Router den Layer 2-Header (Ethernet-Header) und -Trailer entkapselt. Diese Layer 2-Informationen werden nur für die Kommunikation auf dem lokalen Netzwerksegment benötigt und sind nicht mehr relevant, sobald das Paket den Router erreicht hat. Nach dem Entkapseln kann der Router auf die Layer 3-Informationen (IP-Header) zugreifen, die Ziel-IP-Adresse auslesen und in seiner Routing-Tabelle nach der besten Übereinstimmung suchen. Erst nachdem der Router entschieden hat, wohin das Paket weitergeleitet werden soll, wird es in einen neuen Layer 2-Header und -Trailer eingekapselt, der für das nächste Netzwerksegment geeignet ist."
  },
  {
    "question": "Die Standardroute in einer Router-Routing-Tabelle hat welche Netzwerkadresse und Netzmaske?",
    "options": [
      "255.255.255.255/32",
      "127.0.0.1/8",
      "0.0.0.0/0",
      "10.0.0.0/8"
    ],
    "correct": 2,
    "explain": "Die Standardroute in einer Router-Routing-Tabelle hat die Netzwerkadresse 0.0.0.0 und die Netzmaske 0.0.0.0 (oder in CIDR-Notation: 0.0.0.0/0). Diese Kombination repräsentiert jedes mögliche Ziel, da eine Netzmaske von 0.0.0.0 bedeutet, dass keine Bits der Zieladresse berücksichtigt werden müssen, um eine Übereinstimmung zu finden. Die Standardroute wird als letzte Möglichkeit verwendet, wenn keine spezifischere Route gefunden wird, und wird häufig als 'Gateway of last resort' bezeichnet. In der Routing-Tabelle wird die Standardroute oft mit einem Sternchen (*) gekennzeichnet, wenn sie aktiv ist."
  }
]
]
}